{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace02a34-7d06-4e75-a244-cf1b915a9471",
   "metadata": {
    "id": "ace02a34-7d06-4e75-a244-cf1b915a9471"
   },
   "source": [
    "# LightGBM with default hyperparameters\n",
    "\n",
    "CoLab CPU himem.   \n",
    "Model = LG1.    \n",
    "In RNAlight, 1=nuclear.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1849059a-b4a8-4b24-b3b4-5ef3f15d5a2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1849059a-b4a8-4b24-b3b4-5ef3f15d5a2f",
    "outputId": "35e1b076-5ead-44ec-b2f7-6630f3696f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27 12:55:01.289018\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86f0998f-216d-441d-9dc5-5cf2827fe98c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86f0998f-216d-441d-9dc5-5cf2827fe98c",
    "outputId": "ee5219b1-5b71-41fc-b334-e8b44e5ebefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "#import sklearn.metrics as metrics\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5bb7b34a-6cb1-4162-9c13-8d64163e98ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb7b34a-6cb1-4162-9c13-8d64163e98ae",
    "outputId": "727d459f-1846-479a-83f6-a2b079a67652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06a3c204-1130-447c-a654-c8bff965a3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06a3c204-1130-447c-a654-c8bff965a3a8",
    "outputId": "0a0779bf-b291-4e57-f423-12f2ade5d267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CoLab\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "DATA DIR /content/drive/My Drive/data/Localization/RNAlight/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/RNAlight/'  # must end in \"/\"\n",
    "    MODEL_DIR=PATH+'My Drive/data/Localization/RNAlight/'  # must end in \"/\"\n",
    "    output_dir=PATH+'My Drive/data/Localization/RNAlight/'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = './'    # Mac\n",
    "    MODEL_DIR = './'    # Mac\n",
    "    output_dir = './'\n",
    "print('DATA DIR', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "295a8797-dd52-4b92-969a-0655f5e62310",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "295a8797-dd52-4b92-969a-0655f5e62310",
    "outputId": "b83bb5d8-4c5d-490d-cf72-e8b5c8bc756c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "SEED = 100\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c1ce357-cdc1-422e-aba2-8c8a995f73f8",
   "metadata": {
    "id": "4c1ce357-cdc1-422e-aba2-8c8a995f73f8"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    new_model = lightgbm.LGBMClassifier()\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da9eb695-32e6-4527-b54c-a1afd03bcdff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da9eb695-32e6-4527-b54c-a1afd03bcdff",
    "outputId": "5cc56bc1-9456-4fed-a015-983975c74220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier()\n"
     ]
    }
   ],
   "source": [
    "test = build_model()\n",
    "print(test)\n",
    "test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dea5888f-521c-418b-ad28-437df4507c44",
   "metadata": {
    "id": "dea5888f-521c-418b-ad28-437df4507c44"
   },
   "outputs": [],
   "source": [
    "class stats_collector:\n",
    "    def __init__(self):\n",
    "        self.reset_statistics()\n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_mcc=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "    def _append_statistics(self,accuracy,precision,recall,f1,mcc,auprc,auroc):\n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "    def compute_performance(self,y_test,yhat_pred,yhat_classes,verbose=False):\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        self._append_statistics(accuracy,precision,recall,f1,mcc,auprc,auroc)\n",
    "        if verbose:\n",
    "            self._show_confusion(y_test,yhat_pred,yhat_classes)\n",
    "            self._show_statistics(accuracy,precision,recall,f1,mcc,auprc,auroc)\n",
    "    def _show_confusion(self,y_test,yhat_pred,yhat_classes):\n",
    "            print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
    "            print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "            cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "            print('Confusion matrix\\n',cm1)\n",
    "            cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "            print('Normalized matrix\\n',cm2)\n",
    "    def _show_statistics(self,accuracy,precision,recall,f1,mcc,auprc,auroc):\n",
    "            print('accuracy:',accuracy,'precision:',precision,'recall:',recall,\\\n",
    "                  'F1:',f1,'MCC:',mcc,'AUPRC:',auprc,'AUROC:',auroc)\n",
    "    def _show_variance(self, name, stats_list):\n",
    "        if name=='MCC':\n",
    "            print('%10s %5.3f mean, %6.3f stdev' % (name,np.mean(stats_list),np.std(stats_list) ) )\n",
    "        else:\n",
    "            print('%10s %5.2f mean, %6.3f stdev' % (name,np.mean(stats_list),np.std(stats_list) ) )\n",
    "        print(stats_list)\n",
    "    def dump_all(self):\n",
    "        self._show_variance('accuracy', self.cv_accuracy)\n",
    "        self._show_variance('precision',self.cv_precision)\n",
    "        self._show_variance('recall',   self.cv_recall)\n",
    "        self._show_variance('F1',       self.cv_f1)\n",
    "        self._show_variance('MCC',      self.cv_mcc)\n",
    "        self._show_variance('AUPRC',    self.cv_auprc)\n",
    "        self._show_variance('AUROC',    self.cv_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2c0fe64b-d172-4167-bc2b-d9f617fbb1a1",
   "metadata": {
    "id": "2c0fe64b-d172-4167-bc2b-d9f617fbb1a1"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def _count_kmer(Dataset,k): # k = 3,4,5\n",
    "\n",
    "    # copy dataset\n",
    "    dataset = copy.deepcopy(Dataset)\n",
    "    # alphbet of nucleotide\n",
    "    nucleotide = ['A','C','G','T']\n",
    "\n",
    "    # generate k-mers\n",
    "    #  k == 5:\n",
    "    five = list(itertools.product(nucleotide,repeat=5))\n",
    "    pentamer = []\n",
    "    for n in five:\n",
    "        pentamer.append(\"\".join(n))\n",
    "\n",
    "    #  k == 4:\n",
    "    four = list(itertools.product(nucleotide,repeat=4))\n",
    "    tetramer = []\n",
    "    for n in four:\n",
    "        tetramer.append(\"\".join(n))\n",
    "\n",
    "    # k == 3:\n",
    "    three = list(itertools.product(nucleotide,repeat=3))\n",
    "    threemer = []\n",
    "    for n in three:\n",
    "        threemer.append(\"\".join(n))\n",
    "\n",
    "    # input features can be combinations of diffrent k values\n",
    "    if k == 34:\n",
    "        table_kmer = dict.fromkeys(threemer,0)\n",
    "        table_kmer.update(dict.fromkeys(tetramer,0))\n",
    "    if k == 45:\n",
    "        table_kmer = dict.fromkeys(tetramer,0)\n",
    "        table_kmer.update(dict.fromkeys(pentamer,0))\n",
    "    if k == 345:\n",
    "        table_kmer = dict.fromkeys(threemer,0)\n",
    "        table_kmer.update(dict.fromkeys(tetramer,0))\n",
    "        table_kmer.update(dict.fromkeys(pentamer,0))\n",
    "\n",
    "    # count k-mer for each sequence\n",
    "    for mer in table_kmer.keys():\n",
    "        table_kmer[mer] = dataset[\"cdna\"].apply(lambda x : x.count(mer))\n",
    "\n",
    "    # for k-mer raw count without normalization, index: nuc:1 or cyto:0\n",
    "    rawcount_kmer_df = pd.DataFrame(table_kmer)\n",
    "    df1_rawcount = pd.concat([rawcount_kmer_df,dataset[\"ensembl_transcript_id\"]],axis = 1)\n",
    "    df1_rawcount.index = dataset[\"tag\"]\n",
    "\n",
    "    # for k-mer frequency with normalization , index: nuc:1 or cyto:0\n",
    "    freq_kmer_df = rawcount_kmer_df.apply(lambda x: x/x.sum(),axis=1)\n",
    "    df1 = pd.concat([freq_kmer_df,dataset[\"ensembl_transcript_id\"]],axis = 1)\n",
    "    df1.index = dataset[\"tag\"]\n",
    "\n",
    "    return df1  # ,df1_rawcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e70228e-003b-4b4e-895f-b5d642270490",
   "metadata": {
    "id": "9e70228e-003b-4b4e-895f-b5d642270490"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def load_dataframe(cyto_f,nuc_f):\n",
    "    print('load dataframe')\n",
    "    dataset_cyto = pd.read_csv(cyto_f,sep='\\t',index_col = False)    #1806\n",
    "    dataset_nuc = pd.read_csv(nuc_f,sep='\\t',index_col = False)    #1986\n",
    "    print( len(dataset_cyto), 'cytoplasmic samples')\n",
    "    print( len(dataset_nuc),  'nuclear samples')\n",
    "    return dataset_cyto,dataset_nuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "449b9c12-3a7d-4e97-9816-43db7ea0caa8",
   "metadata": {
    "id": "449b9c12-3a7d-4e97-9816-43db7ea0caa8"
   },
   "outputs": [],
   "source": [
    "# Added\n",
    "def rebalance(dataset_cyto,dataset_nuc):\n",
    "    print('sample down to balance classes')\n",
    "    min_size = min(len(dataset_cyto),len(dataset_nuc))\n",
    "    # random sampling without replacement\n",
    "    dataset_cyto = dataset_cyto.sample(min_size, random_state=SEED)\n",
    "    dataset_nuc  = dataset_nuc.sample(min_size,  random_state=SEED)\n",
    "    print( len(dataset_cyto), 'cytoplasmic samples')\n",
    "    print( len(dataset_nuc),  'nuclear samples')\n",
    "    return dataset_cyto,dataset_nuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4ef1e58c-07a6-47f0-9fef-c439c298b3ff",
   "metadata": {
    "id": "4ef1e58c-07a6-47f0-9fef-c439c298b3ff"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def extract_features_and_split(dataset_cyto,dataset_nuc):\n",
    "    print('add labels, concatenate')\n",
    "    # Set the tag of RCI(log2FC): nuclear 1 / cytosol 0\n",
    "    dataset_nuc['tag'] = 1;dataset_cyto['tag'] = 0\n",
    "    # merge the nuc and cyto dataset\n",
    "    dataset = pd.concat([dataset_nuc,dataset_cyto]) # 3792\n",
    "\n",
    "    print('dedupe (probably not necessary)')\n",
    "    # remove duplications(actually,each lncRNA is unique in its class)\n",
    "    dataset.drop_duplicates(keep=\"first\",subset=[\"ensembl_transcript_id\",\"name\",\"cdna\"],inplace=True) # 3792\n",
    "\n",
    "    print('count kmers')\n",
    "    # k = 3,4,5 count the normalized and raw count of kmer\n",
    "    df_kmer_345 = _count_kmer(dataset,345)   # df_kmer_345,df_kmer_345_rawcount =\n",
    "\n",
    "    # We commented this out. No need to save the tsv.\n",
    "    # df_kmer_345.to_csv(os.path.join(output_dir,\"df_kmer345_freq.tsv\"),sep='\\t')\n",
    "    # This was commented out in the original. Seems they reran using saved kmers. Should test if file exists.\n",
    "    # load kmer file\n",
    "    # df_kmer_345 = pd.read_csv(os.path.join(output_dir,\"df_kmer345_freq.tsv\"),sep='\\t',index_col= 0)\n",
    "\n",
    "    # convert to x:kmer-freq , y:label\n",
    "    del df_kmer_345['ensembl_transcript_id']\n",
    "    x_kmer = df_kmer_345.values\n",
    "    y_kmer = y_kmer = np.array(df_kmer_345.index)\n",
    "\n",
    "    # split into training and test sets (9:1)\n",
    "    print('train/test split')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_kmer, y_kmer, test_size = 0.1, random_state = SEED)\n",
    "\n",
    "    #print('Apply cross-validation to all the data (no test set withheld)')\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x_kmer, y_kmer, test_size = None, random_state = SEED)\n",
    "    print('train set shape',x_train.shape)\n",
    "    # Added\n",
    "    labels,counts = np.unique(y_train,return_counts=True)\n",
    "    print('train set labels', labels, 'counts',counts)\n",
    "    labels,counts = np.unique(y_test,return_counts=True)\n",
    "    print('test set labels', labels, 'counts',counts)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18b66e70-43ab-4a04-95ec-8d74064d8b65",
   "metadata": {
    "id": "18b66e70-43ab-4a04-95ec-8d74064d8b65"
   },
   "outputs": [],
   "source": [
    "def do_cv(x_train, y_train):\n",
    "    stats = stats_collector()\n",
    "    for round in range(1,3):\n",
    "        fold=0\n",
    "        splitter = KFold(n_splits=5)\n",
    "        for train_index, valid_index in splitter.split(x_train):\n",
    "            fold += 1\n",
    "            print('Round', round, 'Fold', fold)\n",
    "            print('Num samples in train and valid sets:', len(train_index), len(valid_index))\n",
    "            print('Train')\n",
    "            lgb = build_model()\n",
    "            history = lgb.fit(x_train[train_index], y_train[train_index])\n",
    "            print('Validate')\n",
    "            x_valid = x_train[valid_index]\n",
    "            y_valid = y_train[valid_index]\n",
    "            yhat_classes= lgb.predict(x_valid)  # get 0 or 1\n",
    "            yhat_pairs=   lgb.predict_proba(x_valid)  # get [ prob of 0, prob of 1 ]\n",
    "            yhat_pred=    [pair[1] for pair in yhat_pairs]\n",
    "            stats.compute_performance(y_valid,yhat_pred,yhat_classes,verbose=False)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37daf14d-0c14-49c8-b9c0-1590df839c3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37daf14d-0c14-49c8-b9c0-1590df839c3d",
    "outputId": "f42b1bfc-2411-4ac2-9a98-df45cb46610a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the RNAlight training set (already has middle excluded)\n",
      "Data files:\n",
      "/content/drive/My Drive/data/Localization/RNAlight/02_lncRNA_info_cyto_transcript.tsv \n",
      " /content/drive/My Drive/data/Localization/RNAlight/02_lncRNA_info_nuc_transcript.tsv\n",
      "load dataframe\n",
      "1806 cytoplasmic samples\n",
      "1986 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (3412, 1344)\n",
      "train set labels [0 1] counts [1622 1790]\n",
      "test set labels [0 1] counts [184 196]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 2729 683\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1419, number of negative: 1310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335916\n",
      "[LightGBM] [Info] Number of data points in the train set: 2729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519971 -> initscore=0.079925\n",
      "[LightGBM] [Info] Start training from score 0.079925\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 2729 683\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1450, number of negative: 1279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336303\n",
      "[LightGBM] [Info] Number of data points in the train set: 2729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.531330 -> initscore=0.125485\n",
      "[LightGBM] [Info] Start training from score 0.125485\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1419, number of negative: 1311\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335875\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519780 -> initscore=0.079162\n",
      "[LightGBM] [Info] Start training from score 0.079162\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1443, number of negative: 1287\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335874\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528571 -> initscore=0.114410\n",
      "[LightGBM] [Info] Start training from score 0.114410\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 1301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.054920 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523443 -> initscore=0.093842\n",
      "[LightGBM] [Info] Start training from score 0.093842\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 2729 683\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1419, number of negative: 1310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335916\n",
      "[LightGBM] [Info] Number of data points in the train set: 2729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519971 -> initscore=0.079925\n",
      "[LightGBM] [Info] Start training from score 0.079925\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 2729 683\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1450, number of negative: 1279\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058959 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336303\n",
      "[LightGBM] [Info] Number of data points in the train set: 2729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.531330 -> initscore=0.125485\n",
      "[LightGBM] [Info] Start training from score 0.125485\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1419, number of negative: 1311\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335875\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.519780 -> initscore=0.079162\n",
      "[LightGBM] [Info] Start training from score 0.079162\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1443, number of negative: 1287\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.061532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335874\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.528571 -> initscore=0.114410\n",
      "[LightGBM] [Info] Start training from score 0.114410\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 2730 682\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1429, number of negative: 1301\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.057708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 336341\n",
      "[LightGBM] [Info] Number of data points in the train set: 2730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.523443 -> initscore=0.093842\n",
      "[LightGBM] [Info] Start training from score 0.093842\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 67.38 mean,  0.599 stdev\n",
      "[67.49633967789165, 67.34992679355784, 67.74193548387096, 68.03519061583577, 66.27565982404691, 67.49633967789165, 67.34992679355784, 67.74193548387096, 68.03519061583577, 66.27565982404691]\n",
      " precision 68.31 mean,  2.242 stdev\n",
      "[71.46974063400576, 65.1948051948052, 70.13333333333334, 66.92913385826772, 67.8474114441417, 71.46974063400576, 65.1948051948052, 70.13333333333334, 66.92913385826772, 67.8474114441417]\n",
      "    recall 70.80 mean,  2.658 stdev\n",
      "[66.84636118598382, 73.82352941176471, 70.88948787061994, 73.48703170028818, 68.97506925207756, 66.84636118598382, 73.82352941176471, 70.88948787061994, 73.48703170028818, 68.97506925207756]\n",
      "        F1 69.46 mean,  0.742 stdev\n",
      "[69.08077994428969, 69.24137931034483, 70.50938337801608, 70.05494505494507, 68.4065934065934, 69.08077994428969, 69.24137931034483, 70.50938337801608, 70.05494505494507, 68.4065934065934]\n",
      "       MCC 0.347 mean,  0.013 stdev\n",
      "[0.3498886620099441, 0.350415843085617, 0.3491538165367133, 0.3611889218988734, 0.32253377339770717, 0.3498886620099441, 0.350415843085617, 0.3491538165367133, 0.3611889218988734, 0.32253377339770717]\n",
      "     AUPRC 73.87 mean,  1.116 stdev\n",
      "[74.79549837802942, 71.93394039790604, 74.69370889511195, 74.64356338970336, 73.27824061534723, 74.79549837802942, 71.93394039790604, 74.69370889511195, 74.64356338970336, 73.27824061534723]\n",
      "     AUROC 72.57 mean,  1.174 stdev\n",
      "[72.89290897781463, 72.36666095009431, 71.8194503427774, 74.61740289904944, 71.15920642728317, 72.89290897781463, 72.36666095009431, 71.8194503427774, 74.61740289904944, 71.15920642728317]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use the RNAlight training set (already has middle excluded)')\n",
    "    cyto_f = DATA_DIR+'02_lncRNA_info_cyto_transcript.tsv'\n",
    "    nuc_f  = DATA_DIR+'02_lncRNA_info_nuc_transcript.tsv'\n",
    "    print('Data files:')\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c05c7485-5917-446b-9207-74fa17bcf5eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c05c7485-5917-446b-9207-74fa17bcf5eb",
    "outputId": "c424b4e2-c904-498b-d6b1-7339a7b9d04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "1806 cytoplasmic samples\n",
      "1806 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (3250, 1344)\n",
      "train set labels [0 1] counts [1632 1618]\n",
      "test set labels [0 1] counts [174 188]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1286, number of negative: 1314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334586\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494615 -> initscore=-0.021539\n",
      "[LightGBM] [Info] Start training from score -0.021539\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1290, number of negative: 1310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335134\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496154 -> initscore=-0.015385\n",
      "[LightGBM] [Info] Start training from score -0.015385\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1286, number of negative: 1314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335010\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494615 -> initscore=-0.021539\n",
      "[LightGBM] [Info] Start training from score -0.021539\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1309, number of negative: 1291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335096\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503462 -> initscore=0.013846\n",
      "[LightGBM] [Info] Start training from score 0.013846\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1301, number of negative: 1299\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334863\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500385 -> initscore=0.001538\n",
      "[LightGBM] [Info] Start training from score 0.001538\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1286, number of negative: 1314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334586\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494615 -> initscore=-0.021539\n",
      "[LightGBM] [Info] Start training from score -0.021539\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1290, number of negative: 1310\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063243 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335134\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496154 -> initscore=-0.015385\n",
      "[LightGBM] [Info] Start training from score -0.015385\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1286, number of negative: 1314\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335010\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494615 -> initscore=-0.021539\n",
      "[LightGBM] [Info] Start training from score -0.021539\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1309, number of negative: 1291\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335096\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503462 -> initscore=0.013846\n",
      "[LightGBM] [Info] Start training from score 0.013846\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 2600 650\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1301, number of negative: 1299\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.063707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 334863\n",
      "[LightGBM] [Info] Number of data points in the train set: 2600, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500385 -> initscore=0.001538\n",
      "[LightGBM] [Info] Start training from score 0.001538\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 67.82 mean,  1.700 stdev\n",
      "[69.38461538461539, 67.38461538461539, 66.46153846153847, 65.6923076923077, 70.15384615384616, 69.38461538461539, 67.38461538461539, 66.46153846153847, 65.6923076923077, 70.15384615384616]\n",
      " precision 67.82 mean,  2.518 stdev\n",
      "[71.52103559870551, 67.6829268292683, 68.0379746835443, 63.60759493670886, 68.24925816023739, 71.52103559870551, 67.6829268292683, 68.0379746835443, 63.60759493670886, 68.24925816023739]\n",
      "    recall 67.32 mean,  2.822 stdev\n",
      "[66.56626506024097, 67.6829268292683, 64.7590361445783, 65.0485436893204, 72.55520504731862, 66.56626506024097, 67.6829268292683, 64.7590361445783, 65.0485436893204, 72.55520504731862]\n",
      "        F1 67.53 mean,  2.079 stdev\n",
      "[68.95475819032761, 67.6829268292683, 66.35802469135803, 64.32, 70.33639143730886, 68.95475819032761, 67.6829268292683, 66.35802469135803, 64.32, 70.33639143730886]\n",
      "       MCC 0.357 mean,  0.035 stdev\n",
      "[0.38931493773515957, 0.347636721708832, 0.33003031830417145, 0.3129822378081731, 0.4043839905403544, 0.38931493773515957, 0.347636721708832, 0.33003031830417145, 0.3129822378081731, 0.4043839905403544]\n",
      "     AUPRC 71.91 mean,  3.487 stdev\n",
      "[77.63996540461986, 73.82182418650919, 70.69854152333313, 67.6604667534431, 69.72373497944363, 77.63996540461986, 73.82182418650919, 70.69854152333313, 67.6604667534431, 69.72373497944363]\n",
      "     AUROC 73.37 mean,  2.193 stdev\n",
      "[75.85530802455102, 74.335327980609, 70.47245586118058, 71.04176750277595, 75.13380888775211, 75.85530802455102, 74.335327980609, 70.47245586118058, 71.04176750277595, 75.13380888775211]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cf916e9f-18b0-4892-8f78-4ea810f7bfe1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf916e9f-18b0-4892-8f78-4ea810f7bfe1",
    "outputId": "1ba95d55-9c75-43e5-a4b6-979da5823d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use our lncATLAS training set \"middle exclusion\" (CN-RCI < -2 or CN-RCI > 0)\n",
      "Data files:\n",
      "/content/drive/My Drive/data/Localization/RNAlight/ForRNAlight.lncRNA_RCIgt0.canonical.tsv \n",
      " /content/drive/My Drive/data/Localization/RNAlight/ForRNAlight.lncRNA_RCIlt-2.canonical.tsv\n",
      "load dataframe\n",
      "1703 cytoplasmic samples\n",
      "706 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (2168, 1344)\n",
      "train set labels [0 1] counts [1524  644]\n",
      "test set labels [0 1] counts [179  62]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 491, number of negative: 1243\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047029 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326857\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.283160 -> initscore=-0.928839\n",
      "[LightGBM] [Info] Start training from score -0.928839\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 517, number of negative: 1217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326619\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298155 -> initscore=-0.856101\n",
      "[LightGBM] [Info] Start training from score -0.856101\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 525, number of negative: 1209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326180\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302768 -> initscore=-0.834151\n",
      "[LightGBM] [Info] Start training from score -0.834151\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 1735 433\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 522, number of negative: 1213\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326820\n",
      "[LightGBM] [Info] Number of data points in the train set: 1735, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300865 -> initscore=-0.843184\n",
      "[LightGBM] [Info] Start training from score -0.843184\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 1735 433\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 521, number of negative: 1214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326641\n",
      "[LightGBM] [Info] Number of data points in the train set: 1735, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300288 -> initscore=-0.845926\n",
      "[LightGBM] [Info] Start training from score -0.845926\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 491, number of negative: 1243\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326857\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.283160 -> initscore=-0.928839\n",
      "[LightGBM] [Info] Start training from score -0.928839\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 517, number of negative: 1217\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326619\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.298155 -> initscore=-0.856101\n",
      "[LightGBM] [Info] Start training from score -0.856101\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 1734 434\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 525, number of negative: 1209\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326180\n",
      "[LightGBM] [Info] Number of data points in the train set: 1734, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.302768 -> initscore=-0.834151\n",
      "[LightGBM] [Info] Start training from score -0.834151\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 1735 433\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 522, number of negative: 1213\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326820\n",
      "[LightGBM] [Info] Number of data points in the train set: 1735, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300865 -> initscore=-0.843184\n",
      "[LightGBM] [Info] Start training from score -0.843184\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 1735 433\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 521, number of negative: 1214\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 326641\n",
      "[LightGBM] [Info] Number of data points in the train set: 1735, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.300288 -> initscore=-0.845926\n",
      "[LightGBM] [Info] Start training from score -0.845926\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 75.97 mean,  2.334 stdev\n",
      "[71.88940092165899, 75.34562211981567, 78.80184331797236, 77.36720554272517, 76.44341801385681, 71.88940092165899, 75.34562211981567, 78.80184331797236, 77.36720554272517, 76.44341801385681]\n",
      " precision 66.16 mean,  2.641 stdev\n",
      "[70.12987012987013, 63.51351351351351, 68.4931506849315, 64.28571428571429, 64.38356164383562, 70.12987012987013, 63.51351351351351, 68.4931506849315, 64.28571428571429, 64.38356164383562]\n",
      "    recall 39.36 mean,  3.301 stdev\n",
      "[35.294117647058826, 37.00787401574803, 42.016806722689076, 44.26229508196721, 38.21138211382114, 35.294117647058826, 37.00787401574803, 42.016806722689076, 44.26229508196721, 38.21138211382114]\n",
      "        F1 49.24 mean,  2.499 stdev\n",
      "[46.95652173913044, 46.766169154228855, 52.083333333333336, 52.427184466019426, 47.95918367346939, 46.95652173913044, 46.766169154228855, 52.083333333333336, 52.427184466019426, 47.95918367346939]\n",
      "       MCC 0.369 mean,  0.030 stdev\n",
      "[0.3390267230305371, 0.34131433336509115, 0.41403174517392066, 0.3938080101896279, 0.35924502947610776, 0.3390267230305371, 0.34131433336509115, 0.41403174517392066, 0.3938080101896279, 0.35924502947610776]\n",
      "     AUPRC 62.90 mean,  2.754 stdev\n",
      "[66.57467619293583, 58.356435673248455, 62.66993468816528, 64.69257758296462, 62.193204702142815, 66.57467619293583, 58.356435673248455, 62.66993468816528, 64.69257758296462, 62.193204702142815]\n",
      "     AUROC 77.59 mean,  1.526 stdev\n",
      "[76.76598516037495, 75.1417066352048, 79.01027077497666, 79.30261978809762, 77.7261998426436, 76.76598516037495, 75.1417066352048, 79.01027077497666, 79.30261978809762, 77.7261998426436]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use our lncATLAS training set \"middle exclusion\" (CN-RCI < -2 or CN-RCI > 0)')\n",
    "    cyto_f = DATA_DIR+'ForRNAlight.lncRNA_RCIgt0.canonical.tsv'\n",
    "    nuc_f  = DATA_DIR+'ForRNAlight.lncRNA_RCIlt-2.canonical.tsv'\n",
    "    print('Data files:')\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c636039b-3223-4bed-9975-aa712353a1a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c636039b-3223-4bed-9975-aa712353a1a5",
    "outputId": "9e4c9575-3d11-4075-ece7-99c5126769d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "706 cytoplasmic samples\n",
      "706 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (1270, 1344)\n",
      "train set labels [0 1] counts [639 631]\n",
      "test set labels [0 1] counts [67 75]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 500, number of negative: 516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046312 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281969\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492126 -> initscore=-0.031499\n",
      "[LightGBM] [Info] Start training from score -0.031499\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 508, number of negative: 508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045482 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284020\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 509, number of negative: 507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.045548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284421\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500984 -> initscore=0.003937\n",
      "[LightGBM] [Info] Start training from score 0.003937\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 502, number of negative: 514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048649 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 282854\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494094 -> initscore=-0.023623\n",
      "[LightGBM] [Info] Start training from score -0.023623\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 505, number of negative: 511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043684 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284544\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497047 -> initscore=-0.011811\n",
      "[LightGBM] [Info] Start training from score -0.011811\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 500, number of negative: 516\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 281969\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.492126 -> initscore=-0.031499\n",
      "[LightGBM] [Info] Start training from score -0.031499\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 508, number of negative: 508\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284020\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 509, number of negative: 507\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284421\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500984 -> initscore=0.003937\n",
      "[LightGBM] [Info] Start training from score 0.003937\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 502, number of negative: 514\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 282854\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.494094 -> initscore=-0.023623\n",
      "[LightGBM] [Info] Start training from score -0.023623\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 1016 254\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 505, number of negative: 511\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.044510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 284544\n",
      "[LightGBM] [Info] Number of data points in the train set: 1016, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497047 -> initscore=-0.011811\n",
      "[LightGBM] [Info] Start training from score -0.011811\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 70.71 mean,  2.522 stdev\n",
      "[66.92913385826772, 72.04724409448819, 74.40944881889764, 70.86614173228347, 69.29133858267717, 66.92913385826772, 72.04724409448819, 74.40944881889764, 70.86614173228347, 69.29133858267717]\n",
      " precision 71.71 mean,  2.370 stdev\n",
      "[68.50393700787401, 72.03389830508475, 75.67567567567568, 72.0, 70.33898305084746, 68.50393700787401, 72.03389830508475, 75.67567567567568, 72.0, 70.33898305084746]\n",
      "    recall 68.00 mean,  1.557 stdev\n",
      "[66.41221374045801, 69.10569105691057, 68.85245901639344, 69.76744186046511, 65.87301587301587, 66.41221374045801, 69.10569105691057, 68.85245901639344, 69.76744186046511, 65.87301587301587]\n",
      "        F1 69.80 mean,  1.770 stdev\n",
      "[67.44186046511628, 70.53941908713693, 72.10300429184548, 70.86614173228347, 68.0327868852459, 67.44186046511628, 70.53941908713693, 72.10300429184548, 70.86614173228347, 68.0327868852459]\n",
      "       MCC 0.414 mean,  0.050 stdev\n",
      "[0.338750739558115, 0.4400369672560624, 0.4874880929564311, 0.41767441860465115, 0.38625181545140586, 0.338750739558115, 0.4400369672560624, 0.4874880929564311, 0.41767441860465115, 0.38625181545140586]\n",
      "     AUPRC 77.67 mean,  1.261 stdev\n",
      "[76.53541841519447, 77.1356383941365, 80.11551031856018, 77.06781896242394, 77.48290192481473, 76.53541841519447, 77.1356383941365, 80.11551031856018, 77.06781896242394, 77.48290192481473]\n",
      "     AUROC 78.05 mean,  2.409 stdev\n",
      "[74.36852231117732, 79.77409545087816, 81.43318430203675, 77.4077519379845, 77.25074404761905, 74.36852231117732, 79.77409545087816, 81.43318430203675, 77.4077519379845, 77.25074404761905]\n"
     ]
    }
   ],
   "source": [
    "if True:   # just to be sure\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1830d712-20a6-4f94-9ddb-e21be989c4d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1830d712-20a6-4f94-9ddb-e21be989c4d6",
    "outputId": "205d7595-385e-4ad4-ca01-7c38e166a1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use our lncATLAS training set \"all\" (-inf <= CN-RCI <= +inf)\n",
      "/content/drive/My Drive/data/Localization/RNAlight/ForRNAlight.lncRNA_RCIgt-1.canonical.tsv \n",
      " /content/drive/My Drive/data/Localization/RNAlight/ForRNAlight.lncRNA_RCIlt-1.canonical.tsv\n",
      "load dataframe\n",
      "2887 cytoplasmic samples\n",
      "1548 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (3991, 1344)\n",
      "train set labels [0 1] counts [2606 1385]\n",
      "test set labels [0 1] counts [281 163]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 3192 799\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1102, number of negative: 2090\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.065909 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340977\n",
      "[LightGBM] [Info] Number of data points in the train set: 3192, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345238 -> initscore=-0.640037\n",
      "[LightGBM] [Info] Start training from score -0.640037\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1098, number of negative: 2095\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341051\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.343877 -> initscore=-0.646063\n",
      "[LightGBM] [Info] Start training from score -0.646063\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1099, number of negative: 2094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051810 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344190 -> initscore=-0.644675\n",
      "[LightGBM] [Info] Start training from score -0.644675\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1134, number of negative: 2059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.355152 -> initscore=-0.596469\n",
      "[LightGBM] [Info] Start training from score -0.596469\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1107, number of negative: 2086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052174 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340953\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346696 -> initscore=-0.633595\n",
      "[LightGBM] [Info] Start training from score -0.633595\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 3192 799\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1102, number of negative: 2090\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340977\n",
      "[LightGBM] [Info] Number of data points in the train set: 3192, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.345238 -> initscore=-0.640037\n",
      "[LightGBM] [Info] Start training from score -0.640037\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1098, number of negative: 2095\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341051\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.343877 -> initscore=-0.646063\n",
      "[LightGBM] [Info] Start training from score -0.646063\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1099, number of negative: 2094\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.053443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341021\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.344190 -> initscore=-0.644675\n",
      "[LightGBM] [Info] Start training from score -0.644675\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1134, number of negative: 2059\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050579 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 341022\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.355152 -> initscore=-0.596469\n",
      "[LightGBM] [Info] Start training from score -0.596469\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 3193 798\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1107, number of negative: 2086\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.051180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340953\n",
      "[LightGBM] [Info] Number of data points in the train set: 3193, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.346696 -> initscore=-0.633595\n",
      "[LightGBM] [Info] Start training from score -0.633595\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 68.40 mean,  1.854 stdev\n",
      "[69.96245306633291, 68.67167919799499, 66.29072681704261, 70.80200501253134, 66.29072681704261, 69.96245306633291, 68.67167919799499, 66.29072681704261, 70.80200501253134, 66.29072681704261]\n",
      " precision 57.85 mean,  4.035 stdev\n",
      "[62.01117318435754, 63.12056737588653, 55.4140127388535, 56.08108108108109, 52.63157894736842, 62.01117318435754, 63.12056737588653, 55.4140127388535, 56.08108108108109, 52.63157894736842]\n",
      "    recall 33.22 mean,  3.146 stdev\n",
      "[39.2226148409894, 31.010452961672474, 30.419580419580424, 33.067729083665334, 32.37410071942446, 39.2226148409894, 31.010452961672474, 30.419580419580424, 33.067729083665334, 32.37410071942446]\n",
      "        F1 42.12 mean,  3.096 stdev\n",
      "[48.05194805194806, 41.58878504672897, 39.27765237020316, 41.60401002506266, 40.089086859688194, 48.05194805194806, 41.58878504672897, 39.27765237020316, 41.60401002506266, 40.089086859688194]\n",
      "       MCC 0.242 mean,  0.039 stdev\n",
      "[0.2987505651859557, 0.26214323134281053, 0.2020200477574343, 0.2530847284231821, 0.19504218761060327, 0.2987505651859557, 0.26214323134281053, 0.2020200477574343, 0.2530847284231821, 0.19504218761060327]\n",
      "     AUPRC 54.34 mean,  3.778 stdev\n",
      "[59.06258994731027, 57.06800885914617, 54.24556610362076, 53.332563382562114, 47.96849759124533, 59.06258994731027, 57.06800885914617, 54.24556610362076, 53.332563382562114, 47.96849759124533]\n",
      "     AUROC 68.10 mean,  1.856 stdev\n",
      "[69.3093105431835, 67.66605071697909, 68.09030812937063, 70.48952271353343, 64.95918649695628, 69.3093105431835, 67.66605071697909, 68.09030812937063, 70.48952271353343, 64.95918649695628]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use our lncATLAS training set \"all\" (-inf <= CN-RCI <= +inf)')\n",
    "    cyto_f = DATA_DIR+'ForRNAlight.lncRNA_RCIgt-1.canonical.tsv'\n",
    "    nuc_f  = DATA_DIR+'ForRNAlight.lncRNA_RCIlt-1.canonical.tsv'\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44560340-f786-4111-a3de-242d9b2aeb17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44560340-f786-4111-a3de-242d9b2aeb17",
    "outputId": "6053dce0-01c3-474b-df55-a7bb89027670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "1548 cytoplasmic samples\n",
      "1548 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (2786, 1344)\n",
      "train set labels [0 1] counts [1397 1389]\n",
      "test set labels [0 1] counts [151 159]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 2228 558\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1096, number of negative: 1132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335379\n",
      "[LightGBM] [Info] Number of data points in the train set: 2228, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491921 -> initscore=-0.032319\n",
      "[LightGBM] [Info] Start training from score -0.032319\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1086, number of negative: 1143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.058816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.487214 -> initscore=-0.051155\n",
      "[LightGBM] [Info] Start training from score -0.051155\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1109\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047371 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335620\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502467 -> initscore=0.009870\n",
      "[LightGBM] [Info] Start training from score 0.009870\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1131, number of negative: 1098\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335509\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507402 -> initscore=0.029612\n",
      "[LightGBM] [Info] Start training from score 0.029612\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1123, number of negative: 1106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335644\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503813 -> initscore=0.015254\n",
      "[LightGBM] [Info] Start training from score 0.015254\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 2228 558\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1096, number of negative: 1132\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047227 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335379\n",
      "[LightGBM] [Info] Number of data points in the train set: 2228, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491921 -> initscore=-0.032319\n",
      "[LightGBM] [Info] Start training from score -0.032319\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1086, number of negative: 1143\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.046441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335465\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.487214 -> initscore=-0.051155\n",
      "[LightGBM] [Info] Start training from score -0.051155\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1120, number of negative: 1109\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.047022 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335620\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502467 -> initscore=0.009870\n",
      "[LightGBM] [Info] Start training from score 0.009870\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1131, number of negative: 1098\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.048144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335509\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507402 -> initscore=0.029612\n",
      "[LightGBM] [Info] Start training from score 0.029612\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 2229 557\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1123, number of negative: 1106\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.052804 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 335644\n",
      "[LightGBM] [Info] Number of data points in the train set: 2229, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503813 -> initscore=0.015254\n",
      "[LightGBM] [Info] Start training from score 0.015254\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 61.27 mean,  1.653 stdev\n",
      "[62.00716845878136, 59.06642728904848, 62.29802513464991, 63.37522441651705, 59.60502692998204, 62.00716845878136, 59.06642728904848, 62.29802513464991, 63.37522441651705, 59.60502692998204]\n",
      " precision 61.66 mean,  2.833 stdev\n",
      "[64.83516483516483, 64.82213438735178, 61.13207547169811, 59.92647058823529, 57.564575645756456, 64.83516483516483, 64.82213438735178, 61.13207547169811, 59.92647058823529, 57.564575645756456]\n",
      "    recall 59.32 mean,  2.977 stdev\n",
      "[60.40955631399317, 54.12541254125413, 60.223048327137555, 63.17829457364341, 58.64661654135338, 60.40955631399317, 54.12541254125413, 60.223048327137555, 63.17829457364341, 58.64661654135338]\n",
      "        F1 60.36 mean,  1.623 stdev\n",
      "[62.544169611307424, 58.99280575539567, 60.67415730337079, 61.50943396226415, 58.100558659217874, 62.544169611307424, 58.99280575539567, 60.67415730337079, 61.50943396226415, 58.100558659217874]\n",
      "       MCC 0.227 mean,  0.031 stdev\n",
      "[0.2415826303782754, 0.19092245311725337, 0.24473695327470957, 0.2665821154563267, 0.1911537270821675, 0.2415826303782754, 0.19092245311725337, 0.24473695327470957, 0.2665821154563267, 0.1911537270821675]\n",
      "     AUPRC 66.13 mean,  3.498 stdev\n",
      "[70.31218577265, 69.551344260979, 64.33058039211886, 65.64729101561564, 60.79144824850833, 70.31218577265, 69.551344260979, 64.33058039211886, 65.64729101561564, 60.79144824850833]\n",
      "     AUROC 66.17 mean,  1.948 stdev\n",
      "[67.40163564943009, 64.75793248616199, 64.88925030978933, 69.42003059293252, 64.3645195462884, 67.40163564943009, 64.75793248616199, 64.88925030978933, 69.42003059293252, 64.3645195462884]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35cf8437-c2c6-41d2-8b1f-70cc7ba25672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35cf8437-c2c6-41d2-8b1f-70cc7ba25672",
    "outputId": "50d657e7-1f49-43ff-fccf-13364c8562c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-27 13:03:54.053080\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
