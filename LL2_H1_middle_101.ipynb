{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "duDHL7JnN3uF"
   },
   "source": [
    "# LL2\n",
    "LncLocator2    \n",
    "Cell line H1   \n",
    "Filter train ? Yes, i.e. exclude middle     \n",
    "Fiter test ? No, i.e. inverse filter and keep middle       \n",
    "Epochs = default = 100.     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0XCYs3fnyuk",
    "outputId": "3c20f03b-6622-43eb-9174-ea552026015c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on CoLab\n",
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      "DATA PATH drive/MyDrive/data/Localization/lncLocator2/\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    DRIVE_PATH='/content/drive/'\n",
    "    drive.mount(DRIVE_PATH)\n",
    "    DATA_PATH='drive/MyDrive/data/Localization/lncLocator2/'  # must end in \"/\"\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    print('Running at home')\n",
    "    DATA_PATH=\"./\"\n",
    "print('DATA PATH', DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRs_65cHBV-J",
    "outputId": "65573a6e-3481-4779-9c82-58e9ddeef5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print('GPU device not found')\n",
    "else:\n",
    "    print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pwzjoZDowc63",
    "outputId": "8872937c-54b4-4fa6-befd-4fdd1f33bff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NKuvUxBazGgO",
    "outputId": "f0bd4818-137f-4299-b227-b8dd1c9f2269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/MyDrive/data/Localization/lncLocator2/'\n",
      "/content/drive/MyDrive/data/Localization/lncLocator2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['train.py',\n",
       " 'dataset.py.Mar28',\n",
       " 'record.py',\n",
       " 'README.md',\n",
       " 'model',\n",
       " 'glove',\n",
       " '__pycache__',\n",
       " 'checkpoints',\n",
       " '.ipynb_checkpoints',\n",
       " 'config.py.Mar28',\n",
       " 'CNRCI',\n",
       " 'utils.py',\n",
       " 'record.csv',\n",
       " 'acc.png',\n",
       " 'loss.png',\n",
       " 'auroc.png',\n",
       " 'main.py.Mar28',\n",
       " 'config.py',\n",
       " 'dataset.py',\n",
       " 'main.py',\n",
       " 'train.log']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()\n",
    "%cd $DATA_PATH\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFsnchNh1pAe",
    "outputId": "d313bf85-a932-4a69-e15e-e330bdcae298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "3200/9282 \n",
      "loss: tensor(2.2689, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3425,  1.0841, -1.2267, -1.1069, -1.9386, -1.8882, -1.8804,  1.6172,\n",
      "        -1.2700, -2.5523, -1.7923,  1.6848, -1.0238,  1.3683, -1.6888, -1.6938,\n",
      "         1.3041,  1.5850, -1.5794,  2.5384, -1.1375, -1.1923,  1.4382, -1.5850,\n",
      "        -1.0486, -2.0000, -3.6897,  1.0555, -1.1699, -2.4594, -1.1737, -1.9875],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4159,  0.3943, -1.3270,  1.2240,  1.3952, -1.5834, -1.0736,  1.6751,\n",
      "        -1.9847, -1.6042, -1.6233,  1.0424, -1.2431,  1.6487, -0.8903, -1.4897,\n",
      "         0.1547, -0.4859, -1.2363,  0.0609,  2.2204, -1.6702,  1.6649, -0.4950,\n",
      "        -1.6523,  1.0993, -1.5640, -0.0337, -0.5059, -0.0438, -0.1691, -1.1821],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.9146, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.8826, -2.0937, -1.1676,  1.3352,  3.4150,  1.0297, -1.2737, -2.4594,\n",
      "        -1.2070,  1.3479,  1.7994, -1.6003,  1.4374, -2.1803,  1.1444,  1.1475,\n",
      "        -1.4400, -2.4417, -1.4875,  1.1255, -2.0939, -1.4935, -2.4288,  1.0750,\n",
      "         1.7370, -2.4742,  2.3692,  1.0189, -2.3219, -1.3077, -2.1993, -2.0666],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8852, -0.7740, -1.2203,  1.1833,  1.7579,  1.1362,  1.1915, -1.8095,\n",
      "        -1.7578,  1.2663, -0.0026, -1.6320,  1.2609, -1.8867,  0.3122,  2.1613,\n",
      "        -1.7102,  1.8838, -1.6602,  1.8867,  2.0462, -1.8836, -0.9717,  0.7779,\n",
      "         0.9249,  1.0934, -0.9131, -0.3710,  0.4063,  0.8624, -0.9587,  0.2994],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1398, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.2334, -1.1651, -1.2682, -2.0939,  1.5850, -1.0407,  1.1453, -1.9095,\n",
      "        -1.8680, -1.7447, -1.4400,  1.4105, -1.8784,  2.2635, -1.4854, -2.0275,\n",
      "        -1.6080, -2.2033,  1.6818,  1.0446,  1.1690, -2.4041, -2.4417,  1.7746,\n",
      "        -1.3727, -1.2732, -2.4417, -1.4482,  2.8821,  2.7143, -1.1677, -1.3310],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.6507, -1.7565, -1.6449, -1.6305,  1.1355, -1.2133,  0.8389, -1.4009,\n",
      "        -1.5571, -1.9035, -1.4148,  2.2916,  0.2611,  1.4338, -0.4571, -1.7074,\n",
      "        -1.8679, -2.0267,  0.4112, -0.3115,  1.1425, -1.2868,  0.9698,  1.1039,\n",
      "        -1.0245, -0.1976,  1.0707, -1.5120,  1.7558,  0.3893,  0.6738,  1.5216],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4532, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.5443,  2.1066, -1.6647, -1.3099, -1.3310, -1.1211,  1.3986,  2.7798,\n",
      "         1.1871,  2.9542,  1.2479, -1.4482,  1.8217, -2.3318,  1.8826,  1.9372,\n",
      "         1.8263, -2.2076, -1.1726, -1.9347, -2.0504, -1.4594,  1.3943, -3.8000,\n",
      "        -1.6675,  1.1375, -3.4215,  1.5146, -1.0999,  1.3468, -1.5589, -1.6084],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1580,  0.7716, -1.4813, -0.4857,  1.8610,  0.4924, -0.1518,  0.1609,\n",
      "         1.9356,  0.0516,  0.4486, -0.7409,  2.7105, -1.6845,  0.7648,  1.9034,\n",
      "         0.7877, -0.5305, -0.1719, -1.2276, -0.7360, -0.7733, -0.1354, -1.8448,\n",
      "        -0.4737,  1.2719, -1.6737, -0.5170, -1.3844,  0.4770, -1.0020, -1.4308],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 35 Predict 1068 zeros 615 ones, one bias 0.365419\n",
      "train loss: 2.2135291842904694 dev loss: 1.4371422142020867\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.4287, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3310,  1.3931, -1.2966,  1.8160, -1.3450,  1.2282, -1.3785, -1.4058,\n",
      "        -1.6255, -1.0446, -1.5549, -2.0194,  2.0888, -1.0766,  1.5142, -1.6003,\n",
      "        -2.5220, -2.0000, -2.4448,  1.5236, -1.6472, -1.0522, -2.4595,  3.0444,\n",
      "        -1.9022, -1.8458, -1.9260, -1.3831,  1.3239,  1.5400, -1.0987,  1.3468],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2343, -0.2099, -0.5926,  0.0419,  2.0643, -0.8227,  0.0718, -0.6276,\n",
      "        -1.5743,  1.2570, -1.0832,  0.5869, -0.9801, -2.0028,  1.7239, -1.7418,\n",
      "        -1.5350,  0.7837, -1.4452,  1.0708,  0.2797,  1.2355, -1.9171,  1.5140,\n",
      "        -1.3079, -1.0583, -1.2228, -1.1372,  1.5224,  0.5846, -1.1080,  1.2512],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.5330, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0536,  1.0281,  1.7162, -1.7320, -1.0243,  1.8399,  2.6945, -1.3219,\n",
      "        -1.1677, -2.7553, -2.2730,  2.0275, -1.2214, -1.2685,  1.2658,  1.9883,\n",
      "         1.2630, -1.3215,  1.2137,  1.3255, -1.8804, -1.6828, -1.0091,  3.0444,\n",
      "         1.2224,  1.2941,  1.1333, -1.3398, -1.0716,  1.3768,  1.0846,  1.3119],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1662,  1.0902,  1.5266, -1.6062, -1.0178, -1.1412,  1.1124, -1.1048,\n",
      "        -1.6265, -1.5044, -1.6437,  1.1631, -1.1143, -0.8930,  2.0023, -1.3008,\n",
      "         0.2533, -1.7809, -1.3733, -1.3967, -1.2437,  1.1830, -1.5823,  0.7790,\n",
      "         0.6930, -1.5963, -1.5212, -1.1608, -1.5281,  1.0574, -0.3456,  1.8865],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(5.5952, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8074, -2.6245,  2.7558, -3.1193, -2.9696, -1.0486, -1.1699, -1.9682,\n",
      "        -3.2854, -1.2486, -1.0446,  3.1430, -2.3708, -2.6955, -2.2816,  1.2578,\n",
      "        -1.1319, -1.0522, -2.3495,  1.6092,  1.0770, -1.6374,  4.2479, -1.6675,\n",
      "        -1.0370, -4.3219,  1.4406,  1.0761, -3.1945, -1.3219,  1.3969,  1.4228],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8527, -1.5838,  2.5550, -1.6723, -1.0934, -1.7996, -0.9887, -1.6618,\n",
      "        -1.2147, -0.7304, -2.0299, -1.3200, -1.1450, -1.1165, -1.1227, -1.1094,\n",
      "        -0.9713, -1.4750, -1.8656,  1.7142, -0.0189, -2.1247, -1.7016, -1.1407,\n",
      "        -0.6807,  1.2045,  0.9265, -0.6665, -0.7373,  0.0724, -0.4955, -0.2372],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.1080, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.1865, -1.4763, -2.4922,  1.8122,  1.5850,  1.5482, -2.4594, -2.9116,\n",
      "        -2.2624,  1.7148,  1.2475,  1.1527, -2.0360, -2.3394,  2.8431,  1.2494,\n",
      "         1.4475, -1.4875,  1.0408, -1.5884,  3.0444, -1.6288, -1.0712, -1.7081,\n",
      "        -1.8433,  1.4076,  1.1107, -1.4055,  1.5564, -2.6924,  1.2685, -1.0766],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0552, -1.8448, -1.9377,  0.9523, -1.5569,  1.2617, -1.5936, -2.3011,\n",
      "        -1.4712,  0.4817,  0.6037,  0.9441, -0.5131, -1.0808,  1.6844,  0.7682,\n",
      "         0.6534, -1.7292,  0.2021, -1.4148,  1.6634, -1.5896, -1.8386, -2.2540,\n",
      "        -1.8708,  1.2629, -0.3791, -1.5874,  0.7708, -2.4056, -0.2125, -1.5824],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.8207, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0431,  1.6017, -2.4413,  2.6168, -1.5407,  1.1699, -1.8747, -1.3809,\n",
      "        -1.0705, -1.8837,  2.1463,  1.6863, -1.4150,  1.0728,  1.7726,  1.8573,\n",
      "         1.5135, -1.6268,  1.5850, -2.0298,  1.6750, -1.5746, -1.4167,  1.6894,\n",
      "        -1.6614,  1.1964,  3.3173, -1.1024,  3.5744,  1.0776, -1.9879,  1.3615],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0415,  0.2547, -1.0778,  2.9044, -0.1591, -0.7477, -1.5532, -0.2958,\n",
      "        -0.6232, -1.6756,  1.3454,  0.9097, -1.1052,  0.0653, -0.7331,  0.7038,\n",
      "         1.4094, -0.7496,  1.3101, -0.7256,  1.0655, -0.3024, -0.0334,  1.7706,\n",
      "        -0.5450, -0.1582,  0.7628, -0.7777,  0.6186, -0.4059, -1.1830,  0.9388],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2856, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3621,  1.5110,  1.6897, -2.0106,  1.3785,  1.0024, -1.1876,  2.8073,\n",
      "        -1.4132, -1.7512,  1.0841, -2.2441,  2.3219, -2.3219,  1.3172, -3.5425,\n",
      "        -1.1942,  1.0464,  1.3219,  1.5850,  2.3219, -1.0370,  2.3219, -1.0945,\n",
      "        -1.0041, -2.4288, -1.6978,  1.7124, -1.6888, -1.3077,  1.5624, -2.2066],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6557,  1.5275, -0.7212, -0.2122,  0.0879, -0.1102, -1.6646,  1.3934,\n",
      "         0.8520, -0.3444,  0.9595, -1.7751, -0.0144, -1.5701,  1.5149, -1.7555,\n",
      "        -1.6208, -1.9919,  0.2335, -1.6556,  0.5914, -0.9910,  0.8286, -1.1194,\n",
      "         1.0674, -1.9042, -2.0960,  0.1414, -0.5240, -0.9062,  0.5434, -1.6879],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 36 Predict 1062 zeros 621 ones, one bias 0.368984\n",
      "train loss: 2.200392852798409 dev loss: 1.0968930013189708\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.3974, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3683, -1.7011, -1.2191,  1.7105, -2.3741,  1.5564, -1.8433, -1.9069,\n",
      "         1.4370, -1.1478,  1.1957, -2.4594, -1.9260, -1.7051,  1.2224,  1.0047,\n",
      "        -1.6524,  1.4232,  1.9594, -2.5510,  1.0993, -1.3185, -1.6675, -2.0478,\n",
      "        -2.3669, -1.9778, -2.3978, -1.3591, -1.0614,  1.0194, -3.1375, -1.2224],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.2219, -1.6956, -1.9473,  1.3988, -1.3276, -0.1005, -0.3099, -1.3103,\n",
      "         0.6197, -1.1246, -1.0439, -1.3495, -1.0945, -2.1541, -1.0725,  0.2578,\n",
      "        -0.2083, -0.0681,  0.7983, -1.0775, -1.8152,  0.9580, -0.7318, -1.8513,\n",
      "        -1.6599, -0.0285, -1.3565, -1.8695, -0.4808,  0.5300,  1.0360, -0.2284],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(4.0394, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.2645, -1.3163,  1.5850, -1.7004, -1.8074, -1.0181,  3.1414, -1.8846,\n",
      "        -1.3010,  1.6092,  2.2721,  3.7635,  1.0841, -2.2598, -1.9401, -2.4127,\n",
      "         1.7227, -1.8921, -1.3102, -2.5850,  2.2654, -2.8073,  2.7143, -2.6881,\n",
      "        -2.4041, -1.4150,  3.5850,  5.2785, -1.1602, -1.5850, -1.2340, -2.1115],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5135, -1.6811, -1.0137,  0.9360, -1.2136, -0.4656, -0.1750,  0.0927,\n",
      "        -1.9931,  1.0556,  1.4780,  1.2713, -0.1418, -1.7933, -0.4434, -1.6206,\n",
      "         0.0206, -0.6432, -2.2136, -0.3491,  0.3143, -0.9021,  1.0897, -0.9439,\n",
      "        -2.1925, -1.1079,  1.3952,  0.7827, -1.3826,  0.2110, -1.0085, -0.5884],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.0378, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0298,  1.1874, -1.2224,  2.1066,  1.3468, -1.0243,  1.1718, -2.6658,\n",
      "        -2.0666,  1.0669, -1.4500,  1.7914,  1.3022, -1.8571, -1.3975,  1.8074,\n",
      "        -1.5422, -1.9704,  1.1069,  1.8517, -1.6924, -1.9069, -1.9281,  1.0297,\n",
      "        -1.7309,  1.5187, -1.6524,  1.7868, -1.9069,  1.9723, -1.0486, -1.0070],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1018, -1.0995, -1.2333,  0.4190, -0.1967, -1.4215,  0.6120, -2.0718,\n",
      "        -0.1679, -0.7357, -1.3443,  0.1836,  0.8247, -1.6408, -1.6154, -0.4561,\n",
      "         1.2465, -1.7411, -1.1384,  1.8087, -1.3540, -0.9916, -2.2210, -0.0087,\n",
      "        -1.4046,  1.3488, -0.5442,  0.1872,  1.4606,  1.8885, -1.7500,  0.0554],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.7587, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0870, -1.8747,  2.6676, -1.9260,  1.6750, -1.6656, -1.4081, -1.1259,\n",
      "        -2.8694, -2.9696,  1.7061, -4.9925,  2.0358, -1.7004, -2.4285, -3.1509,\n",
      "        -1.5884, -2.7370, -2.0275,  1.2633, -2.2330, -1.3036, -1.0431,  1.0734,\n",
      "         1.0756, -1.8389,  1.4382, -1.0768, -2.3536, -1.1319, -1.2232, -2.8073],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3799, -1.6694,  1.8089, -1.4043,  0.9061, -1.6213, -1.3614, -1.3881,\n",
      "        -0.6166, -1.4698,  1.4118, -1.7003,  0.8600, -0.1412, -1.7364, -1.4432,\n",
      "        -1.4635, -1.4892, -1.6142,  0.8730, -1.5845, -0.3453,  1.0968,  0.9516,\n",
      "        -1.7742, -1.6323,  0.6755, -1.3448, -1.8234, -1.1028, -1.9547, -1.3132],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.6205, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8074, -1.0658, -1.0155, -2.0324,  1.8004,  2.0940,  1.7974, -1.3103,\n",
      "         1.4557,  1.0669, -2.0767,  1.5850, -1.4454, -1.0870, -3.0000, -1.2663,\n",
      "        -1.3923, -1.9260,  1.5487, -1.7046, -1.4159, -2.4234, -1.1165,  1.0024,\n",
      "         1.0109, -1.3745, -1.1043, -1.4150,  1.7370,  1.0669, -1.6003, -1.2058],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7262, -0.8023, -1.5042, -1.7820,  0.3376,  0.3061,  0.9082, -1.3607,\n",
      "        -0.1132, -0.2116, -1.6977, -0.6170, -1.5674, -0.1461, -1.3153, -1.6696,\n",
      "        -1.0404, -1.0337,  2.2620,  0.3105, -1.8575, -1.7424, -0.8638,  1.2987,\n",
      "        -0.1906, -0.2060, -1.2639, -1.0521, -0.7550, -1.4286, -1.7306, -0.9854],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(4.3941, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.3835, -2.0000, -2.9386, -1.4962,  1.2022,  5.2785, -1.0103,  1.7914,\n",
      "         1.2776,  2.1915, -2.5920, -1.4706,  1.8122, -1.1155, -1.9778, -3.3709,\n",
      "         1.3334,  3.0809,  1.0380, -1.0562,  1.8931,  1.3931,  2.6800,  1.3785,\n",
      "         2.5361,  2.0000,  1.7010,  1.3215, -1.4936, -3.0875, -1.1024, -1.2543],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6464,  0.6887, -1.7870, -1.8136,  0.7854, -0.3143, -1.9022, -1.2310,\n",
      "        -0.1619,  1.0290,  0.1027, -0.9868,  0.2242, -0.0944, -0.9256, -1.7446,\n",
      "         0.2101,  1.1924, -1.5883, -1.7187, -1.7558,  0.6113,  1.1819,  1.3159,\n",
      "         1.4230,  0.9976,  0.8840,  0.5569, -0.8504, -0.9103,  0.2947,  0.6837],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 37 Predict 1001 zeros 682 ones, one bias 0.405229\n",
      "train loss: 2.1965264697137563 dev loss: 1.4427700254762548\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.0916, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2257, -1.4083, -2.1115,  1.2357,  1.7370, -1.4610, -1.5729,  1.5850,\n",
      "        -2.9681,  1.3941, -2.3738, -1.7082,  1.2685,  1.8260, -1.5247, -1.1543,\n",
      "         2.0000, -1.8611, -1.9260, -1.5817,  1.7225, -1.5265, -1.4482, -2.4595,\n",
      "         3.1414, -1.1205, -1.6008, -2.5850,  1.6618, -1.8458,  1.0384,  1.2708],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0634, -1.0858, -0.7890,  1.0304,  0.8508, -1.7685, -0.8294,  0.0698,\n",
      "        -1.8021,  1.3924, -1.7271, -1.5300,  0.3790,  0.3833, -1.9283,  1.4248,\n",
      "         1.2493, -1.4373, -0.9489, -1.8683,  0.9778, -1.2730,  1.3045, -0.4375,\n",
      "         1.1134,  1.3351, -1.6738,  1.0112,  0.9930, -0.5104,  2.2713,  1.4800],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.5039, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.4150, -1.8504, -1.3215,  2.6932, -2.4041,  3.0000,  1.2111,  2.0211,\n",
      "         2.6625, -2.2630,  1.9723,  1.3949,  1.0380, -1.4523, -1.2730, -3.3219,\n",
      "        -2.4234, -2.2605, -2.4586,  2.6825, -2.5395,  2.6738, -1.8649, -1.5729,\n",
      "        -1.5834, -3.8073, -1.2479, -1.5850, -1.0999, -1.0766, -1.7082,  1.0841],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1861, -1.1506, -1.5820,  2.2941, -1.0421,  1.3630,  0.5993, -0.0874,\n",
      "         1.0926, -1.5321,  1.2840,  0.1325, -1.6656, -0.6465, -1.2700, -1.6005,\n",
      "        -1.2883, -1.2013, -1.7227, -0.7583, -1.3213,  1.1033, -0.7444, -0.8125,\n",
      "        -1.4326, -0.9713, -0.4285, -0.7326, -1.0530, -1.2817, -1.5583, -0.2873],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.9644, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3833, -2.1155,  2.1825, -2.1155,  1.0067,  1.3344,  1.0961,  1.5850,\n",
      "         1.3219,  2.1694,  2.0232, -1.5309, -1.8258, -2.7380, -1.0100,  3.7726,\n",
      "        -1.4454,  1.6201, -1.5729,  1.3196, -1.2675, -1.8074,  1.6571, -2.2630,\n",
      "        -1.7447, -2.7370, -1.8846, -2.4127, -1.6828, -1.2814,  1.7914,  2.1196],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0051, -1.5197,  0.6774, -1.7398,  0.2407,  1.0048,  0.8445,  0.1916,\n",
      "         1.0595,  1.1248,  0.7201, -0.5876, -1.2478, -2.2887,  0.2250, -0.1629,\n",
      "        -1.1293,  0.7171, -0.7444, -1.0721, -0.9102,  1.5980,  1.4024, -1.6281,\n",
      "        -1.8826, -1.2612,  0.0038, -0.6228,  1.0079, -0.0078, -0.9738,  0.4781],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.7094, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0704,  1.3499,  1.0750,  1.0841,  2.0623,  2.1139, -2.1927,  1.1481,\n",
      "        -1.0431, -1.2977, -1.1833,  1.2412,  1.1929, -1.4866, -1.4432,  1.3949,\n",
      "        -1.4935, -1.7358, -2.7225, -1.0088,  1.5500, -1.5198, -1.9005,  1.8931,\n",
      "         1.3212, -1.8658, -1.6415,  1.8367,  2.7111, -1.5633,  1.2122, -1.1909],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.2839,  0.1811,  1.5884, -1.0340, -0.7211,  0.1650, -1.6640,  1.9336,\n",
      "         0.3590, -1.4205, -0.8559, -0.4890,  0.7133, -1.6985, -1.5485,  0.1561,\n",
      "        -1.8371,  0.6073,  0.1238, -1.6557,  1.5299, -1.7821, -0.3599,  1.2762,\n",
      "         0.7414, -1.5685, -1.4562,  0.1668,  1.3782, -1.4332,  1.0599, -1.6665],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1644, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.4175,  3.0444, -1.6118, -1.8837,  1.0970, -1.9909,  1.8031, -1.3077,\n",
      "         1.6818,  1.0349, -3.1375, -1.2973, -1.9260, -1.3149,  1.4775, -2.0666,\n",
      "         1.5491, -2.0875,  1.5297, -1.3870,  1.7077, -2.0000, -1.5282,  1.2418,\n",
      "        -2.0506,  1.4651,  1.2701, -1.8837, -1.7472,  2.7651, -1.3809, -3.5425],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0486,  1.0946,  0.0725, -1.5633, -0.2636, -1.0398,  0.3524, -1.1702,\n",
      "         1.3772, -0.1138, -1.8422, -1.2988, -1.2024, -0.0218,  0.0105, -0.6549,\n",
      "         0.0800, -1.6440,  3.1972, -0.0869,  0.3519,  0.0738,  0.4646, -0.1023,\n",
      "        -1.6628,  0.0312, -0.2028, -1.9550, -1.5293,  1.1122,  0.9970, -1.7659],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.5810, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.7816, -2.2605, -1.1211,  1.6571, -1.1694,  1.5648,  2.0209, -1.0870,\n",
      "         2.1047,  1.6631, -1.8819, -1.9778, -2.0275, -2.1741, -2.6924, -2.2301,\n",
      "        -2.1122, -2.4595, -1.8063, -1.5850, -2.1155,  1.5850,  2.2885, -1.5242,\n",
      "         1.1844, -3.3424, -1.5902,  3.4150, -1.8198, -1.2756, -2.4909, -3.0875],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.5171,  0.0676,  0.2402,  1.2150, -1.5999,  0.5200,  2.3296, -1.4152,\n",
      "         1.9681,  1.3755, -1.4239, -0.4340, -1.0303, -0.9357, -1.6675, -0.9844,\n",
      "         0.5975, -1.4460,  1.0834, -1.2526, -1.7314, -1.0972,  1.5072, -1.5067,\n",
      "        -1.1173, -1.1511, -0.1927,  1.9322, -1.7991, -1.3470, -1.5414,  0.4402],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 38 Predict 1115 zeros 568 ones, one bias 0.337493\n",
      "train loss: 2.1450831700542623 dev loss: 1.328785889351531\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.6210, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1267,  1.0841, -1.9852, -1.6229, -2.5850,  2.1252, -1.1973, -1.2479,\n",
      "         1.3683, -2.3738,  3.1831, -1.0100, -1.3185, -1.9376, -1.7923, -1.6280,\n",
      "        -2.8290,  2.8821, -1.8074, -2.0478, -1.8063,  2.0099, -2.6963, -4.7279,\n",
      "        -2.4594, -3.0298,  1.1278, -2.4010,  3.1075,  2.7798, -3.2854,  1.5606],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9875, -0.6579, -0.1940, -1.1444, -1.6678,  0.7230,  1.9993, -0.7199,\n",
      "         0.9473, -1.7703,  2.0513, -1.7941,  0.3381, -1.8233, -1.7817, -1.1247,\n",
      "        -1.8600,  0.6262, -0.7252, -1.4145, -1.4683,  1.4842, -1.6758, -1.5989,\n",
      "        -1.5711, -1.8002, -0.6818, -1.5813,  1.9152,  0.6938, -1.0142, -0.8945],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.4262, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7737, -1.2801, -1.2682, -2.8832,  1.6712, -3.1699,  2.9875,  2.0000,\n",
      "         1.5960,  1.5850, -2.1234,  1.2357, -2.9696, -1.6696,  2.6567, -1.1864,\n",
      "         1.3986,  2.0985, -1.4644, -2.0369, -2.4595, -2.9386,  1.4150,  1.0286,\n",
      "        -2.5620,  1.7004,  2.3661, -1.6696,  1.3125,  1.1838,  1.8230, -1.2955],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.8296,  0.5148, -1.3966, -1.4875, -1.2605, -1.5115,  0.8174,  0.2089,\n",
      "         1.5018,  0.2564, -0.7333, -0.3658,  0.9556, -1.7849,  1.2082, -1.5506,\n",
      "         0.4750,  1.5005, -1.7596, -1.3662, -1.5418, -0.9988,  0.1632,  0.1797,\n",
      "        -2.0244,  1.2326,  1.1503, -0.7819,  0.3612,  0.3558,  1.0664, -0.9474],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.7092, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6845, -3.2525, -2.3003,  1.8467,  1.3785, -1.3138, -1.8924, -1.3923,\n",
      "        -1.4055, -2.8154,  1.3943, -1.9386,  1.3119, -1.0522, -1.0875,  1.3219,\n",
      "        -1.3219,  1.0446, -1.2851, -2.0976,  1.4038, -2.4285, -2.1520, -1.1864,\n",
      "        -3.8073, -1.7004, -1.5850,  2.3219,  1.5220, -2.9500, -1.5850,  2.0000],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1455, -2.2101, -1.7900,  1.2629, -0.5398, -1.4328, -1.2040, -1.7579,\n",
      "        -1.4570, -2.2060, -0.3941,  0.6435,  0.0052,  0.2363, -1.3614, -0.1637,\n",
      "        -0.2862, -0.2091, -1.8557, -1.3427, -0.0810, -1.7007, -1.2618, -0.9603,\n",
      "        -2.5218,  0.8315,  1.0967,  1.0722,  0.8489, -1.4776, -1.6697,  1.6680],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.4006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4137, -1.4372, -3.3575, -1.7045, -1.1048, -1.4763,  1.2977,  3.4525,\n",
      "         1.2977,  1.7061, -2.2301, -4.5850, -1.5850, -2.8157, -1.4044,  2.0940,\n",
      "        -1.5850,  1.3196, -1.2064, -2.8073, -1.5850, -2.7380, -2.2199, -3.0119,\n",
      "         1.1555, -2.0920, -1.6010,  1.0180,  1.0767, -1.2044, -2.7896, -1.1726],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1781, -1.7412, -1.7537, -0.3491, -1.8965, -1.9914, -0.2946,  1.7145,\n",
      "        -1.1210,  0.1879, -0.3393, -1.3478, -1.3300, -1.9896,  0.4594,  1.0876,\n",
      "        -1.2524,  1.2757, -1.3549,  0.1750,  0.5028, -2.7166, -0.9820, -1.9789,\n",
      "        -0.8552, -1.8136, -1.8409, -1.0788,  1.1083, -2.2996, -1.9753, -1.0099],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.3962, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4894, -1.0311, -1.5850, -2.1115,  1.6631,  1.1999, -2.3219,  2.6323,\n",
      "        -2.1727,  1.1699, -1.0536, -1.1726, -1.2665, -1.3923,  1.8122,  1.2496,\n",
      "         1.2224,  2.9542, -1.4044,  1.4630, -2.2598,  1.7599, -1.9635, -1.3046,\n",
      "         1.5784,  2.7655, -1.8458, -2.3833,  1.6818, -2.0275, -1.2630, -1.2479],\n",
      "       device='cuda:0')\n",
      "tensor([-2.2482, -1.7485, -1.8378, -1.0180,  1.4651, -2.0104,  0.1284, -1.9612,\n",
      "        -1.1271,  1.0690, -2.5567, -0.1484, -2.3154, -0.7879,  0.8844, -0.7727,\n",
      "        -0.0760,  0.7250, -1.3588,  0.1148, -1.5830,  0.3940, -1.2007, -1.0228,\n",
      "         1.6059, -1.0069, -1.3161, -1.5715, -1.7128, -1.7858, -1.7791, -1.8103],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.9731, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8561, -2.6924, -1.5850, -2.4594,  2.8073,  2.1043, -1.4296, -1.0562,\n",
      "         1.0912, -2.0506,  2.1865,  3.0255, -1.9260, -1.5009, -1.6717,  1.1690,\n",
      "         1.5195,  1.4105,  1.5850, -2.7808, -1.0393, -1.3138,  1.8403,  1.8705,\n",
      "         1.1988, -2.3833,  1.2167, -2.3061, -1.3765,  1.2988,  1.3332, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9608, -1.8056, -0.9948,  0.4425, -1.7396,  1.1317,  1.3715, -1.5157,\n",
      "        -1.6241, -1.7422,  0.6314, -1.1668, -1.2225, -1.5523, -1.7423,  0.5273,\n",
      "         2.8931,  1.7347,  0.4944, -1.5457, -0.9741, -0.2384,  1.1679,  3.3684,\n",
      "        -1.6278,  0.5200, -1.1748, -1.8684, -0.6690, -0.6142,  1.5886, -0.2903],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 39 Predict 984 zeros 699 ones, one bias 0.415330\n",
      "train loss: 2.211722958989504 dev loss: 1.4120532258644762\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.1114, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5198,  1.7800, -1.1703, -1.1081, -1.9260,  2.6586,  3.2721, -1.8480,\n",
      "         1.8522,  1.0122, -1.9778,  3.3817,  1.0750,  1.2559, -2.7225,  1.3219,\n",
      "        -1.4150, -2.0546, -1.6265,  1.2390, -2.0875,  3.4175, -2.0287, -2.6739,\n",
      "        -2.0976,  1.1375,  1.0780, -1.6787, -1.7609, -1.3772, -1.3755,  1.8496],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7426,  1.3193, -0.0440, -1.6802, -1.4504,  0.1077,  1.6091,  0.7494,\n",
      "         1.5360,  1.3923,  0.3299,  2.0553,  1.8996,  1.2601, -1.9690,  0.9138,\n",
      "        -0.1971, -1.5755, -0.5774,  1.0231, -1.7128,  0.8695, -1.7750, -0.1415,\n",
      "         0.3517,  1.8086, -0.6911, -0.3696, -2.1468, -1.7834, -1.6172,  0.6145],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.1399, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1844, -1.0091,  2.0000,  1.6571, -1.6265,  2.0655, -1.5502, -1.4706,\n",
      "         2.4328, -1.7923, -1.1520,  1.1537, -1.0308, -1.2630,  1.2837, -1.1726,\n",
      "         1.0608,  1.6067, -1.0869,  1.0592,  2.2119, -1.1844, -1.3105, -1.9260,\n",
      "        -2.9798,  2.4132, -2.0976,  2.2480, -1.7081, -1.1444, -1.3185,  1.6491],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9250, -2.0682, -0.4085,  1.4179,  0.7538,  1.4482, -0.9376, -1.5443,\n",
      "         1.4029, -1.4651, -1.4332,  0.1253, -0.8262, -0.2942,  1.6849,  0.1822,\n",
      "         0.4255,  0.5712, -1.0413,  1.1058, -0.0692, -1.5952, -1.2894,  0.8952,\n",
      "         0.2894,  0.1083, -1.1046,  0.3749, -2.1294, -1.1791, -0.3762,  0.0802],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.7783, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3046, -1.7662,  3.1699, -1.3179,  3.4150,  1.5003,  1.8004, -1.1375,\n",
      "        -1.0766, -1.6696, -2.7004, -1.1656, -1.6828,  2.6553,  1.2518,  3.5850,\n",
      "        -3.1375,  2.0987,  1.0669, -3.1509, -2.2605, -2.9696,  1.0794, -2.6546,\n",
      "        -1.0766,  1.2518,  2.0000,  2.2869, -2.0444, -1.3745, -2.4457, -1.3179],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.8965, -1.1569,  1.8724, -1.5431,  2.2170,  1.2544,  1.6474, -0.8258,\n",
      "        -0.6995, -1.6098, -1.2906, -1.5991,  0.9839,  0.0426,  0.2266,  0.8604,\n",
      "         1.1820,  1.4653, -0.9033, -1.5343, -1.5329, -1.0957, -1.5359, -1.4627,\n",
      "        -1.3603,  1.1345,  1.5909,  0.9521, -1.6914, -1.5627, -1.5528, -1.6470],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.9455, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.7603,  1.4968,  1.5596,  2.4150, -1.6510,  1.4775,  1.3479, -1.7125,\n",
      "        -2.8154, -1.8130, -2.9087, -1.1176, -1.8313,  2.3219, -2.3219,  2.6716,\n",
      "        -2.0351,  1.4450, -2.6623, -1.2811, -1.3219, -2.4594,  1.3089, -1.3077,\n",
      "        -1.6008, -1.0305,  1.1999,  2.4328, -3.5034, -2.8524, -3.1509, -1.8945],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6602e+00,  1.2781e+00, -1.0318e+00,  1.0697e+00, -1.1878e+00,\n",
      "        -8.6304e-01, -7.4803e-01,  1.1737e-01, -1.9939e+00, -1.2062e+00,\n",
      "        -1.7588e+00, -1.7155e+00,  1.1551e-03,  1.1302e+00,  1.1875e+00,\n",
      "         1.4260e+00, -1.8600e+00,  9.4858e-01, -1.5092e+00, -1.4196e+00,\n",
      "        -6.7212e-01, -1.6008e+00, -1.5521e+00,  1.5038e+00, -5.0261e-01,\n",
      "        -8.0928e-01, -1.5039e+00,  2.7077e+00, -1.6891e+00, -1.2225e+00,\n",
      "        -1.7035e+00, -1.8150e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.9865, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5620, -1.1165, -1.6415, -1.0153, -1.3138, -2.9696,  1.7414, -1.9879,\n",
      "        -2.5103, -1.4711, -2.3923, -3.4594, -3.3219, -2.2816,  1.3219, -1.9279,\n",
      "         2.6630, -1.5730, -1.7912,  5.5814,  1.4307, -1.8539, -1.1234,  1.4450,\n",
      "        -1.0393, -2.3219, -1.8975, -1.0454,  1.1826,  2.1699, -1.8074,  1.9353],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5901, -1.3789, -2.2237, -1.5232, -0.3994, -1.4276,  0.3189,  0.7994,\n",
      "        -1.7470, -1.9009, -1.7932, -1.6117, -1.1667,  0.6679,  0.6170,  0.0098,\n",
      "         1.6969, -1.0563, -1.6566,  1.4475,  1.9812, -1.4950, -1.2732,  0.4120,\n",
      "        -0.4170, -1.2932, -1.2306, -1.7919,  1.1659, -1.3468, -0.5742,  0.9372],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4551, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2988, -1.1970, -1.1296, -1.1844,  1.2712, -1.5850,  1.4532,  1.6201,\n",
      "         1.6582, -1.7004,  1.2022, -1.2713,  1.0464, -2.1309,  2.6439, -1.9095,\n",
      "         2.7612, -2.8832, -1.6916, -1.3167, -1.6854, -1.6255,  2.0888, -2.9696,\n",
      "        -1.8458,  1.1375, -1.2064, -1.9722,  1.3286,  1.0497, -1.8074,  1.0429],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7016, -1.6352, -1.6024, -1.5589,  0.0276, -1.4875,  0.7210, -0.1891,\n",
      "         1.3520, -0.1498,  0.9825, -1.5085, -1.0441, -1.7537, -1.2365, -1.6693,\n",
      "        -0.3889, -1.5041, -1.5210, -0.8330, -1.7537, -1.3198,  1.1136, -1.5183,\n",
      "        -0.0759,  0.1886, -2.1963, -1.8949, -1.5584, -1.6494, -1.8014, -0.9352],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 40 Predict 990 zeros 693 ones, one bias 0.411765\n",
      "train loss: 2.1908132128354882 dev loss: 1.3497885559939828\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.8006, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2278, -1.8649, -2.5324,  2.0000, -1.7848, -2.8073, -1.3745, -1.1676,\n",
      "        -1.7744,  1.5850,  1.0555,  4.2970,  1.1715, -4.4263,  3.4175, -1.2044,\n",
      "        -1.2022, -1.3103,  1.5028, -2.1375, -3.9069,  1.7287, -1.7046, -1.2044,\n",
      "         1.3219, -2.7307,  1.3683,  1.0153, -1.2737, -1.5850,  2.1139,  1.1405],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6297, -0.4861, -1.8094,  1.5706, -1.4778,  0.3138, -1.3155, -1.5533,\n",
      "         0.9053,  0.3310,  1.5109,  1.4717,  1.9150, -1.6936,  1.2177, -0.4357,\n",
      "        -1.7353, -1.0514, -0.5027, -1.6871, -0.4418,  0.5469, -0.7805, -1.2039,\n",
      "         1.2610, -1.6625,  1.1127,  0.8499,  1.0220, -1.2506,  1.1101,  0.9778],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.1443, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4413,  1.2977, -2.8073, -1.1726,  1.3773,  1.0511,  1.2316, -1.3530,\n",
      "         1.1481, -1.0343,  1.8160,  1.1375,  1.0431,  1.3593, -1.2955,  2.6800,\n",
      "         2.4270,  1.0906, -1.6781,  2.6786, -1.1319,  1.2546, -1.6220,  1.0620,\n",
      "         1.4026,  2.9341, -1.0716, -1.2857, -3.9069,  2.9519, -1.9260,  1.1020],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4112,  0.8026,  1.1695,  0.8723, -0.9132,  0.2329, -0.6542, -1.4263,\n",
      "         1.8978,  0.0304,  2.1531, -1.4964, -1.1144,  0.4378,  1.1663,  3.4069,\n",
      "         0.6864,  0.7494, -2.0470,  0.8496, -0.3040,  1.7161,  1.2072,  0.0116,\n",
      "        -0.6130,  0.4814, -1.8631, -1.2985, -1.2654,  2.0923, -0.2039,  1.2357],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(4.8592, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.7370,  1.2278, -1.4044,  5.2785, -2.3161,  3.4594, -1.9586, -1.9260,\n",
      "        -1.3278,  2.4966,  1.4557, -1.1960, -2.1838,  2.4270,  1.2977, -1.7685,\n",
      "        -2.8073,  1.4360,  1.6706,  1.3219, -2.4594,  3.1414, -1.1178,  1.9689,\n",
      "        -1.8330, -1.9260, -1.8232, -1.4372, -1.8464, -1.0358, -2.3833, -1.3964],\n",
      "       device='cuda:0')\n",
      "tensor([-4.7982e-01,  1.1208e+00, -7.0309e-01,  2.7602e-01, -1.1492e+00,\n",
      "         1.5296e+00, -1.5064e+00,  1.2340e+00, -1.8252e+00,  2.0408e+00,\n",
      "         1.2283e+00, -8.7756e-01, -1.7690e+00, -4.0937e-01, -1.6634e+00,\n",
      "         1.7733e+00, -1.2239e+00,  1.3629e+00, -6.1257e-01, -6.6534e-01,\n",
      "        -1.7142e+00,  3.8114e-01, -1.1343e-01,  5.8265e-01,  1.1384e+00,\n",
      "         1.5583e-01, -1.3593e+00, -1.4336e+00, -1.6179e+00, -7.2880e-01,\n",
      "        -2.0394e-03, -2.3804e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.6137, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6084,  1.7843, -2.4901, -1.1703, -1.0970,  1.5146, -4.7549,  1.5482,\n",
      "         1.8226,  3.0760, -1.0521,  1.3484,  1.1236, -1.7447, -1.9421, -1.2682,\n",
      "         3.1414, -3.4594,  2.7111,  1.2630, -1.2479,  2.1066,  1.3931, -1.2827,\n",
      "         3.5626, -2.9696, -1.8881, -1.8977,  1.1226,  1.2977,  1.6439, -1.1176],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0028, -1.5879, -1.5666,  0.4633, -0.2301,  0.9183, -0.0871,  1.1581,\n",
      "        -0.7460,  0.9123, -1.4155,  1.5490,  1.5014, -1.6383, -1.5435, -1.1025,\n",
      "         0.0197, -1.4515,  2.3382, -0.9546, -1.5589,  0.0392, -0.3244, -1.5641,\n",
      "         1.8069, -0.4139, -1.7070, -1.6099,  0.7646,  1.3216,  0.4524, -1.5721],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.3562, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1844, -1.6866,  1.1865,  1.3219, -1.7047, -1.2685, -2.0937, -1.2267,\n",
      "        -1.7935, -2.3219,  1.8171,  1.0115,  1.1871,  1.0846, -2.0000, -2.9475,\n",
      "        -1.3923, -2.1234, -3.4594, -2.0657,  1.2545,  1.1822,  1.5331,  3.1699,\n",
      "        -1.1487,  1.1555, -2.9696, -1.1624, -1.3219,  1.3119,  1.0452, -1.0815],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4676, -2.1929,  0.4033,  0.5783, -2.0397,  1.4326, -1.7045, -2.1026,\n",
      "        -1.5615,  1.2035, -0.1554, -0.6661,  2.6185, -0.3314, -1.3811, -1.8626,\n",
      "         0.0599,  0.5403, -2.0475,  0.4137, -1.1894, -0.0637,  1.2587, -1.4293,\n",
      "         0.0414,  1.2249, -1.1714,  0.2399, -1.4033, -0.3015,  1.7032, -1.0774],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2043, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0589,  2.7500, -1.9005, -1.0795, -1.8433, -1.1923,  1.0481,  1.7148,\n",
      "         1.4780, -1.3292, -1.9260, -1.2801, -1.0966, -1.2551,  1.5850, -1.5979,\n",
      "         1.6121, -1.0522,  1.2167,  1.8004,  1.2412, -1.9395, -1.5979, -2.4595,\n",
      "        -1.3219,  1.5850,  1.3069, -1.2224,  2.6051, -1.0028,  1.1481, -1.9746],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4488,  0.8771, -1.3817, -1.7436, -1.6530, -1.9451, -0.2199,  0.0833,\n",
      "         1.6467, -0.0638,  0.8859, -1.8910, -0.4206, -1.7213, -1.3943, -0.5915,\n",
      "         0.3070,  0.3348,  0.6808,  1.5459, -1.1376, -0.7684, -2.0690, -2.0277,\n",
      "         1.5510,  0.6389, -0.0278, -1.2427,  2.2669, -1.8142,  1.7136, -0.9772],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 41 Predict 1084 zeros 599 ones, one bias 0.355912\n",
      "train loss: 2.130492767828391 dev loss: 1.3860469279297756\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.0695, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0515, -3.8791,  1.7300,  1.6631, -1.1945, -1.0827, -1.1220, -1.5850,\n",
      "        -1.2300, -1.0310, -1.5979, -1.1726, -1.3040,  2.4328, -1.8804, -1.3278,\n",
      "        -1.9713, -1.1155, -1.1314, -1.9542,  1.7499,  3.1414,  1.4475,  1.5850,\n",
      "        -1.5025, -1.5968,  1.9069,  1.6323, -1.9386,  5.2785,  1.0654, -2.0251],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0700, -1.5797, -0.0853,  1.1603,  0.1113, -2.1493,  0.8636, -1.5064,\n",
      "         1.5383,  0.4331, -1.7974, -1.2238, -1.7591,  0.3817, -0.7289, -1.7071,\n",
      "        -0.4111, -1.4396, -1.5806, -0.1948,  1.0041,  0.0950,  1.5267, -0.8726,\n",
      "         0.9505, -1.6700,  1.8251,  0.6910, -0.8535,  0.9098, -0.4118, -2.0579],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.8130, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1489, -1.2890, -1.1203, -1.5354, -1.0589,  1.4775, -2.3526,  1.1203,\n",
      "        -1.0356, -2.0882,  2.1865,  3.1414, -1.4649,  2.4156, -1.3163, -2.3801,\n",
      "         1.5606, -2.3481, -1.5850, -1.5850,  1.6057,  1.3419, -1.9260, -1.6649,\n",
      "        -1.7081, -2.3219, -2.1091, -1.9704, -2.4586, -1.0875, -2.0632,  1.0247],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3533,  0.0668,  0.0227, -1.1419, -1.0571,  1.5099, -0.0827,  1.3996,\n",
      "         0.1338, -1.6987,  1.3689,  0.4672, -2.0255,  0.7847, -1.3865, -1.6856,\n",
      "        -1.7456, -1.9013, -0.5797, -1.2964,  0.0662,  0.9265, -0.4722, -1.9792,\n",
      "        -1.5509, -0.6240,  0.0994, -1.4602, -1.7281, -1.8009, -1.1214,  1.1330],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(0.9891, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1975, -1.8255, -2.7004, -1.2419, -1.4081, -3.2613,  1.0437,  1.0054,\n",
      "         1.8122,  2.1365,  2.3219, -2.3978, -1.8745, -1.3878, -1.1273,  1.9125,\n",
      "         1.0592,  1.3269, -2.0478,  1.3219, -1.4498,  1.5003, -1.8945, -1.0583,\n",
      "        -1.1815,  2.4270,  1.5110,  2.3835,  1.3219,  1.0592,  1.4532,  1.0888],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1281, -1.1214, -1.2509, -1.5868, -1.0550, -1.8703,  1.3020,  0.3940,\n",
      "         0.9602,  1.2433,  0.4886, -1.6879, -1.5234, -0.0682, -0.8979,  1.5887,\n",
      "        -0.0833,  1.3684, -1.9841,  0.3301, -1.2437,  0.4460, -1.7846, -1.7161,\n",
      "         1.7370,  0.9138,  0.4465,  1.6630,  0.9575,  0.2525,  1.0742,  0.9015],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.6130, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.0508, -3.5850, -1.2194, -1.6924, -1.8251,  1.4122, -1.6496, -2.7004,\n",
      "        -2.0410,  1.3119, -1.1676, -1.9850,  1.0992,  1.4950,  1.8260, -1.6353,\n",
      "        -1.4498,  1.0545, -2.8524,  1.1475, -1.6108, -1.1072, -3.0704,  1.5193,\n",
      "         1.0171, -3.7603,  1.6379,  1.5850, -1.3923, -1.5671, -1.6694,  1.2776],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3875, -0.9279, -1.5642, -1.6622, -1.3258,  1.2146, -1.6881, -1.2164,\n",
      "        -0.6607,  1.3698, -1.8016, -0.5721, -0.9649,  1.9589,  1.3811,  1.0524,\n",
      "        -1.7781,  2.2525,  0.0521,  1.4577, -1.4439,  0.0465, -0.9654,  0.9403,\n",
      "         1.4598, -1.8017, -1.1080,  1.1165, -1.1045, -1.4435, -0.3632,  0.9067],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.8012, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5979, -1.3785,  1.4651, -2.0275, -1.9260,  1.1375, -1.1535, -1.6675,\n",
      "        -2.5158, -1.8232,  1.0511, -2.0630, -1.1737, -1.3219, -1.2778,  1.7701,\n",
      "        -2.0369, -3.1193, -1.7405, -1.1434,  1.5713, -2.6658, -1.5452, -1.0815,\n",
      "        -3.4215, -1.6108, -1.2397,  1.3968,  1.2350, -1.7370, -2.4793,  2.1139],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7499,  0.8677, -1.3511, -1.4400, -1.1933, -1.1224, -1.5514, -1.4958,\n",
      "        -1.6068, -1.6394,  1.2935, -0.3368, -1.8595,  0.2283, -1.2642,  1.3514,\n",
      "        -1.7207, -1.4786,  0.8821, -1.6327,  0.9664, -0.3449,  0.6650, -1.4932,\n",
      "        -1.5592, -1.2246, -1.1955,  0.6156,  1.3150, -1.0395, -1.6207,  1.0541],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.3429, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6781,  1.6446, -2.9386, -1.4542, -1.3219,  2.6825, -1.5113,  1.8931,\n",
      "        -2.0000,  2.0000,  1.3468,  2.5361, -1.2058, -1.9260, -1.9814, -1.4594,\n",
      "        -1.0041, -1.7662,  2.1865,  2.5850, -3.2854, -1.4454, -1.1824,  2.1753,\n",
      "         1.1929,  1.1025, -3.9362, -1.4935,  1.1293, -2.3842,  1.2282,  1.3551],\n",
      "       device='cuda:0')\n",
      "tensor([-2.6199e+00, -9.8959e-01, -1.4509e+00, -1.5023e+00,  1.7034e-01,\n",
      "         1.5940e+00, -1.7614e+00, -4.3020e-01,  8.4806e-01,  1.3119e+00,\n",
      "         8.6887e-01,  1.9562e+00, -1.8589e-03,  8.9177e-01, -1.8140e+00,\n",
      "        -1.4955e+00,  1.6179e+00, -1.2510e+00,  1.2283e+00, -4.0372e-01,\n",
      "        -1.0183e+00, -1.7202e-01, -1.0888e+00,  1.3641e+00,  1.1632e+00,\n",
      "         5.6359e-01, -1.1517e+00, -1.2723e+00, -1.7564e+00,  8.1354e-01,\n",
      "        -6.5940e-01,  5.8395e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 42 Predict 998 zeros 685 ones, one bias 0.407011\n",
      "train loss: 2.200034557347461 dev loss: 1.4291470923074863\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.7347, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1929,  1.7843, -2.8073, -1.9260, -1.5502, -1.6107, -2.9696,  1.1947,\n",
      "        -1.4894, -2.8073, -1.1375,  1.0841,  1.8399,  1.6594, -3.2525,  1.2313,\n",
      "        -1.9260,  1.8171, -3.9362, -1.3450, -1.0999, -1.0774, -1.9421, -1.5271,\n",
      "        -2.3801, -1.4047, -1.6889,  1.8592, -1.7744,  1.2316, -1.2547,  1.5624],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9533,  0.3788,  0.5696, -0.5974, -0.0128, -1.4501, -0.4459,  0.9199,\n",
      "        -1.9793,  0.3116,  0.9008,  1.2996, -0.2342,  1.1609, -1.2778,  0.3956,\n",
      "        -1.1692,  0.7880, -1.4257, -1.4481, -1.8325, -0.6273, -1.6943, -0.1000,\n",
      "        -1.6829, -0.2733, -1.7096,  0.6673, -0.1977,  1.3077, -1.6346, -0.2979],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.6606, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.3173,  2.2718,  1.2403, -1.5242, -1.6338, -1.5394, -1.5850, -1.5032,\n",
      "        -1.6044,  3.4525, -2.6589, -1.2034, -1.1211,  1.3219,  1.4594,  1.5850,\n",
      "         1.5090, -2.0828, -2.3833,  1.1635, -1.0308,  3.1075,  1.8160, -1.5549,\n",
      "         1.1219, -2.3708,  1.9608,  1.5850, -1.9260,  2.4279,  2.0000, -1.9778],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.9939,  1.2801, -0.3041, -1.2821, -0.7638,  0.7926,  0.6158,  0.6326,\n",
      "         0.2022,  0.5478, -1.8677, -1.8764, -1.2506,  0.7755,  0.4186,  1.0801,\n",
      "        -1.5254, -2.0554,  0.8868,  0.7429,  1.0003,  1.1161,  1.3224, -1.4458,\n",
      "        -1.1711,  0.5053, -0.9682,  0.5271,  0.9607,  1.1532,  1.0596,  0.3041],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.6932, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1969, -1.8074, -2.8182,  1.3332, -1.3450,  1.4493, -2.8651,  1.7914,\n",
      "         2.2086,  2.0195,  1.3711, -1.9069, -1.1630, -2.2301, -1.3111,  2.0747,\n",
      "        -1.2682, -3.3709, -1.1615, -1.2514,  1.3219, -2.0937,  1.2224, -1.0995,\n",
      "        -1.1625,  1.3300,  1.1255, -1.4150, -1.1726, -2.8290, -1.5850,  2.0079],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6127, -1.3462,  0.6338,  0.5788,  0.8680, -0.8681, -1.4408, -1.5680,\n",
      "         1.1766,  1.1890,  1.1043, -0.2488, -1.2394, -0.0590, -1.7184,  1.5594,\n",
      "        -0.9255, -1.6413, -0.8245, -1.7673,  0.4240, -1.5138,  0.9418,  0.4983,\n",
      "        -1.5678, -1.6607, -0.3595,  1.9052, -1.1976, -1.8773, -1.0896,  0.9443],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.7110, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1069,  1.3949,  1.0234, -1.5178, -1.0070, -1.4094, -1.8747,  1.8235,\n",
      "         1.5408, -1.2630, -1.0999, -2.4432, -1.1937, -1.0980,  1.1602,  1.5332,\n",
      "        -1.8228,  1.4374,  1.0109,  1.9267, -2.6262, -1.9778, -2.2783,  1.4475,\n",
      "        -1.1979, -1.5309, -1.9824, -2.0200, -1.8572, -1.0091, -2.8073, -1.9635],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2239, -1.2219, -0.7540, -0.6290, -0.4397, -0.1093, -2.0482,  0.0034,\n",
      "         1.4846,  1.2252, -1.6151, -1.7005, -1.2657, -0.9941,  1.6036,  0.6631,\n",
      "        -1.8442,  1.1298, -0.0234,  2.0344,  0.6474, -1.8826, -1.3494,  1.1458,\n",
      "        -1.9876,  0.2235, -1.7114, -1.7799,  0.4184, -1.8809, -1.6915, -1.5025],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.9749, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1722, -1.5282, -1.3624, -1.7001, -1.7843,  2.4150, -1.1535,  1.8460,\n",
      "         3.3692,  1.7382, -3.3628,  1.3137,  1.7650, -4.6049, -2.0875, -1.8745,\n",
      "         1.6157,  2.3219,  1.8074, -2.0370,  1.3785, -1.3621,  1.1699, -1.2158,\n",
      "        -2.0995,  1.1962,  1.3968, -2.8024, -2.1727, -1.5178, -1.1631, -2.2378],\n",
      "       device='cuda:0')\n",
      "tensor([-0.2560, -0.5695, -1.6853, -1.4371, -1.2449,  1.1532,  0.8464,  2.3375,\n",
      "         1.9814,  0.7397, -1.6634,  1.1794,  0.5554, -1.0263, -1.8011, -1.2394,\n",
      "        -1.0588, -0.7005,  0.3584, -1.7756, -1.5569, -1.4127,  1.2064, -0.3645,\n",
      "        -1.7564, -1.5706,  1.2928, -1.8341,  0.8113,  1.0508, -1.5869, -1.6707],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.3436, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.0000, -1.2126,  1.3219,  1.1481, -1.0153, -3.3067, -4.2479, -1.5850,\n",
      "        -2.0000,  1.3785, -1.2817, -1.2682,  1.4382, -1.0700,  1.3849, -1.6044,\n",
      "         1.8074,  1.0902, -1.3624, -1.1876, -1.0863,  2.2750, -3.1699,  1.0841,\n",
      "        -1.3870, -3.1699, -1.9586, -1.3923,  1.6571, -1.9260, -1.4236,  1.1024],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7156, -0.5924, -0.4207,  0.9659, -1.5974, -1.0083, -1.5325, -0.1942,\n",
      "         1.1996, -1.3683,  0.8564, -1.0134,  1.8714, -1.4857, -1.5043,  0.7739,\n",
      "        -0.7884, -1.1283,  0.5276, -1.4433, -1.0969,  1.1852, -1.0559,  0.8973,\n",
      "         1.1263, -1.1542, -1.4714, -1.1749,  0.8498, -0.2923, -1.1158, -1.1839],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 43 Predict 1076 zeros 607 ones, one bias 0.360665\n",
      "train loss: 2.1196170740922806 dev loss: 1.2023910530119832\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.9242, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9383, -1.5151,  2.8826, -1.2088, -1.0738,  1.2633, -1.8074, -1.0062,\n",
      "        -1.9260, -1.8228,  3.3923, -1.1535, -2.3061,  2.5025,  1.4981,  1.7605,\n",
      "         1.8522,  1.3219, -3.1699, -1.9704, -1.9069,  1.3219,  2.7143,  1.7800,\n",
      "         3.5850, -1.0064, -1.5633, -1.5850,  1.5850, -2.7004,  1.3785, -1.0864],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.6965, -1.6500,  0.9794, -1.7921,  0.3335,  0.5783, -2.1256,  1.0423,\n",
      "        -0.9048, -1.6204,  0.7573, -1.4298, -1.7111, -0.9066,  0.0042,  0.0440,\n",
      "         1.5212,  1.4476, -0.5014, -1.5096, -0.5471,  1.0337,  0.9867,  0.3369,\n",
      "         0.7636, -1.8583, -1.5157, -0.6664,  0.4851, -1.0245,  0.0071,  0.6387],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.3835, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3555, -2.0875,  1.3219, -2.5510, -2.2076,  1.7010, -3.5607,  2.0823,\n",
      "         1.2022,  1.0324,  1.7650,  1.5656, -2.2479, -1.6647, -1.8745, -1.9260,\n",
      "         2.0506,  2.3219, -1.4875,  1.7382, -2.2441,  1.9809, -1.1375, -2.1838,\n",
      "         2.3219, -2.0255,  1.2475,  1.7148, -1.6818, -2.1722,  1.8074, -1.0875],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5483,  0.4139,  0.9881, -1.6530, -0.5707,  1.4423, -1.7624,  1.1964,\n",
      "         0.9700, -0.1077,  1.0465, -1.8225, -1.7260, -1.3981, -0.4862, -0.0159,\n",
      "         1.8180, -2.0253, -1.5871,  0.7799, -1.8479, -1.0385, -1.3404, -2.0102,\n",
      "        -0.8396, -1.0331,  0.0558, -0.1526,  0.2020, -1.7983, -0.5458, -1.6164],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.2654, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4047, -2.1180, -2.0129,  1.5850,  1.4224,  1.7677, -1.5208, -1.1901,\n",
      "         1.2127, -1.5902,  3.0589,  1.3219,  1.2357,  1.3196,  1.3626, -2.9475,\n",
      "        -1.2126,  1.3550, -2.8073,  1.1201, -1.4372,  1.3814, -1.0827, -1.0780,\n",
      "        -1.4894, -1.9386, -1.0466, -1.3185,  2.5062, -3.5850,  2.2701,  1.8367],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0370, -1.4241,  0.7732,  1.1628, -1.1910, -1.2523, -0.6074, -1.8074,\n",
      "         0.8758, -1.1495,  2.3441, -0.4505, -0.7369, -0.4125, -1.1907, -1.7281,\n",
      "        -1.6823, -1.9457, -0.3420, -1.3116, -1.8501,  1.3607, -2.4481,  0.7090,\n",
      "        -2.2795, -0.2830, -2.1448,  0.7135,  2.0562, -1.2759, -0.2944,  0.3051],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.3451, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.2750,  1.6909, -1.3336, -1.3167, -1.3055, -1.9586, -1.9704, -3.3923,\n",
      "        -1.8572,  2.3219, -1.5406, -2.1741, -1.2663,  1.1926,  1.3219,  1.5596,\n",
      "        -1.9395, -1.2058, -1.1375,  1.4527, -1.8804, -1.5850,  1.0772, -3.0000,\n",
      "         1.2630, -1.1679,  1.1155, -1.8686, -2.6439, -3.1530, -2.0516,  1.1699],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3719,  0.9917,  0.1347, -1.1067,  0.8723, -1.4726, -0.3973, -0.3872,\n",
      "         0.0535,  0.3230, -1.2279, -0.8292, -1.6936,  1.3376,  0.4601,  0.4182,\n",
      "         1.2641, -0.8885, -0.8730,  1.8703, -0.9497, -0.2108,  0.1074, -1.9067,\n",
      "         1.4880,  0.9229,  0.3368, -1.5927, -1.2859, -0.6869, -1.8672, -1.3564],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.6923, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3708, -1.3752, -1.8527, -1.0617, -1.9260, -1.4466, -1.3656, -2.2895,\n",
      "        -1.9492, -2.3575,  2.3115, -1.3806, -2.4908, -2.5523,  1.5699, -2.1180,\n",
      "         1.1817, -1.1147,  1.5953,  1.1779,  2.2327,  1.4532, -1.5979, -1.3400,\n",
      "        -1.0773, -2.1770, -1.3838,  1.1293,  2.2979, -3.3219,  1.1475,  1.6848],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1087, -1.4016, -1.1353, -1.2949,  1.1662, -1.1792, -1.7695, -1.7381,\n",
      "        -1.5009, -0.7394,  0.5046,  0.5372, -1.7957, -2.0275, -0.4084, -0.2012,\n",
      "        -1.1942, -0.9311, -1.3563,  0.1290,  0.1101,  0.5702, -1.6323, -1.0697,\n",
      "        -1.6392, -1.6653, -1.7457, -0.9445,  0.3079, -1.5116,  0.4952, -0.9760],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.5100, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8389, -2.3481, -1.8220,  1.8745, -2.9386,  1.0288, -1.1564, -2.3219,\n",
      "        -1.2090,  1.3577,  2.5698, -1.2557, -1.3310, -1.3576, -1.9260, -2.9087,\n",
      "        -1.3017, -1.9069,  1.6719, -1.7923, -1.0870, -1.0928, -1.5829, -2.6845,\n",
      "         1.5850, -1.4451, -1.4499, -1.7144, -2.0082, -2.3280,  2.1047, -1.5407],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2365, -1.9033, -1.7726,  0.5013, -1.6772, -1.4300, -0.8178, -0.6137,\n",
      "         1.2171,  1.2086,  1.8286, -1.0592,  1.3677,  0.1072, -0.5559, -1.7952,\n",
      "        -0.9509, -0.1812,  1.0698, -1.7971, -1.0502, -0.9303, -0.7308, -1.7299,\n",
      "        -0.2667, -0.3656, -1.0927, -0.9914, -1.7052, -1.0749,  1.7768,  0.5600],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 44 Predict 1124 zeros 559 ones, one bias 0.332145\n",
      "train loss: 2.1357043326299165 dev loss: 1.3918254612316197\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.3831, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1214, -1.4533, -2.2492, -1.8504, -3.0609, -2.0937,  1.3388, -2.6521,\n",
      "         1.2745,  1.1555,  2.0000, -1.8313,  1.6323,  2.3998, -1.8220, -1.6924,\n",
      "         1.5324, -1.1538,  1.2350, -2.6640, -3.4311, -2.6620,  1.3196, -1.8837,\n",
      "         1.4322, -2.4594, -3.3219, -2.2569, -1.0800, -1.8922,  1.1699,  1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0989, -0.5897, -1.5479, -1.5598, -1.9054, -1.4101,  1.0197, -1.5725,\n",
      "         1.2670,  0.1899, -0.3131, -1.0455, -0.1940,  1.3781, -1.5358, -1.5834,\n",
      "         1.0959, -1.0744, -0.5760, -1.9928, -1.5535, -1.6173,  1.1112, -1.6824,\n",
      "        -1.7279, -1.0994,  0.8647, -1.7611, -1.0112, -2.0321,  0.8331, -1.4906],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.4744, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4922,  1.6571, -1.9947, -1.1726, -2.7225, -2.9696,  1.3125,  1.2167,\n",
      "         1.7914, -1.1147,  2.1139,  2.0823,  2.5850, -1.5194, -2.4595, -2.5850,\n",
      "         2.1694, -1.6080, -1.0327,  1.0481, -2.5510, -1.4795,  2.7176, -1.2419,\n",
      "        -1.6347,  1.9403,  1.4888,  2.0000, -2.2311,  2.1915, -1.1155, -1.7011],\n",
      "       device='cuda:0')\n",
      "tensor([-2.2242,  0.7754, -1.6554, -0.4633, -1.7460,  0.4087, -0.5649,  0.5989,\n",
      "        -0.4287, -0.3422, -0.0982,  1.0088, -0.5457, -1.0906, -1.6376, -1.0455,\n",
      "         1.0930, -1.5509, -2.0493, -0.8619, -1.7777, -1.2737,  1.7827, -1.1625,\n",
      "        -1.6146, -0.6993,  0.1884,  0.1680, -1.9577,  1.4269,  0.2362, -1.5520],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.9855, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0943, -1.5633, -2.7065,  1.5541, -1.5574, -1.8313,  2.0000, -1.2814,\n",
      "        -2.0410, -1.3823, -2.7370, -2.6640, -1.0371, -1.9778, -3.1375, -1.0444,\n",
      "         3.5744,  1.8705,  1.0047, -1.1598,  2.1047,  1.3468,  1.2376, -1.5850,\n",
      "        -2.1722, -1.8198, -1.1165, -1.4159,  2.0655,  1.2022,  2.1252, -1.5564],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1481, -1.7364, -1.7230, -1.1513, -1.4850, -0.2126,  1.5059, -0.1775,\n",
      "        -1.2512, -1.0923, -1.3778, -1.6973, -1.5717, -0.3895,  0.8438, -0.7310,\n",
      "         1.3620,  1.0828, -0.2548, -1.1266,  1.3095,  0.7373,  2.4164, -1.7492,\n",
      "        -1.6448, -2.0687, -0.6306, -1.2808,  1.2183,  0.4748,  0.7179,  0.3495],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.2595, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4058,  1.1453, -1.1478, -1.7309, -1.9260, -2.0369, -1.1823, -1.2713,\n",
      "        -1.3219, -1.5376,  3.2720, -1.1621, -1.1211,  1.0841,  1.6848, -1.2737,\n",
      "        -1.8561, -1.8571, -1.1970, -2.1116, -1.7309, -1.5850, -1.1993, -1.2333,\n",
      "        -1.6439,  1.0841, -2.0096, -2.0451,  2.3692, -1.2682, -1.0999, -2.5931],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7781,  0.8649, -1.1448, -1.5447, -1.2671, -1.0714, -1.0845, -1.8491,\n",
      "        -1.0087,  0.2394,  0.7913, -0.3653,  0.7817,  0.5396,  1.2775,  1.2589,\n",
      "        -1.8044, -0.4382, -1.8577, -1.6816, -0.9677, -0.2098, -1.6802, -1.3246,\n",
      "        -0.9378,  1.0987, -1.2495, -1.6812, -0.2554, -1.1738, -1.1352, -1.4603],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.3848, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.6716, -1.3219, -1.2756,  1.5850,  1.1865, -1.0155, -1.1597, -1.7370,\n",
      "         1.4475, -3.3966,  1.5850, -1.8682, -2.8073, -1.5817,  2.3334, -1.8863,\n",
      "        -1.8190, -1.5407,  1.1483,  1.8226, -1.2682, -1.9260,  1.3219, -2.4594,\n",
      "        -1.3310, -1.3219, -1.1543,  1.6405, -2.1905, -1.9069, -1.8458, -1.6675],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.3487, -1.3688, -1.3061,  1.6209, -1.5682, -1.7355, -0.3762, -1.4922,\n",
      "        -1.0866, -1.3310,  0.7316, -1.6045, -1.1704, -1.7470, -1.1024, -1.2548,\n",
      "        -1.1772, -0.0166, -0.9100, -1.0152, -1.5338, -1.1401,  1.1412, -1.3200,\n",
      "         1.7068, -1.1222,  0.7699, -0.0754, -1.2203, -1.1232, -1.5966, -1.8033],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.3344, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8330, -1.2659, -2.0455,  1.3933, -1.5025,  1.2412, -1.1975,  1.3416,\n",
      "        -1.9005, -2.7482,  1.0841, -1.4256, -1.7845, -1.4354, -2.1299, -1.2486,\n",
      "         1.1135,  2.2926, -2.4595,  1.5713,  1.3196, -1.8680,  1.0067, -1.0051,\n",
      "        -1.8747, -1.5850,  1.1016, -1.1778, -1.1155,  2.1060, -2.0224,  1.6863],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8862, -0.3283, -1.9404,  1.2884,  1.4751, -1.5845, -0.0903, -0.4069,\n",
      "        -1.2455, -1.9965,  0.2594, -0.6188, -1.5467,  1.2444, -1.6850, -1.1089,\n",
      "        -1.4574,  0.7120, -1.5272, -0.2968, -0.6276, -1.1957,  0.4949, -1.1629,\n",
      "        -1.0520,  1.0866, -1.4057,  0.0122, -0.8442,  1.3008, -0.4652,  0.7708],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 45 Predict 1140 zeros 543 ones, one bias 0.322638\n",
      "train loss: 2.076282067279368 dev loss: 1.4100457846870174\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.6409, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3219, -2.6955,  2.7294, -1.0583, -1.9069,  1.2668, -1.5549, -1.7447,\n",
      "         1.4224,  1.7010, -1.9260, -1.1782, -2.0129, -1.2730,  1.3532, -1.8561,\n",
      "         1.8960,  1.9240,  2.6586,  2.4328, -1.1699, -1.2630, -1.0766, -1.1065,\n",
      "         1.6206,  2.5850,  1.4241,  1.8496,  1.1454, -1.1375, -1.5817, -1.0962],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4941, -1.7819,  0.9065, -1.4267, -0.7633,  0.2410,  1.2577, -1.7094,\n",
      "        -1.0339,  1.7481, -1.3949, -1.7400, -1.4640, -0.6672,  1.3703, -2.1464,\n",
      "        -0.8523, -1.1684,  1.2718,  0.8087, -0.6739,  0.9407, -2.0722, -1.0631,\n",
      "         1.4483, -0.8221,  1.0736, -0.5973, -0.1922, -0.8243, -2.0364, -1.2912],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.0840, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0618, -2.0995,  2.0646, -1.3785,  2.0000,  3.3173,  1.3344, -2.3219,\n",
      "         2.4156,  1.5850, -2.5850, -1.1543, -1.7935, -1.3105, -1.4780,  2.0888,\n",
      "        -2.8073,  1.2941, -2.7497,  1.5606,  1.5324, -2.3318,  1.2354, -1.1726,\n",
      "        -1.7843, -1.9260,  1.0841,  1.7914, -2.7198,  1.8960, -1.6084,  1.0189],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6891, -1.7504,  1.0656, -0.8764,  1.1886,  2.0171,  0.1937, -1.0628,\n",
      "         1.2299,  1.3732, -1.1792,  1.7702, -1.1180, -0.1780, -1.4873, -0.9820,\n",
      "        -1.2839,  0.7865, -1.7435, -1.7166,  0.9571, -1.7100, -1.2308, -1.0819,\n",
      "        -0.7290, -1.3114,  0.5945, -1.1867,  1.0824, -0.8014, -1.0309, -0.0412],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.8282, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0000, -1.1993, -1.4935,  1.5482, -1.5242, -1.5850,  5.2785, -1.8819,\n",
      "        -1.6280, -1.4594, -2.2076,  1.0171, -1.0088, -1.0766, -1.2116, -1.3745,\n",
      "         1.4775, -1.4695, -2.8524, -1.2481, -2.1905,  1.8644,  1.2022,  1.5564,\n",
      "         1.2955, -1.8841, -1.0363, -1.0962,  1.4970,  2.7651, -1.4795, -2.4595],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1371, -2.1550, -2.4331,  1.3148, -0.3458,  0.7434, -0.1794, -1.7024,\n",
      "        -0.6103, -1.3207, -1.4748,  0.6207, -1.9487, -1.9625, -1.8346, -1.1662,\n",
      "        -1.3334,  0.0420, -0.8465, -0.9859, -0.2297,  1.1535, -1.3317,  0.6338,\n",
      "         0.9542, -1.0161, -0.9381, -1.5117,  0.7438,  1.2248, -1.3008, -1.9885],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.3830, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4586,  1.4962,  1.8074, -1.8063,  2.3114, -1.6025, -1.5394,  2.8821,\n",
      "         1.5850,  1.1817, -1.0272, -1.2241,  1.0712, -1.8074,  1.5606,  2.2721,\n",
      "        -1.7662, -1.1676,  1.2745,  1.4555, -1.6781,  1.0912, -1.9069,  2.0379,\n",
      "        -1.8458, -1.3905, -2.0024, -1.4354, -1.3398, -1.9005, -2.4432, -1.8433],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7908, -0.1461,  0.1612, -0.9792,  2.0557, -0.5323, -1.2808,  1.1799,\n",
      "         1.3747, -0.0772, -1.5882, -1.3028,  1.4412, -1.4099, -1.6929,  1.1290,\n",
      "        -1.7017, -1.2757, -0.8575,  1.0753, -1.0723, -1.7144, -0.9295,  1.5913,\n",
      "        -0.8840, -1.6429, -2.0023, -0.4558, -0.6444, -1.7265, -1.9714, -1.9381],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.3264, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5523,  1.2538, -1.3655, -1.6492, -1.6181,  1.1481,  1.0846, -3.1699,\n",
      "        -2.3785,  1.3468,  1.3414, -1.6787,  1.1024, -1.5032, -1.7250, -2.3166,\n",
      "         2.2410, -2.8745, -1.5059,  2.2926, -1.5850,  1.6172, -1.2755,  1.0171,\n",
      "         1.4834,  2.0948,  1.0297, -1.0661, -1.8240, -1.0870, -2.6955, -2.6477],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9414, -1.1817, -0.7834, -0.7482, -1.0282,  0.0687, -0.6601, -0.2212,\n",
      "        -1.8411,  0.4395, -1.3062, -1.2448,  1.2920,  1.2101, -0.5125, -1.7556,\n",
      "         0.7587, -0.4614, -1.7782,  0.0746, -1.2227,  1.2565, -1.4389, -1.1568,\n",
      "         2.0780,  1.2889,  0.1231, -1.8458, -1.7888, -0.2726, -0.9253, -0.8042],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.1347, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2685, -1.3376,  1.4150, -2.0939, -1.1065,  3.7635,  1.3785, -2.0666,\n",
      "         1.9260, -1.0863,  1.2685,  1.3510, -1.8580, -1.1444, -1.6700,  1.8074,\n",
      "         1.0477, -1.2857, -1.3823, -1.0641, -3.9069,  1.2174, -1.4594, -1.9069,\n",
      "        -1.9492,  1.6848, -2.3626,  1.2022, -1.9778,  2.0033,  1.4527, -1.5243],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1444, -1.9857,  1.0746, -1.7243, -1.0610, -1.3097,  1.3676, -1.3457,\n",
      "         1.4413,  0.0106,  0.3622, -0.8204, -1.2719, -1.4851, -1.4756, -0.6729,\n",
      "         1.2749, -1.6773, -1.6668, -1.7170, -0.3437, -0.8401, -1.1926, -1.0818,\n",
      "        -1.6661, -0.2276, -0.4795,  0.4882, -0.2241, -0.0075,  1.4848,  0.0108],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 46 Predict 1162 zeros 521 ones, one bias 0.309566\n",
      "train loss: 2.08926064005907 dev loss: 1.5072668166759111\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.1429, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9746,  1.1772, -2.8755,  2.0195, -1.3818, -2.0000, -2.2761,  2.2993,\n",
      "         1.7370, -1.2682,  2.5062,  1.0826, -2.8073,  2.0589, -3.7248,  2.6567,\n",
      "        -2.4285,  1.8122, -1.1291,  1.4150, -1.0583, -1.9260, -1.9260, -1.6553,\n",
      "         1.5986, -1.2955, -1.2333, -2.1703,  2.2410,  4.3631, -2.6405,  1.9220],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6906,  2.2841, -2.0868, -1.0619, -1.6050, -0.4999, -1.7418,  2.2613,\n",
      "        -0.3335, -1.8777,  2.3399, -0.3629, -1.9128, -1.2788, -1.9984,  1.2717,\n",
      "        -2.0990,  0.7392,  1.1055,  0.9901, -0.9012, -1.1519, -0.6847, -1.7369,\n",
      "         1.5053,  0.9314, -1.1910, -1.0701,  0.8191,  2.8501, -1.6821,  0.9219],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.3150, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4228,  3.5744,  2.0000, -1.5746, -1.1844, -1.6181, -1.4055, -1.1726,\n",
      "        -1.8361, -1.2659, -1.7047,  1.1957,  2.6906,  1.2205, -1.0987,  2.8821,\n",
      "         1.0618, -2.3536, -3.8861, -1.0522, -2.0553,  1.1769, -1.3040,  2.9069,\n",
      "        -1.3450, -2.0370, -1.0041, -2.4417,  2.0000,  2.2635, -2.0730, -1.9548],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0178,  1.1582, -1.0005, -1.1942, -1.0725, -0.4835, -0.6969, -1.0151,\n",
      "        -1.6624, -0.0549, -1.3542, -1.4466,  1.1564, -0.9606, -1.7683,  2.1902,\n",
      "        -0.7533, -1.5579,  0.1178,  1.2851, -1.6873, -0.7936, -1.5312,  0.9686,\n",
      "        -1.5706, -1.9999,  1.8536,  1.0153,  1.7056,  0.9948, -1.3421, -1.0184],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.8430, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.9069,  1.6701, -1.9069,  1.5110,  1.3870,  1.5850,  1.6057,  1.2685,\n",
      "        -1.1296,  2.0298, -2.2150, -1.1258, -2.1234, -1.1165,  1.5331, -1.1211,\n",
      "         1.5663, -3.0508, -1.2267,  1.1817,  2.5513, -2.4594,  1.4594, -1.7998,\n",
      "        -1.3944, -3.3637,  2.3216,  1.0120, -1.0780,  1.1454, -2.9500,  5.8826],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0680e-03,  8.1852e-01, -7.1692e-01,  1.1004e+00,  2.3430e-01,\n",
      "        -5.3920e-01,  1.0972e-01, -8.9295e-03, -1.0070e+00, -3.6425e-01,\n",
      "        -1.6214e+00, -1.5108e+00,  1.4016e-01, -1.1365e+00,  8.4253e-01,\n",
      "        -9.9974e-01,  8.0786e-01, -2.5667e-01, -1.6260e+00, -4.7166e-01,\n",
      "         7.2878e-01, -1.4042e+00,  6.7549e-01, -1.5907e+00, -1.6668e+00,\n",
      "        -1.6781e+00, -3.9051e-01, -1.3145e+00, -3.2996e-01,  8.4520e-01,\n",
      "        -1.3501e+00,  7.5999e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.6642, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.1196,  1.2538, -2.0000, -1.1615, -1.6482,  1.4557, -1.5817,  1.4150,\n",
      "        -1.6717, -2.6521, -1.3050,  1.7373, -2.4694, -1.1147,  1.8403, -1.6696,\n",
      "        -1.2756,  1.1962, -2.4420, -1.9349, -1.6031,  1.7004, -1.4150,  1.5077,\n",
      "        -1.1628,  1.6157, -2.4457, -1.8924, -2.2479,  1.7914,  2.6800,  1.9329],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1093e+00, -1.3832e+00, -1.8216e+00, -1.7106e+00, -1.3111e+00,\n",
      "         2.3216e-01, -1.6994e+00, -1.0125e+00, -6.6677e-01, -1.6519e+00,\n",
      "        -1.6588e+00, -1.0315e+00, -1.5342e+00,  6.0875e-01, -9.7967e-01,\n",
      "        -1.6694e+00, -7.0745e-01, -1.3200e+00, -1.1845e+00, -1.5549e+00,\n",
      "         5.0718e-04,  1.1872e+00, -1.7524e+00,  1.3890e-02, -1.5623e+00,\n",
      "        -1.3909e+00, -1.1114e+00, -1.5677e+00, -1.8581e+00, -1.3524e+00,\n",
      "         1.1001e+00,  4.4172e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.9538, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2267, -1.9778, -2.3219,  1.1673, -1.9005, -1.4159, -1.0139, -1.3219,\n",
      "        -1.2486,  1.0772, -1.2022, -1.0233, -2.0000, -1.2547, -2.3003,  1.0712,\n",
      "         1.8171, -1.5475,  2.5731, -3.5850,  1.2977,  1.3215, -1.5151, -2.7613,\n",
      "        -1.7936, -1.5850,  1.5850, -1.9260,  1.3125,  1.2603, -2.3842, -1.6826],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1203, -0.9473, -0.2034,  0.8664, -1.2299, -1.8031, -1.4887, -0.2070,\n",
      "        -1.9063, -0.7518, -2.0122,  0.4304, -2.1248, -1.7117, -1.2271,  1.5298,\n",
      "         0.4533,  1.0941,  0.7365, -0.4923,  0.5489,  0.8323, -2.1878, -1.7078,\n",
      "        -2.0330, -1.8848,  0.4450, -1.1616, -0.4781, -1.1031, -0.3857, -2.1357],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.0394, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4432,  1.1555, -1.6044,  3.1497,  1.1782, -1.0181,  1.3293, -2.9475,\n",
      "         1.0841, -1.4500, -1.9778, -1.5984,  1.4241,  1.3941,  3.0444, -1.7004,\n",
      "         2.7143, -1.0870, -1.0875, -1.2801, -1.7908,  1.0620,  1.1817,  2.0506,\n",
      "         1.8429,  1.9055,  1.0993, -1.0999,  1.4406,  1.8074,  4.4594, -2.2076],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6893,  1.5070, -0.1805,  1.4944, -0.4586,  0.1235,  1.7617, -1.2010,\n",
      "         0.4542, -2.0537, -1.4093, -1.9964,  0.6175, -0.8379,  1.1799, -1.2628,\n",
      "        -0.1609, -1.3912, -0.3962, -1.3486, -1.1670,  1.6373,  0.0049,  1.5892,\n",
      "         0.7005,  0.7945, -1.5961, -1.4943,  1.1739,  1.5351,  1.5405, -1.1816],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 47 Predict 1107 zeros 576 ones, one bias 0.342246\n",
      "train loss: 2.0907747885246417 dev loss: 1.3255796143868224\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.2046, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.3219, -1.4150, -1.9260, -1.3219, -1.7370,  3.7726, -1.5850,  1.7162,\n",
      "         1.4594,  1.5004, -3.4215, -2.2563,  1.0728,  1.1699, -1.4935,  3.6553,\n",
      "         1.3014,  2.1463, -1.5294,  1.7287,  1.4477, -1.2814, -1.4044, -1.0873,\n",
      "        -2.0298, -1.1737,  1.4845, -4.2479, -1.0962, -2.8342, -1.4159, -2.0504],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1365, -0.4087, -0.8459,  0.3036, -0.8640, -0.1239, -0.4179, -0.3767,\n",
      "        -1.0145, -0.3444, -1.5436, -0.6017,  0.0234,  1.0329, -1.6551,  0.8720,\n",
      "         1.2250,  1.4915, -1.0777,  2.0408,  0.0059, -1.2497, -0.8064, -0.2149,\n",
      "        -0.6073,  0.1398,  0.6000, -1.8056, -1.1759,  0.6967, -0.8836, -1.2651],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.3743, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3300,  1.4145, -1.6694,  1.0728, -3.1699, -1.2486, -1.0237,  2.3342,\n",
      "        -1.9808, -1.9069, -1.6649, -1.8232, -1.0583, -1.0454,  1.4150, -1.4791,\n",
      "        -1.9635, -1.9005, -1.1597,  2.9535, -3.5607,  1.0841,  4.1133,  1.0180,\n",
      "        -1.6488,  1.6637, -2.6259, -1.3219,  3.0731,  2.5895,  1.7499,  2.7294],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4178, -1.9335, -0.3017,  0.8589, -0.1241, -1.2119, -1.6119,  1.4499,\n",
      "        -2.2320, -0.8685, -1.6503, -0.6333, -2.2694, -1.6007, -0.5357, -1.2034,\n",
      "        -1.9847, -1.5792, -1.7010,  0.2907, -2.4806,  0.2197,  1.3600, -1.3360,\n",
      "        -1.6958, -0.0052, -0.9425,  0.9339,  1.7373,  2.2028,  0.8852, -1.0530],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.8607, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0324, -2.7004,  1.3219,  1.5240, -1.5309, -1.3772, -1.2224, -1.0311,\n",
      "         2.1066, -1.1508,  1.2303, -1.1676, -1.3204, -3.3219,  3.4594,  1.2002,\n",
      "        -1.8313, -1.9069,  1.2354, -1.6118, -1.9778, -3.3966,  3.4594,  2.2370,\n",
      "         2.0666, -2.2311,  2.2724,  1.1238,  1.6736,  1.5850, -2.5620, -1.5360],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8980, -0.2771,  1.2679,  0.9314,  0.5897, -1.6512, -2.1061, -1.5607,\n",
      "         1.5648, -1.2425, -1.0152, -1.4215, -1.5639, -0.8079,  1.5159, -1.3480,\n",
      "        -0.9069, -0.8406,  0.1114, -1.6588, -1.4726, -0.4242,  1.2453, -0.1822,\n",
      "         1.1368, -1.7114, -0.2928,  0.4122, -0.8896,  1.5161, -1.8381, -1.8821],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.1214, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1155, -1.4359,  1.6410, -1.1699,  1.2350,  4.6893,  4.4046, -1.3765,\n",
      "        -1.0978, -1.8401,  1.0776,  1.0349,  2.7798,  2.1467,  2.3342, -1.7168,\n",
      "        -3.7603,  1.6521, -1.2058, -1.6717, -1.5439,  1.9167, -1.7260, -2.1214,\n",
      "        -1.5407, -2.0000, -1.1278, -1.6618, -1.8572,  1.8004, -1.0555,  1.6848],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2816,  0.0460, -1.0085,  0.4237,  0.2625,  0.6083,  2.3309,  0.6666,\n",
      "        -0.5555, -0.5949,  1.1899,  1.1019,  0.8549,  1.4524,  1.4546, -1.3720,\n",
      "        -1.6446, -1.1960,  0.4433,  1.5397, -2.2420,  1.2158, -1.1009, -2.0888,\n",
      "         0.3725,  0.0924, -0.6998, -1.3676, -0.5732,  1.7783,  1.1981,  1.6474],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.6926, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4143, -1.0343, -2.7004,  1.1699, -1.0462, -3.1193,  1.5003,  2.9542,\n",
      "        -1.8950, -2.3219, -2.4780,  2.1345, -2.5850, -2.2850, -2.5850, -2.3219,\n",
      "         1.1475, -2.8024, -1.7621,  1.6147, -2.7380,  1.6220,  2.1066, -1.3655,\n",
      "        -1.8464, -1.9260, -2.1993, -1.3624,  1.1483, -1.4513,  1.8226, -2.0000],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4122, -1.0079, -1.9135,  1.3772, -1.2154, -1.5376,  0.3950, -0.1106,\n",
      "        -1.6999, -2.0304, -2.2136,  1.5920, -0.9925, -1.7479, -0.6969, -0.1296,\n",
      "         0.7647, -1.8954, -2.0546,  0.3788, -2.3395,  0.6830, -0.4002, -0.4950,\n",
      "        -1.6450, -1.2479, -1.3976, -1.6114,  1.0081, -1.8350,  1.2705, -0.9039],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.0568, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0768, -2.8712,  1.2357, -1.3015,  1.2357,  1.1844,  1.3785,  1.6916,\n",
      "        -1.0371,  1.3414,  1.0189, -1.9814,  1.8101, -1.8765,  1.1183, -1.5850,\n",
      "         1.1506, -1.0518,  1.1371, -1.4354,  1.3119, -1.2044, -3.3219, -2.3219,\n",
      "        -2.2676,  2.4132,  1.5803,  1.1826, -2.8524, -1.2682, -1.3809, -1.8924],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4304, -1.5650,  0.9146, -1.5701, -0.3436, -0.9569,  1.3044, -0.0536,\n",
      "        -1.7867, -1.7129, -1.1740, -1.6798, -0.2404, -1.5983, -0.0656, -0.6495,\n",
      "         0.1332, -0.9092,  1.1869, -0.6578,  1.8441, -1.3926, -1.8802, -0.9280,\n",
      "        -1.2059,  1.5047, -0.0859, -1.5332, -0.3436, -0.6373,  0.4315, -1.4617],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 48 Predict 1178 zeros 505 ones, one bias 0.300059\n",
      "train loss: 2.0896523371772298 dev loss: 1.331163450694382\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.4410, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.4594, -1.2682,  2.3707, -1.7045,  2.9535, -1.1069,  1.3416,  2.3219,\n",
      "         3.0444,  1.8517, -1.6980, -1.8572, -2.1091,  2.0000,  1.5187, -1.0555,\n",
      "        -2.1076,  1.6897,  2.0940, -2.5620, -1.5502,  2.1066, -1.4626, -2.3669,\n",
      "        -1.2611, -2.8168,  1.5201, -1.4191,  1.0478, -1.3857,  1.3814,  2.6781],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5068, -0.7352,  0.2311,  1.1702,  0.3024,  0.3002,  1.1486,  0.4731,\n",
      "         0.1412,  1.9324, -1.4147,  0.4940, -1.5578, -0.0695,  1.3782,  0.8481,\n",
      "        -1.6616, -0.6716,  0.9883, -2.0872,  0.8974,  0.2769, -1.6062, -1.6133,\n",
      "        -0.8365, -1.6891, -0.4553, -1.4596, -0.5413, -1.3204,  1.2868,  1.5618],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.7537, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1069, -2.5794,  1.5784, -1.9260, -1.9143, -2.3219, -1.2476, -1.9542,\n",
      "         2.9942, -2.5064, -1.4875, -2.5136, -1.4236, -1.1597,  2.2410, -1.4706,\n",
      "        -1.4919, -2.6919, -2.0324, -1.6700,  2.0000,  1.2167,  2.5594, -1.1212,\n",
      "         1.3196,  2.7855,  1.1699, -1.5194,  1.0099,  2.4132,  1.5825, -1.2890],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2718,  0.6253,  1.5109, -0.2383, -1.4238, -1.3362, -1.4498,  0.9347,\n",
      "         2.1150, -1.4611, -1.5196, -1.3447, -0.8914, -1.1222, -0.8919, -1.1133,\n",
      "        -0.5049, -2.2315, -1.2716,  0.7077,  1.2977,  0.7630, -0.2756, -1.7603,\n",
      "         0.4564,  1.1156,  1.3980,  1.2031,  1.1663,  0.2908,  0.9399, -1.5195],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.9717, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1435,  1.1082,  1.5850, -1.2070, -1.1937,  1.5617, -1.8580, -1.8689,\n",
      "        -3.5110, -1.0967, -1.3215,  1.8429,  2.0336, -1.2291, -2.9798,  1.3000,\n",
      "        -1.2090, -2.9696, -4.6439, -2.0875, -1.1319, -1.0308, -2.3388, -1.4812,\n",
      "        -1.9713,  2.6676,  1.8160,  1.1414,  1.3219, -1.9143, -1.1147,  1.1871],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0381,  1.8939, -0.8935, -1.4141, -0.8013,  0.9411, -0.2527, -0.6929,\n",
      "        -0.6225, -1.2100, -1.3853,  1.3844,  1.1646, -1.6108,  0.2917, -1.5498,\n",
      "        -0.3020, -1.0191, -1.5538, -0.8367, -0.3431, -0.1638, -1.5466, -0.3664,\n",
      "        -1.2872,  0.0161,  0.9454,  0.2270,  2.5590, -0.9502, -0.5220, -1.1523],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.9065, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4600, -1.2663,  1.1839, -1.1630, -1.5208,  1.4888,  1.8403, -1.1165,\n",
      "        -1.4763,  1.0904, -1.9797,  2.7294,  1.3550,  1.1201, -1.0592,  1.1690,\n",
      "        -1.2977, -1.0999, -1.2027, -1.9260,  1.0177, -1.5309,  2.3575, -1.8074,\n",
      "        -1.7011, -1.9260, -1.6980, -1.7033, -1.0802,  1.3000,  1.3943,  1.6571],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4906, -1.7767,  0.1876, -1.6583,  0.1806, -1.4504, -1.1994, -1.7591,\n",
      "        -1.7370, -1.1010,  1.3087, -1.3260,  0.0228, -0.6445, -0.5597,  1.9233,\n",
      "        -1.5714, -1.6678, -0.7778, -0.1541, -1.6390,  0.4508,  0.9398, -2.0218,\n",
      "        -1.7544, -0.6212, -1.5565, -1.9203, -1.2162, -0.7528,  0.5731,  1.6310],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.7834, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0655, -2.9696,  2.5487, -1.0070, -1.1375,  1.7030, -2.0632, -1.0116,\n",
      "         1.1699, -1.2848, -2.3833, -1.5850, -1.4239, -2.4383, -2.4854,  1.2137,\n",
      "        -2.5850, -2.1699, -1.1155, -1.8730, -2.1333,  1.8745,  1.1107,  1.7800,\n",
      "         1.7124, -3.1043,  2.0486,  2.3342, -2.3219,  1.4411, -1.0815, -3.8073],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1378, -0.7604, -0.9334, -0.6667, -1.5253,  1.3403, -0.9787, -1.7099,\n",
      "         1.2987,  0.1861,  0.6360, -0.8920, -1.3789, -1.6246, -0.4585, -0.9043,\n",
      "        -0.1617, -1.5738, -1.1960, -1.4629, -1.7521,  0.8271, -0.9561, -0.1806,\n",
      "         0.1682, -1.8494,  0.3791,  1.0636, -0.4012,  1.2073, -0.8110, -2.1053],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.7446, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4344, -1.3310, -1.9358,  1.3814, -1.9260,  1.5337, -1.2090, -1.2303,\n",
      "        -1.9069, -1.8784,  1.3651,  1.3022, -1.2659, -1.3292,  1.3615, -2.7274,\n",
      "         1.1371,  1.2165, -1.8130,  4.9357, -1.5355,  1.8074, -2.1641,  1.6300,\n",
      "         1.2174,  2.0000, -1.2044, -1.9401, -2.9358,  1.2167, -1.1584, -1.3900],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7240,  1.0859, -1.8630,  0.9640, -1.0400,  0.9711,  0.1375, -1.0710,\n",
      "        -0.4202,  0.7666,  1.6715,  1.2941,  0.0240, -0.5896, -0.2788, -0.1269,\n",
      "        -0.5063, -1.0768, -1.0051,  2.4814, -1.3968, -0.3691, -1.7445,  1.4497,\n",
      "        -0.7561,  1.3846, -1.6364,  1.7585, -1.3064, -1.3844, -0.6465, -1.6040],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 49 Predict 1056 zeros 627 ones, one bias 0.372549\n",
      "train loss: 2.0699332738020275 dev loss: 1.4576477366214278\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.6619, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1285,  1.8171, -1.9260,  1.1497, -2.2865,  1.7004,  1.8399, -1.0952,\n",
      "        -1.1382, -2.7482, -2.0875, -1.9095, -1.1155, -1.1631, -3.3219, -1.1703,\n",
      "        -1.3757,  1.7974, -1.9370, -2.6546, -2.4432, -2.9696, -1.5887, -1.1628,\n",
      "        -5.8745,  1.1969, -1.1069, -1.5415,  1.7105, -1.5469,  1.7914, -1.8074],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6864, -1.4441,  0.8351,  1.7417, -2.0920,  1.1057,  0.7516, -1.5855,\n",
      "        -1.6658, -1.5190, -1.8303, -1.3896, -1.6854, -1.5051,  1.4590, -0.4584,\n",
      "        -0.8023,  1.2850, -0.9639, -2.0572, -2.3085, -1.0201, -1.0100, -1.9887,\n",
      "        -1.1040,  1.4246,  0.5862, -0.7774,  0.9598, -1.7708, -0.7571, -0.9661],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.5021, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0680,  3.0000,  1.0504, -1.5243, -3.4215,  1.1183,  2.0395, -2.3029,\n",
      "        -3.2525, -2.8694, -1.2801, -1.5971, -2.1468, -2.4041,  1.8496, -1.4706,\n",
      "        -2.1155,  1.1219, -2.6400,  2.1783, -1.2267,  1.3931,  1.5676,  3.5084,\n",
      "        -1.9279, -1.5032, -2.9696,  1.6379, -2.5745, -1.4137,  1.9492,  1.2418],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1048,  0.2013,  0.2116, -0.7277, -1.8556,  2.2295,  1.3018, -1.0254,\n",
      "        -1.6698,  0.7867, -0.6023, -1.6582,  0.7629, -2.2186,  0.6106, -0.8520,\n",
      "        -1.8751, -0.1650, -1.1745, -0.8006, -2.1543,  0.2154,  1.7126,  1.4377,\n",
      "         0.0760,  1.1077, -0.9607,  1.1368, -1.2362, -1.5803,  0.0960,  0.3500],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.3771, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0592, -1.5850,  2.1865,  1.3219,  2.3219, -1.2827, -1.1487, -1.4962,\n",
      "        -2.3219, -1.0486, -1.1444,  2.1753,  1.4763,  1.3337, -3.7472,  2.3431,\n",
      "        -2.1113, -1.4150, -2.2076,  1.8711, -3.7472, -1.5850, -1.2224, -1.5850,\n",
      "        -2.6067,  1.1547,  3.0000,  1.0189, -2.7370, -1.5657, -2.5136, -1.0766],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3554, -0.7139,  1.4017,  1.4815,  1.0096, -1.7936,  1.3005, -1.7653,\n",
      "        -0.1732, -1.7299, -1.7467,  1.6121,  1.5543, -0.9530, -1.6061,  1.2852,\n",
      "         0.4551, -1.9021, -1.3346, -0.4729, -1.8410, -1.6852, -1.6590, -0.5160,\n",
      "        -0.1757,  1.3815,  1.5756, -1.6942, -0.9262, -2.0137, -1.0343, -1.1754],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.8284, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.9580,  2.1986, -1.3010, -2.6258, -2.9696,  1.0431,  1.0280,  1.0686,\n",
      "         1.6594, -1.9095,  4.3631, -1.0391,  1.4105, -3.0750, -2.0351, -1.6888,\n",
      "        -2.4041, -1.6472, -2.6439, -3.3976,  1.0067, -1.0995, -1.3015,  1.6909,\n",
      "         1.2685,  2.3219, -2.0546, -1.1069,  1.3101,  1.0090, -1.6108, -1.4150],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1410, -1.6064, -1.8343, -0.3329, -1.0816, -1.1639, -1.6626,  1.5815,\n",
      "         0.8151, -1.5613,  2.6019, -1.1391,  0.2317, -1.7471, -1.4474, -1.0119,\n",
      "        -1.1460,  1.3286, -1.7883, -1.6214,  0.1153, -1.0964, -1.6216,  0.0551,\n",
      "        -1.3988,  0.9128, -0.6014, -0.7436,  0.6780,  1.6016, -1.2639, -0.3698],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.2334, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8686, -1.3539,  1.4052,  3.1155, -1.0827,  1.2977, -2.3738,  1.1371,\n",
      "        -2.1949,  1.0841, -1.0869,  1.2436,  2.6168,  1.7914, -1.9069,  1.0780,\n",
      "        -1.8074,  1.4053,  1.4150, -1.3900, -1.0345, -1.3050, -2.2095,  1.3046,\n",
      "         1.4527,  2.2869,  1.8496, -3.7603, -1.9814, -1.1375, -1.9260,  1.8272],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8394, -1.5716, -0.3294,  2.2495, -1.2944, -0.7611, -1.9194,  0.7150,\n",
      "        -1.6799,  1.6852,  1.8456,  0.4099, -0.4639, -0.2822,  0.1860, -1.6927,\n",
      "        -1.7438,  0.9667,  1.0617, -1.6905, -1.0473, -1.4006, -1.2195,  1.1739,\n",
      "         0.6057,  1.3971, -1.2710, -1.8747, -1.5727, -1.5483, -0.1706,  0.9880],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.3112, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2152, -1.8458,  1.1929,  1.0447, -1.4533, -1.2778,  1.0704,  2.6323,\n",
      "        -1.3757,  1.5195, -1.1444,  1.4105,  1.2122,  1.0297,  1.4651,  2.0000,\n",
      "        -2.3219, -1.4150, -1.0716, -2.6439,  1.3931,  1.5606, -1.8365,  2.0118,\n",
      "         1.0841,  1.3931,  2.0682, -1.0941, -1.3823,  2.2370, -1.3119,  1.3119],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9941, -1.3304,  1.1254, -0.0317,  0.1090, -1.1547,  0.5485, -1.7059,\n",
      "        -1.3457,  1.8050,  0.0047,  2.0266,  1.7012,  0.3301, -0.2937,  0.2820,\n",
      "        -0.5424, -1.6953, -1.7463, -1.0622,  1.0617, -2.0952, -0.0913,  1.5732,\n",
      "         0.3783, -0.5275,  1.6718, -1.4070, -1.7265,  1.8200,  0.8206,  1.4185],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 50 Predict 1075 zeros 608 ones, one bias 0.361260\n",
      "train loss: 2.1021403395597904 dev loss: 1.3100659229583786\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.3459, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7358,  1.5120, -1.7843,  1.2044,  2.5670, -2.1838,  1.2346, -1.2139,\n",
      "        -2.0451, -1.3461,  1.6848,  1.5617, -1.6265, -1.6778, -3.0609,  1.2633,\n",
      "        -1.4498, -1.8572, -2.3219, -1.3624, -1.7105, -2.1699, -1.5984, -1.1615,\n",
      "        -2.1113,  1.9662,  1.8235, -1.4134,  3.1414, -1.7370, -1.0941, -1.2851],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1688,  0.9324, -1.4999, -1.0504,  2.5964, -1.6361, -1.4491, -0.6683,\n",
      "        -1.5818, -1.5821,  0.5755, -0.8794, -1.0799, -1.4499, -1.7701,  0.2039,\n",
      "        -1.4929, -0.7326, -1.5738,  1.3281, -1.5870, -1.4021, -1.4794, -1.7667,\n",
      "        -1.2710,  1.3357,  1.2178, -0.6432,  1.0503, -1.4877, -1.2432, -1.5178],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.8609, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9069, -2.9798, -2.4742, -1.6488, -2.1468, -2.3318, -2.9500, -2.8073,\n",
      "         1.4557, -2.0000, -2.2441, -2.3003, -1.4962,  2.9069, -2.3219, -1.6180,\n",
      "         2.3363, -2.9555, -1.6707,  1.0047,  2.1463, -1.1813, -2.2638, -1.5432,\n",
      "        -1.9069,  1.1839, -1.2817, -2.2598, -1.0562, -1.6828,  1.2902, -1.6700],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.2405, -0.5979,  1.3044, -1.6206,  0.2143, -1.3473, -1.3666, -1.6244,\n",
      "         1.3556, -0.7570, -0.8744, -1.5967, -1.6658, -0.2922,  0.2639, -1.6593,\n",
      "        -0.4983, -1.8021, -1.4201, -1.5696, -0.0448, -1.7726, -1.3133, -0.5870,\n",
      "         0.3139,  1.0107,  0.3370, -1.7227, -1.6050,  1.0651, -0.4016,  0.8123],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.7790, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4957, -1.1155,  2.6716, -1.5850,  1.1988, -2.3219,  2.0940, -2.9475,\n",
      "        -1.5475, -1.3940, -1.9279, -2.3708, -1.9069, -1.3036, -1.2224, -1.7262,\n",
      "        -6.4702, -1.3992,  1.2167, -1.1165,  1.3785, -1.1319,  1.6909,  1.6439,\n",
      "        -1.6515, -2.5374,  2.7558,  1.3948,  1.7914, -1.5208, -1.9069, -1.5850],\n",
      "       device='cuda:0')\n",
      "tensor([-0.2856, -0.3413,  2.6370,  0.4703, -1.8343,  1.0197,  1.2333, -1.7449,\n",
      "         0.5866, -1.9148,  1.0751,  1.4266, -1.3022,  0.3313, -0.4875, -2.0386,\n",
      "        -1.8418, -0.3581,  1.1484, -0.7273,  1.2074, -0.8957,  1.0151,  0.1775,\n",
      "        -1.9426,  0.8259,  2.0300,  1.7589,  1.7501, -1.4191, -1.8749, -1.9641],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.7748, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5368, -1.6658,  1.0608,  2.7855, -3.0000, -1.2095, -1.2752, -2.1155,\n",
      "        -1.1155, -2.9696,  1.8171,  1.2685,  2.3824, -1.9824,  2.6168,  1.1497,\n",
      "        -1.0064, -1.1211,  1.1602,  1.5850,  1.3333,  1.8403,  1.2106,  1.2167,\n",
      "        -2.1155, -1.0941,  1.6796,  1.4651,  1.5220, -2.3028, -1.0444,  1.4052],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0225,  0.2817,  0.5318,  1.0621,  1.7094, -1.8879, -1.0137, -1.5817,\n",
      "        -0.8723, -1.1155,  0.5473, -0.9504,  1.4673, -1.7286,  0.6553,  1.2660,\n",
      "        -0.9764,  0.9381,  1.5194,  1.2533, -0.8152, -0.1147,  1.2752, -1.5077,\n",
      "        -1.6107, -1.3787,  1.3352,  0.1277, -1.0908, -1.5903, -1.0017,  1.6355],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.5183, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1890, -1.2374,  2.0000, -1.8160,  1.3736,  1.8884, -2.1178,  1.0237,\n",
      "        -1.8561, -2.3725, -1.4150, -1.5247, -1.1975,  1.8101, -2.6439, -1.2988,\n",
      "        -1.7004,  1.2980, -1.1211, -3.1699, -1.6930, -2.4595,  2.5850,  2.0000,\n",
      "        -3.7565, -1.0327,  1.1871, -2.5850, -2.7274, -1.0809,  2.1047, -1.1508],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2341, -1.7103,  0.1345,  0.9140,  2.1776,  0.8000, -1.9559,  1.1224,\n",
      "        -1.4189, -0.5802, -1.3089, -1.0163,  2.1606, -1.2053, -0.9126, -1.7343,\n",
      "         0.9277,  1.2441,  0.0827, -1.2425, -1.1925, -1.6925, -1.1434, -1.5969,\n",
      "        -1.4419, -1.8083,  1.6555, -0.4574, -1.3266, -0.6889,  0.8197, -1.9124],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.8233, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2284,  2.5025, -2.0862,  1.1871, -1.1611,  1.6439, -1.8747, -2.9087,\n",
      "        -1.9678, -2.7482,  3.5089, -2.9798, -2.0050, -1.7472, -1.9069, -2.9798,\n",
      "         1.3059, -1.5502,  1.2545, -1.2158, -2.7918,  2.3219,  1.5676, -3.3847,\n",
      "        -2.8073, -1.8190, -2.5220, -1.8730,  1.5606,  1.3626, -2.5715,  1.0555],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3420,  0.2223, -1.2147,  1.2575,  1.5730,  0.2235, -1.6895, -2.2771,\n",
      "        -1.3051, -1.8680,  1.2421, -0.1346, -1.9869, -1.8845,  1.0736,  0.5122,\n",
      "         2.3392, -0.5869, -0.8195, -1.0314, -0.6196, -1.0434,  1.0239, -0.9574,\n",
      "        -1.7722, -0.4823, -1.0414, -0.8561, -1.7694,  0.2424, -1.7321,  1.1820],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 51 Predict 1061 zeros 622 ones, one bias 0.369578\n",
      "train loss: 2.098585694700807 dev loss: 1.4947461123128933\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.7075, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1309,  2.1451, -1.2682, -2.0194, -1.2224,  1.7549,  1.5606, -1.0522,\n",
      "        -1.8924, -2.0657, -1.5502, -2.7482, -1.0371, -1.9879, -1.8863, -1.7029,\n",
      "         1.2773, -2.8901,  1.1371, -1.1535, -3.4594,  1.3196, -1.9260, -1.1212,\n",
      "         1.4915, -2.5920, -2.1299, -1.5729, -2.3388,  1.1226, -1.1699, -1.2996],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1918, -0.2243, -1.2574,  0.0185, -1.7529,  0.7328, -1.7753, -0.6775,\n",
      "        -1.6265, -0.0442,  0.6112, -1.8888, -1.0924, -0.0192, -1.6954,  0.0641,\n",
      "         1.0986, -1.6471,  1.1587, -1.6309,  0.7800,  1.1943, -1.1453, -1.2462,\n",
      "         0.3514, -0.3787, -1.6162,  0.1280, -2.1583,  2.3893, -1.9828, -1.5200],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.8697, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.6323, -2.7613, -1.1579,  1.2167, -1.0766, -2.3219,  1.4532,  1.0680,\n",
      "        -1.0555,  2.2721,  1.1690, -1.0999, -2.0360, -1.2682,  2.3219, -2.1180,\n",
      "         1.7370, -1.3878, -1.5539, -1.0522, -1.8458,  1.5850, -3.3976, -1.2222,\n",
      "        -1.3684, -1.7613, -2.8755,  1.5146, -2.2865,  1.6796, -1.9260, -1.4935],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7592, -0.9869, -1.2966, -1.0559, -1.7763,  0.3534,  1.4415, -1.7113,\n",
      "         0.9877,  2.8534,  1.0010, -1.8509,  0.0444, -0.8067,  1.7401, -1.4210,\n",
      "        -1.7027, -0.4337, -1.7110, -1.1179, -1.1063,  1.2774, -1.7735, -0.1812,\n",
      "        -1.4760, -2.1959, -2.0555,  1.4779, -1.7778,  0.9760, -1.3180, -0.3618],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.5516, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0356,  1.3332, -2.9798,  1.9523, -2.4854, -2.5580, -1.8480, -1.5979,\n",
      "        -1.3870, -2.0980, -1.4081, -1.7262, -1.2955, -1.1155,  1.4382,  1.1219,\n",
      "        -1.3303,  1.5433, -1.6353, -1.8682,  1.3067,  2.0471, -1.3388,  2.9069,\n",
      "        -3.2912,  1.3468, -2.0918, -1.6524, -2.1058,  1.6894, -3.3575,  1.0618],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0558,  1.4167,  0.0908, -2.0227, -1.1428, -2.3141, -0.5875,  1.0713,\n",
      "        -0.8528, -1.0794, -1.0180, -2.5186, -1.2407, -1.2056,  1.2541, -0.2367,\n",
      "        -0.4947,  0.7657,  0.7875, -2.6898,  1.6787,  0.2523, -1.3945,  1.5185,\n",
      "        -1.5812, -1.2811, -1.9432, -1.3441, -2.4196,  1.1553, -1.8617, -1.1334],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.9523, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5095, -3.5480, -1.1543,  1.0464,  1.0464, -1.8571, -1.0875, -2.1174,\n",
      "         1.5606, -2.2624, -1.0506,  1.0666, -1.2733, -1.1155, -2.4417,  1.0119,\n",
      "         2.3114, -1.5850,  1.8171, -2.8580, -1.7370, -1.2973,  1.0881,  1.3949,\n",
      "        -1.6618,  2.0589,  1.7004, -1.2097, -1.9418, -1.0116, -1.7004, -1.0639],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9766, -1.8763,  0.3734, -0.4892, -1.7523, -0.8582, -1.5083, -1.6483,\n",
      "        -1.7333, -1.4737, -1.4137,  1.3684, -1.2642, -1.6497,  2.0391,  1.0437,\n",
      "         2.4530,  0.1868, -0.6842, -0.0850,  0.1724, -1.9606,  1.1566,  0.3064,\n",
      "        -1.4512, -1.5684,  1.4267, -1.8215,  2.2630, -1.5246,  0.5794, -1.0066],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.0156, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3624, -2.5580, -1.0704,  1.7600,  1.2167, -1.2413, -2.0666, -2.2569,\n",
      "         1.0846, -1.1009, -1.0870,  2.3219, -2.4263,  1.7077, -1.3923,  2.1756,\n",
      "        -1.4150, -1.6938, -2.9386,  1.1483,  1.3683,  3.1414, -2.1113,  1.4307,\n",
      "         1.4957, -1.3109, -1.6108, -2.6589, -1.2687, -1.1508, -1.2929,  2.9964],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3498, -1.7343, -0.9379,  1.4663,  0.3141,  0.9587,  0.1197, -1.4440,\n",
      "         0.5426,  0.3912,  2.0212,  0.7709, -1.8190,  0.5679, -1.3768,  0.8335,\n",
      "         1.6147, -0.9652, -1.5620,  1.5827,  1.1501, -0.1999, -1.2366,  1.5953,\n",
      "         0.9048, -1.2094, -1.4416, -1.5785, -1.4516, -1.5566, -1.6719,  1.0431],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.1686, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0572, -1.3105,  3.4150,  1.2224, -1.3102, -1.1945, -2.1722, -1.6826,\n",
      "        -1.7923, -1.8251,  1.4532,  2.4060,  1.3785,  1.1025, -1.4286, -2.8073,\n",
      "         2.5962,  2.9014, -1.1259, -1.0100, -1.1960,  1.4150,  1.3172, -2.0129,\n",
      "         1.8171,  2.2869, -1.3278,  1.4330, -1.5850, -2.0000, -2.8024, -1.8689],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.4721, -1.6333,  2.4668, -1.4235, -2.3333, -0.5999, -2.3044, -1.8900,\n",
      "        -1.7402, -2.1632,  2.3119,  1.1401,  0.9052,  1.8625, -1.6784, -0.4432,\n",
      "         0.6913,  1.2747, -2.1244, -1.9110,  0.1166, -0.0500,  1.4197,  1.0773,\n",
      "        -1.1231,  0.9112, -1.8297, -1.0956, -1.4912, -0.6353, -1.6842, -1.6926],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 52 Predict 1040 zeros 643 ones, one bias 0.382056\n",
      "train loss: 2.089060149298637 dev loss: 1.241375306970232\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.4560, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4557,  1.7040, -1.6265,  2.7612,  1.0561,  2.1345, -2.4594,  1.2855,\n",
      "        -1.7046, -1.0700, -2.0000, -2.4448, -1.1489,  1.4227, -1.7004, -1.0522,\n",
      "        -1.1676, -1.3870, -1.6280,  1.0858, -1.6524, -2.6400, -1.4542, -1.1979,\n",
      "        -2.0796,  1.0680, -1.0873, -2.4288,  1.5500,  1.4557,  1.1024,  2.2869],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6224,  1.4508, -1.6937,  0.9847,  0.6609,  1.4558, -0.4119,  0.9326,\n",
      "        -0.0123, -1.0765, -1.4783, -1.4632,  0.7680, -0.9914,  0.6306, -0.7056,\n",
      "        -1.5520, -0.7294, -0.7528, -1.0103, -1.4367, -1.5650, -1.5397, -1.7218,\n",
      "        -1.2974, -0.2510, -0.8978, -1.6810,  0.9960,  0.5047,  1.8541,  1.5147],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7359, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3870, -1.2034,  2.1255, -1.1699, -2.0000, -1.0091, -1.6483, -2.0451,\n",
      "         1.6562, -1.5794, -1.9069, -1.7091, -1.1976,  1.7737, -3.1993,  2.6353,\n",
      "        -2.4041, -1.1489, -1.1706,  2.6168, -1.1975,  1.0718, -1.4109, -1.5746,\n",
      "         1.2062, -1.5623, -2.5171, -2.1641,  3.6943,  1.1822,  1.1444, -1.9797],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3053, -1.9702, -0.0141, -2.1391, -1.6921, -2.0749, -1.7978, -1.6337,\n",
      "        -0.0077, -1.0594, -1.4900, -1.9300, -1.7446,  1.0432, -1.9611,  1.4592,\n",
      "        -1.9479, -0.7722,  0.1925,  0.3234,  0.5486, -0.8482, -0.0532, -1.7104,\n",
      "         0.2068, -1.4986, -1.3886, -1.8350,  1.0382, -0.5991,  1.1038, -2.0306],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.4391, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4950, -2.0875, -2.2076, -1.9358, -1.4894, -1.7405, -1.0962, -2.4525,\n",
      "        -1.0356, -1.9022,  1.3219, -1.8686, -2.0369,  1.1082,  1.5850, -1.9238,\n",
      "        -2.9475,  1.6630, -1.3336, -1.0363,  1.5580, -1.0431,  1.0452,  1.6842,\n",
      "        -2.8297, -1.3944,  3.1414, -2.0000, -2.3254,  1.7692, -2.3394,  1.3468],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6817, -0.7777, -0.8151, -1.5931, -2.1241,  0.2573,  0.1413, -1.6491,\n",
      "        -0.6802, -0.8769,  0.8951, -1.8338,  0.4414,  1.2859, -1.6061, -1.1365,\n",
      "        -0.0709, -1.4328,  0.8608, -0.0066,  1.3498,  0.5173,  0.9300,  1.3817,\n",
      "        -1.9931, -1.8340,  0.9742, -1.2599, -1.6559,  1.0272,  0.1688,  1.5267],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(4.1096, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7287, -1.8313, -2.7918, -3.0875,  1.5825, -1.8465, -3.0000, -1.8232,\n",
      "         1.6092,  1.2303, -1.8924,  2.5571, -2.3324,  1.1020,  1.8192,  3.5349,\n",
      "        -1.3167,  1.2606, -1.7033,  1.2350,  4.4046, -1.5850, -1.2241, -1.4894,\n",
      "        -2.9798,  3.9307, -2.3029, -1.3624, -2.5745, -3.9449, -1.7004,  1.5110],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9806, -0.9510, -1.9120, -1.6112,  1.7012, -1.4699, -0.5978, -1.5222,\n",
      "         1.5921, -0.6240, -1.7206,  0.4303, -1.7793,  2.5061,  1.1060, -1.0988,\n",
      "        -1.4523,  0.1890, -1.8219,  1.6173,  2.2692,  1.2049, -0.6714, -1.3850,\n",
      "         0.1458,  1.3064, -0.1619,  1.1996, -1.7686, -0.1844, -1.1158,  1.9802],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.0252, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0614, -1.6108, -1.1844, -4.6439, -1.2814,  1.2224, -2.8073,  2.0118,\n",
      "        -1.9441, -1.2224, -1.4250,  1.4854, -1.1844,  1.0056, -2.5095,  1.9693,\n",
      "        -1.2315,  1.8399,  2.8073, -1.9260, -1.2682,  1.8767, -1.1336, -1.0928,\n",
      "        -2.4010,  1.3101, -2.8755, -1.0371,  1.5360,  1.7974, -1.0875, -1.9594],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2455,  0.1069, -0.0775, -2.0682,  1.3327, -1.6971, -0.1701,  1.3272,\n",
      "        -1.7827, -1.4655, -1.6747,  0.2525, -1.9750, -1.1232, -1.3676,  1.0028,\n",
      "        -1.8605,  0.8021, -1.6636, -0.7213, -0.8326,  0.1951, -0.6606, -1.7286,\n",
      "        -1.7482,  0.5734, -1.8486, -1.5281, -1.4900,  1.1243,  0.1980, -1.7416],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.7236, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7995, -2.8832,  1.8122, -1.4533, -1.2756,  2.8073,  1.6323,  1.9608,\n",
      "        -1.2224,  1.0464, -2.0000,  2.4328, -1.5850, -1.0641,  1.1444, -1.4044,\n",
      "        -1.2955,  1.6172, -2.5374, -1.0766, -1.2955,  1.0408,  1.2320, -1.1100,\n",
      "        -1.4854,  2.3219, -1.1069, -2.7004, -1.6845, -1.9260,  2.0358, -2.5651],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3478, -1.6397,  0.7247, -1.6959, -1.1029,  2.2012, -0.2509,  0.5565,\n",
      "        -1.1173, -0.0565, -0.9736,  0.6997,  0.9467, -1.4993,  2.0081, -0.9876,\n",
      "        -1.6144,  1.0419, -0.9908, -1.2288, -1.7460, -0.2120,  0.5437,  0.1144,\n",
      "        -1.4983, -0.6544, -0.4589, -1.2164, -1.0916, -1.0550,  0.8474, -0.4224],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 53 Predict 1007 zeros 676 ones, one bias 0.401664\n",
      "train loss: 2.0490913435807134 dev loss: 1.2415428533928512\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5944, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1727, -3.7549, -1.8689, -1.6008, -1.6717, -2.1375, -1.5422, -1.4094,\n",
      "        -1.1615,  1.3986, -3.0000, -1.4286,  1.3219, -1.5850, -1.0841, -1.3626,\n",
      "        -1.6415, -1.6228, -1.0864, -1.0062,  1.5330, -1.0875,  3.3219,  2.5698,\n",
      "         1.2167, -2.2783, -1.9476, -2.0000, -2.7380, -1.5247, -1.9542, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7810,  1.0979, -1.0953, -0.1568, -0.5432, -1.2591, -0.6036,  0.4539,\n",
      "        -1.5393,  0.8880, -1.1015, -1.9393,  0.4499, -1.0560, -1.5949, -0.4414,\n",
      "        -1.9301, -0.3404,  1.5977,  0.8622,  1.5890, -2.0025,  1.1002,  1.0132,\n",
      "         0.9722, -1.3814, -0.1382, -0.7669, -1.7353,  0.2199, -1.1000, -1.4778],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.8344, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.9500, -2.0920,  1.9267,  1.5360, -2.9798, -2.0200, -2.2000,  1.2745,\n",
      "         2.4195, -3.6897, -1.6108, -2.6400, -1.4205,  2.6716, -2.0369,  2.0666,\n",
      "        -1.5407,  1.2685, -1.5407, -2.2598, -1.1535, -1.8931, -1.1255, -1.4336,\n",
      "        -2.6955, -1.8749, -3.5850,  1.6204, -1.8819,  1.2545, -1.0041, -2.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1966, -1.6784,  1.5726,  0.0666, -0.1315, -1.3042, -1.4826, -0.0889,\n",
      "         0.7140, -1.6471, -1.1731, -1.5402, -1.4465,  2.1848, -1.4910,  1.1862,\n",
      "        -0.6450,  1.1734, -1.0130,  0.2906, -1.4871, -0.5084, -1.2351, -1.4078,\n",
      "        -0.8261, -1.4425, -0.6550, -0.9531, -1.4525, -0.3423,  0.7056, -0.2342],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.7123, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.7472,  1.8573, -1.8458,  1.0888, -2.0000, -1.5271,  1.6206,  1.0349,\n",
      "         1.6157, -1.7262,  2.4279, -1.1630,  3.1375, -2.1722, -1.1444,  1.5332,\n",
      "         1.1414, -2.3923, -1.7004,  1.2303,  1.3388,  3.5807, -1.6472, -1.6321,\n",
      "        -2.6656, -1.2224, -1.0562, -2.4594,  1.0680, -2.8755, -1.3655,  2.0823],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9133e+00,  1.7390e+00,  6.2719e-02,  3.1905e-01, -2.9159e-01,\n",
      "         1.6464e-01,  2.1775e+00,  1.0407e+00,  1.5651e+00, -2.1130e+00,\n",
      "         1.9366e+00, -2.0844e-01, -3.7813e-01, -1.5854e+00,  7.7696e-03,\n",
      "         9.3464e-01,  4.4864e-01, -1.9773e+00,  1.3631e+00, -3.5797e-01,\n",
      "         5.2843e-01,  1.1177e+00,  1.7274e+00, -2.0924e+00, -1.7340e+00,\n",
      "        -5.6309e-04, -1.6109e+00, -3.4554e-01, -1.5352e+00, -2.0282e+00,\n",
      "        -1.1497e+00,  9.7023e-01], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.1147, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2801, -1.5661, -2.0875,  1.5541,  1.2475, -2.9386, -1.5730, -1.9400,\n",
      "        -1.3085, -3.6897, -3.5034, -1.0583, -1.5083, -2.4127, -1.9778,  1.8931,\n",
      "        -2.3219, -2.0287,  1.5606,  2.4270, -2.4417, -1.5538,  2.0224,  1.5850,\n",
      "         1.2677, -2.8073,  1.4150, -1.3450,  1.0761, -2.3978, -1.8395, -1.4507],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0563, -1.5479, -1.5177, -1.3180, -0.0043, -1.5928, -1.9376, -1.8309,\n",
      "        -1.7151, -1.5709, -1.9517, -0.4461, -1.1062, -1.1624, -0.5396,  2.3440,\n",
      "         1.2341, -1.5316, -1.5961,  1.9614,  1.2691, -1.7004,  1.4872, -1.5499,\n",
      "         1.1985, -1.5487,  0.3181, -1.5538,  0.0672, -2.0666, -1.5599,  1.0796],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1833, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1072, -1.5850, -2.0516, -1.0345,  1.3332, -2.5374, -2.3219, -1.7294,\n",
      "         1.7914,  1.8160, -1.5083, -1.5971, -1.8640, -1.6338,  1.1500, -1.4044,\n",
      "        -1.8863, -1.1069, -1.2713, -1.5971, -1.2397,  2.2869,  2.0000, -1.7355,\n",
      "         1.3196, -1.3310,  1.8391, -1.4936, -1.4058, -1.2065, -3.1699, -1.6129],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3556, -1.1733, -1.5862,  0.4261,  1.0157,  0.0108,  0.0964, -1.2146,\n",
      "         0.2904,  1.3881, -1.7501, -2.0904, -2.0031,  1.1994, -1.0051, -0.7240,\n",
      "        -1.9322,  1.2208, -1.4574, -1.4515,  1.0469,  1.2920,  1.1975, -1.3893,\n",
      "         0.4777,  1.5855,  1.9262,  1.0722,  0.8047, -1.4162, -1.0147, -1.8142],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.3354, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1905, -1.4466, -2.0444,  1.3626, -2.3842, -2.5850,  1.4374, -1.2966,\n",
      "        -1.8157,  2.3317,  1.4450, -2.2044, -1.9260,  2.0655,  1.6067, -2.3219,\n",
      "        -1.8682, -1.4167, -1.7909,  1.3099, -1.2284, -2.1876,  2.3219,  1.5850,\n",
      "        -2.7808, -1.2966, -2.2624,  1.4854, -1.2938, -2.9542, -1.4594, -1.8572],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3476,  0.7393, -1.8920,  1.3421,  0.7321, -1.6623,  1.2890, -0.2299,\n",
      "        -1.7928,  1.4458,  0.4726, -1.8978, -1.0685,  1.9651,  1.0184, -1.5027,\n",
      "        -1.6159,  1.1044,  0.2031,  0.5593, -1.5977,  0.8614,  0.6262,  1.2969,\n",
      "        -1.2845, -1.0098, -1.8057,  0.8432,  0.5400, -0.4473,  1.2748, -1.0499],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 54 Predict 1141 zeros 542 ones, one bias 0.322044\n",
      "train loss: 2.06119436443019 dev loss: 1.5865361096247685\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.8275, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.4780, -1.1543,  1.4269, -1.1096,  1.3219, -1.9598,  1.4594, -1.1628,\n",
      "         1.6362, -1.6070,  1.5502,  1.5003, -1.1717,  1.1699, -1.2730, -2.4383,\n",
      "        -1.6108, -1.6008, -1.5242,  1.4475,  1.8931,  1.1375,  1.4150, -2.5136,\n",
      "        -1.0062, -1.3665,  1.3300, -1.6521, -2.1641, -1.5247,  1.4227,  3.5744],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.1373,  0.3518,  0.9105, -2.2123,  0.8916, -1.9562,  0.4940, -2.5523,\n",
      "         1.1581, -1.9853,  1.3009,  1.0228, -1.0644,  0.7609, -1.8763, -1.5067,\n",
      "        -1.7285, -1.9741, -2.1196,  0.6251, -1.9356, -1.2218,  0.8734, -1.8729,\n",
      "         1.3936, -1.8717, -1.4402, -1.7262, -2.0585, -0.2972, -1.0542,  1.6007],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.6701, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1584, -1.2811,  1.8074,  1.3059, -2.5136,  2.1066,  2.0000, -1.3744,\n",
      "        -1.5850, -1.8383, -1.5417, -2.4722,  1.3565,  1.8745, -2.0767, -2.7380,\n",
      "         2.6168,  1.4382, -1.2854, -1.9678, -1.0539,  1.1375,  1.1969, -1.2158,\n",
      "        -1.2665, -2.4041, -1.3102,  1.1444, -1.3138,  1.7300, -1.3077, -1.3727],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5222, -1.2406,  1.0807,  0.3327, -1.7228,  0.0638, -0.5481,  0.1334,\n",
      "        -1.3830, -0.3471, -0.6910, -1.1396, -1.1409, -0.6410, -2.4297, -2.4253,\n",
      "         1.0808,  0.3402, -1.7076, -1.0167, -1.6938,  2.0043,  0.9051, -1.6182,\n",
      "        -1.9021, -1.1809, -1.8859,  1.5895,  0.1312, -0.1353, -1.7743, -0.9246],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.8769, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9260, -1.4137, -1.6843,  1.1520,  1.4970,  2.0000,  2.0358, -1.1621,\n",
      "        -1.7168, -1.2397,  4.3631, -1.8846, -1.9005, -1.1339, -1.3204, -3.5034,\n",
      "         1.3577, -1.9715, -1.2685,  2.0000, -1.3278, -1.1211, -1.6866, -2.7370,\n",
      "        -1.3527,  1.4125, -3.2525, -1.8501, -1.4507,  1.5850, -1.8804,  1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1370, -1.5306, -0.9373, -1.1638,  1.1427,  0.6588,  1.0589, -0.9940,\n",
      "        -1.6672,  0.7450,  1.3684,  0.0551, -1.0830, -0.9360, -1.5178, -1.7874,\n",
      "         0.9382, -1.7924,  1.1719,  1.5286, -1.8571, -1.3575, -1.5972, -1.4799,\n",
      "        -1.7190,  1.5146, -1.4378, -1.5454, -1.4957, -0.4395, -1.5428, -1.3805],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.2904, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1058, -1.3020, -1.1147, -1.7355,  1.3529, -1.5271, -1.0766, -2.5095,\n",
      "         1.6848, -1.1197,  4.1761, -1.1069,  1.3173, -1.1726, -3.0809, -1.4594,\n",
      "         2.0810, -1.2097,  1.6323,  3.5850,  1.9240,  1.8272, -1.5850, -2.1115,\n",
      "        -2.0197, -1.6908, -1.5236, -1.1706,  3.4594, -1.3621,  1.4125,  1.1871],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2166, -1.7198,  0.2242, -1.0505,  1.3972,  1.8118, -0.4204, -1.3048,\n",
      "        -0.8138, -0.3888,  1.7485,  0.0465,  2.1369, -0.8855, -0.8789, -1.4610,\n",
      "         0.9022, -1.7978, -0.7927,  0.3830, -1.1007,  1.9206, -1.1038,  0.5057,\n",
      "        -1.6630, -1.6179,  0.6686, -1.1210,  0.1639, -1.6399,  0.6661,  1.7671],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.0485, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3278, -1.2663,  1.3814, -1.9260, -1.5151,  1.5656,  1.2198,  1.1069,\n",
      "        -1.0446,  2.3431, -1.5242, -2.3029, -1.5746,  1.3255, -1.3752,  1.4393,\n",
      "        -1.2682, -1.1726, -2.7370, -2.8073, -2.3152, -1.2680, -1.7144, -2.4432,\n",
      "        -2.0003, -2.0516,  1.2106,  1.0681, -1.9005, -2.0275, -1.5657, -4.0000],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6157, -1.6619,  1.0715, -1.2107, -1.7873, -1.0046,  0.7116, -0.5894,\n",
      "         1.2339, -1.6608, -1.0986, -1.5482, -0.5173, -1.3441, -1.3234, -1.0527,\n",
      "        -1.6294, -0.6628, -1.0491, -0.9273, -1.8175, -0.3913,  1.3750, -1.0858,\n",
      "        -2.0706, -1.6668,  0.3580, -1.2725, -1.4560, -1.0941, -1.6579, -0.6376],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.5671, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1434, -2.4525, -2.3978, -2.0504,  1.6722,  1.2316,  1.4854,  1.0608,\n",
      "         1.5324,  3.4175,  1.9126, -1.9069,  1.6172, -1.4695,  1.0712,  1.1839,\n",
      "        -2.3219,  1.1333, -1.1009, -2.4010,  1.9386, -1.7512, -2.0034,  3.5744,\n",
      "        -2.2076, -1.8138, -1.0827, -2.5428,  1.5332,  1.0380,  2.4060, -1.8819],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0277, -1.7541, -2.3930, -1.8608,  0.1039, -0.2072, -1.6039,  1.0658,\n",
      "         1.1851,  0.6091,  0.9709, -1.1972,  1.5276, -1.7788,  1.3623,  0.9695,\n",
      "         0.5919, -0.5537, -1.6970, -1.8604,  0.8040,  0.0211, -0.2601,  0.6106,\n",
      "        -1.1584, -1.7128, -1.9049, -1.1525,  2.4937, -1.5555,  0.3389, -1.5837],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 55 Predict 1079 zeros 604 ones, one bias 0.358883\n",
      "train loss: 2.071436091759831 dev loss: 1.6329248040861348\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.7274, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5817, -2.8073, -1.5850, -2.5850, -1.1211,  1.7974, -1.4482, -3.3966,\n",
      "        -1.2928,  4.0875,  1.7004, -2.7685, -1.4706, -1.7593,  4.7944, -1.7045,\n",
      "        -2.0275, -3.3219, -1.0342, -2.3708, -1.4159,  2.3219, -1.5492,  1.2357,\n",
      "        -1.2851, -3.4594, -2.4021,  1.6529, -1.8572, -1.2158, -2.0050, -1.5309],\n",
      "       device='cuda:0')\n",
      "tensor([-2.1303, -1.7409, -0.7972, -0.9628, -0.8061,  1.4351, -0.7559, -1.1371,\n",
      "        -1.4269,  1.1513,  1.5386, -1.7926, -0.0569, -2.2268,  1.2105,  0.8923,\n",
      "        -1.9030, -1.4766, -0.9926, -1.2297, -1.3723,  0.9896, -1.6053, -0.9408,\n",
      "        -2.1643, -1.6163, -0.6956,  1.5396,  0.5562, -1.2233, -1.1981, -0.2963],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.8790, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.2730, -2.8024,  1.3683,  3.4898,  2.4253, -1.2730, -1.3905,  2.4195,\n",
      "        -2.0000, -1.2854, -2.5136, -1.0518,  1.1082, -1.5432, -1.8240, -2.5443,\n",
      "        -2.0937, -1.5729,  1.1962, -2.0251, -1.1100, -2.3219, -1.0100, -2.4432,\n",
      "        -2.0767, -2.0657, -1.2465, -1.0875, -1.3111, -1.0815, -2.4021, -1.5850],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5291, -1.8987,  0.5112,  1.4282, -1.7494, -0.6858, -1.6298, -0.7196,\n",
      "        -1.6885, -1.6669, -1.2029, -1.3586,  1.3404,  0.0763, -1.5735, -1.0189,\n",
      "        -1.2088,  0.4423, -1.6341,  0.9477, -0.3898,  0.7705,  0.1061, -1.3183,\n",
      "        -1.8254,  1.5998, -0.0225, -1.1824, -1.6399, -1.4983,  0.4284, -0.2469],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.8414, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2685, -1.9069,  2.3431, -2.8157, -1.3878,  2.1375,  3.9680,  2.4479,\n",
      "         1.8221,  1.3212, -1.6854, -2.6400, -1.9260,  1.2633, -1.6025, -1.4094,\n",
      "        -1.0345,  2.1255, -2.1801,  1.5850,  1.5036,  1.8192, -1.2752,  1.3685,\n",
      "         1.0067,  1.2977, -1.6700,  1.5360, -1.9418, -1.8745, -1.2486, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4659,  1.0810,  0.8028, -1.4834,  0.5327, -2.1079,  2.5710,  1.0058,\n",
      "         1.4830,  1.3435, -2.1330, -1.9725, -1.2692, -0.4086, -1.8246, -1.8303,\n",
      "        -0.6957,  0.9028, -0.1892,  0.7178,  1.6616, -0.4266, -1.3968,  0.9441,\n",
      "        -0.3925, -1.9224, -1.9211, -0.0831, -0.5285, -1.4278, -1.2212, -1.3633],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.3407, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.7004,  2.1467,  1.7370,  1.3931,  1.0728,  1.2407, -1.8401, -2.9696,\n",
      "        -1.2936,  3.1949,  1.1520, -1.8747, -2.4595, -1.1100, -1.4894,  3.0000,\n",
      "        -1.4191,  2.3153,  1.1988, -1.8561,  1.1962,  1.6894, -1.2888,  2.6786,\n",
      "         1.3137, -2.3219, -1.9668, -1.1543, -2.3188, -1.3050, -1.1543, -1.7004],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3055,  1.4398, -1.1194,  1.2194,  1.3743, -1.5524, -0.5987, -1.2823,\n",
      "        -0.1574,  2.0974,  1.2317, -1.9899, -1.6891, -1.9602, -1.7464,  1.6450,\n",
      "        -1.6499,  1.1232, -1.7906, -1.9101, -1.8316,  2.4768, -1.6746,  0.6118,\n",
      "         1.2778, -1.6419, -1.7396,  1.2797, -1.9501, -1.8719,  0.5763,  1.2019],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.9908, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0311,  1.6818,  1.5487, -1.9307, -2.0907, -1.0153, -1.8458,  1.7914,\n",
      "         2.7798, -1.1630, -1.0766, -2.2301,  1.0747,  1.8221,  1.2545, -1.5113,\n",
      "        -1.7923, -1.8977, -1.2638, -1.8330, -1.3745, -2.0000,  2.6586,  1.7701,\n",
      "         1.7010, -1.9401, -1.2139,  2.5571, -2.4908,  1.3219, -1.1778,  1.4527],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2990,  2.0641,  1.2235, -1.7763, -1.9730, -1.9344, -0.7571, -1.1368,\n",
      "         2.1492, -1.2346, -1.3769, -1.7395,  0.7864,  0.6839,  0.7912, -0.7959,\n",
      "        -2.4662, -1.7990,  0.1774,  1.2863, -1.3528,  0.5187, -0.0152,  0.1309,\n",
      "         1.3737, -1.0103, -1.2610, -0.2846, -1.8824,  1.8160,  0.4989,  1.2418],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2463, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3550, -1.0669,  2.5850, -1.2397,  2.1155, -2.1437,  1.0384, -2.2676,\n",
      "         1.7914, -1.3624, -1.2122, -1.4111,  1.9689, -1.0700, -1.8313, -1.1806,\n",
      "         1.7914, -1.1065, -2.7497, -1.9005, -1.4250,  2.0195,  1.5596,  1.7078,\n",
      "         1.6618, -1.9778, -1.3398,  1.3532, -1.8680,  1.9723,  1.1785,  1.1962],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8514, -2.3720, -0.6691, -1.0646,  1.1871, -0.9565,  1.9306, -1.1909,\n",
      "         0.3275, -1.7463, -2.0164, -1.1456,  0.9822, -1.7075, -1.6538, -0.8346,\n",
      "        -0.8295, -1.9007, -2.1356, -1.1941, -1.9755,  1.0045,  1.9585, -1.6386,\n",
      "         0.7824, -1.2542, -1.6645,  0.3910, -1.6502,  1.7711,  1.0909, -1.8003],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 56 Predict 1094 zeros 589 ones, one bias 0.349970\n",
      "train loss: 2.005709732947897 dev loss: 1.5020608327560379\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.7139, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5475, -1.4706, -2.7482,  1.6818, -1.8458, -1.7045, -1.0070,  1.6172,\n",
      "         1.3196,  1.4134, -1.6031, -1.6696,  1.3332,  1.0826,  1.2022,  3.0760,\n",
      "         3.3923, -2.1155, -1.5194, -1.1970, -1.9418,  1.0024, -2.7225, -1.0308,\n",
      "         1.2167, -2.7307,  1.2167,  1.2633, -1.1973, -3.3709, -1.9175, -2.3141],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6167, -1.7477, -1.8070,  2.4196, -1.2524,  0.5366, -0.0805,  1.1982,\n",
      "         0.6757,  1.2899, -0.6689, -0.7372,  1.3298,  0.0360, -0.3564,  1.0968,\n",
      "         0.6953, -1.6190,  0.4614, -1.7723, -1.0422,  1.2334, -1.7261, -1.4412,\n",
      "        -1.0026, -1.3537,  0.3061,  1.1340,  0.4237, -1.2378, -1.2182, -1.7029],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.1057, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1226,  1.0776, -1.9879,  1.4053, -2.8524, -1.3745, -1.6916,  1.0331,\n",
      "         4.9357, -1.8745,  3.2720, -1.6630, -1.7970,  1.2167, -2.5095,  1.9809,\n",
      "        -1.3923,  1.2843, -2.1234, -2.3254, -1.2070,  1.1852,  2.0500,  1.1375,\n",
      "         1.2044,  2.6825,  1.3219, -3.5443,  1.3866, -1.0970,  1.8171,  1.1537],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.9784, -0.8484, -1.1429,  0.4476, -1.0418, -0.2580, -1.7742,  0.9353,\n",
      "         2.1779,  0.6077,  0.4370, -1.0711, -0.9030, -1.5501, -1.9747, -1.6229,\n",
      "        -1.3162,  1.0251, -1.5398, -1.7478, -1.9916,  1.2091,  1.2087, -0.1684,\n",
      "        -0.1520, -0.1677,  0.2656, -1.6499,  1.4172, -1.6695,  0.1805, -1.4228],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.1040, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0657, -1.5224, -1.8580, -3.0508,  1.0056, -2.9386,  1.3392,  2.1123,\n",
      "         2.0000,  1.2106, -1.2058,  1.1319, -1.0999, -1.5265, -1.6521, -2.3219,\n",
      "         1.3986, -2.6323, -2.1309, -1.1833,  2.2334,  1.7000, -1.0875,  2.0940,\n",
      "        -2.4234,  2.0211,  1.4370, -1.5469, -1.0062, -3.5850,  1.1483, -1.5498],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5322, -1.4112, -1.0866,  0.3355,  1.2467, -2.2018,  2.0152,  1.7139,\n",
      "         1.4888,  0.8475, -0.7848,  1.9589, -2.3666, -1.5592, -2.3686, -1.0708,\n",
      "         0.8592, -1.9152, -1.9691, -0.0479,  1.7343,  0.2226,  0.9032,  1.1654,\n",
      "        -2.2351, -0.1122,  1.4614, -1.7457,  1.3405, -1.2343,  0.9534,  1.7302],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.1456, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3532, -2.0241, -2.3219, -1.1625,  2.3219, -1.1889, -3.5443, -1.3055,\n",
      "        -2.0666,  2.6553,  1.1076, -1.4191, -1.1375,  1.4053, -1.6280,  1.1926,\n",
      "         1.3219, -2.0360, -2.0516,  1.2907,  2.1463,  2.3046, -1.2232, -3.1193,\n",
      "        -1.0370, -1.5422, -1.0308, -2.5850,  1.9809,  1.4053, -1.8572,  1.4957],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4883,  1.0945, -1.7164, -1.4412, -0.6819, -0.6170, -0.2759,  1.3576,\n",
      "        -1.8137,  0.3374,  0.5707, -1.5785, -1.9789,  2.0997, -0.9405,  2.1002,\n",
      "         1.0878, -1.8200, -1.7730, -0.6527,  0.3949,  1.0205, -1.8335, -1.3875,\n",
      "         1.1884,  0.1228, -0.8139, -1.7472, -1.8873,  1.0612,  0.1919,  1.3506],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.2051, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6894, -2.2301,  2.0000,  1.0654, -1.3973,  1.1375, -1.5850, -1.7814,\n",
      "         2.3219, -2.1699,  2.1139, -1.2479,  1.3219,  2.4490,  1.0473, -1.4081,\n",
      "         2.3219, -1.9069, -1.8433, -2.2850, -2.3219, -1.6717, -1.5151, -2.4595,\n",
      "         1.4527, -1.1822, -1.8470, -1.7923, -1.7909, -3.0704, -1.5850, -1.4894],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3747, -1.7183,  1.9515, -0.2040, -0.1026, -0.5566, -0.5227,  0.9217,\n",
      "         0.1696, -1.0390,  0.2631, -1.5326,  1.0774,  1.9975, -0.0473, -1.0797,\n",
      "         1.1739, -1.1479, -1.9341, -1.7247, -1.3072, -1.7646, -1.4726, -1.5637,\n",
      "         1.7554, -0.2665, -1.6338, -1.6286, -0.5455, -1.7819, -0.9416, -1.7084],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.4973, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2139,  1.3484, -1.1699, -2.4041, -1.5170,  1.4052,  2.4328, -1.7011,\n",
      "        -2.2895,  2.4060,  1.8745, -1.3530,  1.7125, -1.2227,  1.2170,  2.3713,\n",
      "         1.2538, -1.3740, -1.5623, -2.0796,  1.2546, -1.7047, -1.0311, -1.2227,\n",
      "         1.4387, -1.5729,  2.6800,  2.0946, -1.6129,  1.7401, -1.7262, -1.1375],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5898,  0.2098, -1.5002, -1.1312, -1.7912,  2.5704,  1.2215, -1.9137,\n",
      "        -1.7022,  1.7790,  0.1538, -1.9816,  1.1095, -1.8416, -0.4239,  0.9059,\n",
      "        -0.0579, -1.9374, -1.8041, -0.8514, -0.2444, -1.6869, -1.9892, -1.9488,\n",
      "         0.5616,  0.2672,  1.9111, -1.4100, -1.6820,  0.5869, -1.4162, -0.4331],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 57 Predict 1023 zeros 660 ones, one bias 0.392157\n",
      "train loss: 2.069817126246779 dev loss: 1.496002237758489\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.4868, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.0558, -1.4962, -1.0583,  2.5850, -2.0324,  3.6781,  1.0954, -1.8977,\n",
      "        -1.2680,  1.1962, -2.4595,  2.0266, -2.9500,  2.2630, -2.1445,  2.5062,\n",
      "         1.1371,  1.9126, -1.7574,  2.0000, -3.4044, -1.3656, -1.3292, -1.3111,\n",
      "         2.0000, -2.2676, -1.0243,  2.9519, -2.3738, -1.1478, -1.7370, -1.0308],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.2033, -1.3871, -1.9618,  0.5091, -1.7596,  2.6631,  1.6144, -1.7622,\n",
      "         1.4928, -1.7760, -0.8494, -0.5725, -1.0664,  1.0442, -1.8901,  1.6171,\n",
      "         1.2405,  1.0134, -1.3225, -1.8019, -2.1005, -1.8637, -0.3106, -0.9649,\n",
      "         1.3233, -0.2844,  0.2015,  0.9275, -2.1252, -1.3366, -1.6963, -1.0242],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.5937, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0393,  1.7370,  1.2390,  2.9341, -2.0000,  1.0841, -1.1317,  1.0572,\n",
      "         1.7788, -1.8458,  3.2721, -1.1165, -1.0659,  1.3941,  1.4150,  2.4996,\n",
      "        -1.3219, -1.3621, -1.7082, -3.7603,  1.5596,  1.0680, -1.0431, -2.4908,\n",
      "         4.7944, -1.2854, -1.2736,  1.5850, -2.0630, -1.0088,  2.9014, -1.8433],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6986,  0.7859,  2.0568, -0.1497, -1.9966,  0.9452, -0.9039,  1.7265,\n",
      "         1.0890, -0.8533,  1.2545, -1.7816, -1.8936,  1.2136,  1.1941,  1.3143,\n",
      "         1.0126, -1.6251, -2.1060, -2.4254,  1.1843, -1.5880,  0.1543, -2.0506,\n",
      "         0.5058, -2.1407, -2.1554, -0.3226,  0.1452, -1.8710,  1.7317, -1.1558],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.1340, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6347, -1.5850, -1.6265, -1.6781, -1.7998, -1.0343,  2.0810, -1.0233,\n",
      "         1.5297,  2.3219,  3.1414, -1.8458, -1.0995, -1.2988, -2.9681,  1.8592,\n",
      "        -1.6321,  1.3219,  1.5491, -2.2076,  4.2479,  1.8705, -1.0962, -2.3372,\n",
      "         1.2064, -2.1027, -1.0327, -1.0308,  2.9069,  2.1625, -1.0766, -1.3822],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5545, -0.2884, -1.8583, -1.3064, -0.5540, -1.6042,  1.1677,  1.4250,\n",
      "         2.2965,  0.7760,  0.5643, -0.9616,  0.9732, -1.4161, -1.6783,  0.8200,\n",
      "        -1.6663,  0.1280,  0.3228, -1.1188, -1.2498,  1.0092, -1.4186, -1.3693,\n",
      "         0.1661, -1.3960, -1.8867, -0.2824, -0.2807,  1.2455, -1.5294, -1.3441],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.0566, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8403, -1.1018,  1.0481,  1.2316, -1.1737,  1.2630, -1.3219, -1.8580,\n",
      "         1.2988, -2.2076,  2.9519, -1.2755,  1.2111,  1.4651,  1.7650,  2.3219,\n",
      "        -1.1979, -1.1147, -3.6897, -1.2778, -2.3219,  1.0767, -2.5850, -1.5294,\n",
      "        -1.1699, -2.4010, -4.0875,  2.1123,  1.7370,  2.0666, -1.9778,  1.3943],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9469, -0.0244, -1.0563, -0.0252, -0.2653,  1.5234, -0.2154, -1.0310,\n",
      "         1.0089, -1.5735,  0.9976,  1.2159,  1.4185, -1.4436, -0.0319,  0.0805,\n",
      "        -1.5722, -1.2064, -1.6062, -1.7487, -0.8578,  1.6942, -0.9181,  0.7608,\n",
      "        -1.7970, -1.7945, -1.3921,  2.0774, -0.2660, -1.1519, -1.2255,  0.5951],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.5379, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.2638, -1.0153, -1.6828, -1.6800,  1.5850,  1.5850, -1.0639, -1.0995,\n",
      "         1.1839, -2.4595,  2.0471, -1.4936,  1.1537,  1.5360, -1.7370, -1.1100,\n",
      "        -1.2547,  1.5580,  2.3363,  1.7604, -1.2058, -1.1615, -1.6700,  1.0680,\n",
      "        -1.7744, -1.0697,  1.3219, -1.7609,  2.7700, -2.6857,  1.0669,  1.7309],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8668, -1.1924,  0.0661, -0.8065,  0.4032,  0.4386, -0.7369, -0.3959,\n",
      "         0.9034, -1.8453,  0.0327, -0.9444, -0.1791,  0.9982, -1.8594, -1.8597,\n",
      "        -1.1780,  1.0242, -0.8745,  1.2861,  0.3330,  0.0197, -1.7867, -1.6807,\n",
      "        -0.7748, -1.0892,  0.9628, -2.2238,  1.5923, -1.9132, -1.2273,  1.0787],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.3491, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1520, -1.5376, -1.3902, -1.8804, -1.9260, -1.1876,  1.1699, -1.7168,\n",
      "        -1.8458, -1.1699, -2.0324, -3.0000, -1.2088,  1.2446,  1.4099, -1.4400,\n",
      "         2.0327, -1.4533, -1.8931,  1.5722,  2.5775, -1.3772, -1.9370,  1.5663,\n",
      "         2.0358, -1.8745, -1.5633,  1.9220,  3.0558, -1.2224, -1.3624,  2.7651],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7177,  1.4967, -1.6049, -0.0079, -1.3694, -1.4943, -1.0782, -2.0360,\n",
      "        -1.3611, -1.8664, -1.2933, -1.2253, -1.8406,  0.1134, -0.5809, -1.5732,\n",
      "        -0.1498, -0.8295, -1.7557,  1.3244,  1.1884, -1.8746, -0.6676,  1.3133,\n",
      "        -0.0380, -0.4589, -1.5615,  0.8511, -0.5007, -1.0965, -1.6389,  0.8731],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 58 Predict 1172 zeros 511 ones, one bias 0.303624\n",
      "train loss: 2.106097627574836 dev loss: 1.835793723668604\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.5036, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7168,  1.6172,  2.3835,  1.0545, -1.0522, -1.0639, -1.1336,  2.1806,\n",
      "        -1.2682,  1.1929, -2.1722, -3.0000, -1.8433, -2.8342,  1.5676,  1.3577,\n",
      "         1.3785, -1.2801,  2.9942, -1.0345,  1.1699, -1.2111,  2.7549,  1.3814,\n",
      "        -1.2730, -1.8749,  1.3219,  2.4279,  3.0760, -3.5480,  2.2331, -1.1597],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0296,  1.1734,  1.2200,  1.6949, -1.0277, -1.4237, -1.9315,  1.1177,\n",
      "        -1.7049, -1.2340, -1.4910, -1.5290, -1.4187, -1.0886,  0.8493,  1.5218,\n",
      "         1.1878, -1.6914,  1.8597, -1.7818,  0.3559, -2.0270,  1.1438,  1.5317,\n",
      "        -1.7679, -2.2980, -1.0789,  1.7833,  1.2237, -2.3737, -0.2532, -1.2018],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.3034, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8875, -2.2624,  2.1325, -1.5025,  1.3001,  1.5606, -3.1699, -1.8042,\n",
      "         1.1926, -1.6265,  1.4125, -1.1970, -1.1508, -1.3219,  1.6147,  3.1430,\n",
      "        -1.4594,  1.4227,  1.0054,  2.1699, -1.5078, -2.0287, -1.4088,  1.3468,\n",
      "        -1.4482, -1.9704, -1.8977, -1.2241, -1.3450, -2.8712, -2.1727,  1.0797],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9873, -1.8831,  0.9747,  1.1639,  1.7205, -1.9909, -0.4857,  1.7114,\n",
      "         1.9664, -2.6334,  1.1085, -1.9768, -1.8061, -0.3936,  1.3950, -1.0461,\n",
      "        -1.7819,  1.1385,  0.2507, -1.4000, -0.6909, -2.0492, -1.8501,  0.4085,\n",
      "        -1.1682, -2.1626, -1.8575, -2.1210,  1.5401, -1.2711, -1.9493,  0.7413],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.4683, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2167, -1.5247,  1.4639, -1.2637, -1.1726, -2.7370,  1.7162, -1.3336,\n",
      "        -1.3527,  2.4060,  1.9167, -1.3425, -1.5422,  2.7176,  1.0750, -2.0502,\n",
      "         1.0666, -1.8804, -1.1965, -2.1113,  1.4387,  3.3847,  1.6594,  1.1155,\n",
      "         1.7124, -1.7082, -1.4159, -1.8863,  1.3510,  1.6147,  2.3474, -1.8924],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8770, -0.9524,  1.5338, -2.0579, -1.1613, -1.5959,  1.2955, -0.9529,\n",
      "        -2.0878,  1.4966,  1.0743, -1.3023, -0.7124,  0.9409,  0.9306, -2.2140,\n",
      "         0.5475, -0.8758, -1.7026, -1.9635,  1.0310, -0.2880, -0.1384,  1.3309,\n",
      "         1.6104, -2.0848, -1.1794, -2.0411,  0.9212,  1.0551,  1.4233, -1.9600],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.4636, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0050, -1.2630,  1.0347, -1.3624,  4.3923,  1.2354,  1.1699,  1.8931,\n",
      "         1.8705, -1.9814, -4.5850,  1.7914, -1.7287,  1.1555,  2.5384,  1.8122,\n",
      "        -1.4642, -2.0937,  1.5624,  1.5400, -1.2630, -2.3626, -2.3219,  1.1844,\n",
      "        -1.7411,  1.1878,  1.1203, -2.1405, -1.5355,  1.8226, -1.3263, -1.2479],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5357,  0.2658,  0.0643, -0.4293,  0.6285,  0.2840, -0.9286, -1.4380,\n",
      "         1.4319, -1.4685, -1.5106, -0.0621,  1.9217,  1.1362,  0.4547,  2.2180,\n",
      "        -1.5322, -1.4700,  0.8774,  0.8962, -0.7428, -1.0709,  0.0761, -0.4986,\n",
      "        -1.2655, -1.1901,  1.4186, -1.5184, -1.3795, -0.9255, -1.6047, -0.8875],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1842, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0987,  1.9016, -1.3102, -1.6978, -1.3336, -2.2066,  1.8192, -1.1155,\n",
      "        -1.5850, -1.8433,  1.2855, -1.8716,  1.5071, -1.0308, -1.3085, -2.0368,\n",
      "        -1.0999,  2.1345, -1.3656,  1.0718,  1.6719, -1.0153,  2.0000,  1.3651,\n",
      "        -1.6696, -2.7004,  1.6706,  1.7370, -1.8458,  1.6909, -1.2112, -1.1205],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.4721,  1.9352, -1.6596, -1.8092,  0.4564, -1.5397,  1.1086, -1.1974,\n",
      "        -1.2347, -1.3101,  0.9229, -0.8058, -2.2557,  0.8100, -1.5237, -1.4990,\n",
      "        -1.7555,  1.5006, -1.7912, -0.8951,  0.9157, -1.6645, -1.8177,  1.3484,\n",
      "        -1.6105, -0.9157, -0.9876,  0.6593, -1.0847,  1.1629, -1.6105,  1.2662],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.7778, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9778,  1.7370, -1.0028, -2.0000,  3.0558, -1.2814, -2.3019,  1.0189,\n",
      "         2.0000, -1.9778, -1.7386,  1.2087, -1.7843,  1.5915, -1.2659,  1.1069,\n",
      "        -1.0966,  1.0961, -1.0592, -1.1319, -1.5633,  1.4232, -1.1155,  2.3692,\n",
      "        -1.1782, -1.1960,  1.3219, -1.5705, -1.8504,  1.2313, -2.6041, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-7.1524e-01,  1.0291e+00, -2.0490e+00, -7.1507e-01,  1.5522e+00,\n",
      "        -3.8557e-01, -8.8892e-01, -1.0389e+00,  1.4665e+00, -8.2959e-01,\n",
      "        -2.0332e+00,  2.1520e-03, -9.9801e-01,  1.1194e+00, -4.0682e-01,\n",
      "        -1.4297e+00, -1.0834e+00,  7.1424e-01,  1.2833e+00, -8.7618e-01,\n",
      "        -2.6450e+00, -1.5995e+00, -1.3903e+00,  1.0554e-01, -1.2635e+00,\n",
      "        -1.4652e+00,  5.2951e-01, -1.1488e+00,  7.4501e-01,  1.0014e+00,\n",
      "        -1.8154e+00, -1.0905e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 59 Predict 1033 zeros 650 ones, one bias 0.386215\n",
      "train loss: 2.0320216450447717 dev loss: 1.6179364416161015\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.1553, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7358, -1.3039, -2.6924,  1.8745, -1.3398, -1.1926,  1.7162, -1.9778,\n",
      "         1.0478,  2.0000, -2.6656, -1.8480, -1.1656, -1.7405, -1.3020, -1.3046,\n",
      "         1.1699,  2.8705,  1.0780,  1.5220, -1.6084, -1.8401, -1.0522,  1.0056,\n",
      "        -1.5534, -1.1628, -1.5024,  3.4898, -4.7549,  1.7287,  1.7914, -1.5523],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4511, -1.1450, -1.9752,  1.8268,  0.3863, -1.7335,  1.4621, -1.0801,\n",
      "        -1.0890,  1.2727, -1.7784,  1.1159,  0.8473,  1.0190, -1.5787, -1.3801,\n",
      "         1.6127,  0.6441, -1.1698,  1.1794, -0.2157, -1.0363,  1.5941, -1.0798,\n",
      "        -1.8385, -2.1548, -1.3765,  1.7543, -0.5819,  1.7396, -1.3335,  0.6922],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.3786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5850, -2.5794, -2.2730,  1.0572, -1.2682, -3.3219,  1.1375,  1.0122,\n",
      "        -1.6912,  1.5663, -2.6477,  3.0255, -1.3424, -2.7199,  3.2591,  1.6630,\n",
      "        -1.5850,  1.3219,  3.9307,  1.7300, -1.3138, -1.4706, -1.2224,  1.3215,\n",
      "        -1.5817, -2.0995,  2.1255, -1.5827,  2.7798,  2.5823,  1.7382,  1.8182],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7012, -1.0166, -1.6797,  0.9250, -0.9992, -1.6577,  1.2021, -0.9873,\n",
      "        -1.6689,  1.0430, -1.1346, -1.4151, -1.5544, -1.1373,  2.4754, -1.2566,\n",
      "         0.3064,  1.4443,  1.0463, -0.0924, -0.4407, -1.1433, -1.8550,  1.1074,\n",
      "        -1.3141, -1.5931, -0.9228, -1.7619,  1.0235,  1.3587, -1.3013,  1.5111],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.9757, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3119,  1.0177,  1.8467, -1.8391, -1.3054,  1.4411, -1.2397,  3.2809,\n",
      "        -1.3278,  1.9809, -1.6265,  1.1278,  1.0669,  2.0875, -1.8804, -1.3870,\n",
      "         1.3986, -2.4594, -4.3219,  1.5850,  1.5915, -1.6108, -1.9678,  1.3931,\n",
      "        -1.7309,  1.3219,  3.4594, -1.8251, -2.3372, -1.1737,  2.0118, -1.2685],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2159, -1.2009,  0.9722, -1.7141, -0.5906,  2.2726,  0.7723,  1.1156,\n",
      "        -1.6676, -1.2351, -1.7197,  0.8278, -1.5426, -0.0582, -0.8499, -0.1997,\n",
      "         1.0237, -0.4602, -1.2055,  0.9242,  0.4640, -1.6825, -0.9730,  1.0976,\n",
      "        -1.6779,  1.7764,  0.6427, -1.6347,  1.2184, -1.8883,  1.6036, -0.9502],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.2364, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2606, -3.1699, -1.5850,  1.3219,  1.1822, -1.4695,  1.5267,  1.2070,\n",
      "         1.8160,  1.2346,  1.3683, -1.8138, -1.1540, -1.3621,  1.2677, -1.5151,\n",
      "        -1.4256, -2.3854,  1.5438, -1.8945, -2.3161,  1.2842, -1.2752,  1.0770,\n",
      "         1.3101,  1.1520,  1.4854,  2.2748, -1.0522, -1.5236,  1.6323,  1.5491],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6224, -1.7322, -0.1747,  0.8845,  0.8961, -1.7419,  0.7733,  0.7235,\n",
      "         1.3669,  1.1850,  0.9157, -1.9929,  0.2170, -1.9037,  1.0906, -2.0214,\n",
      "        -1.2028, -1.7808,  1.0170, -1.9578, -1.8156,  1.2461, -1.0869, -0.7668,\n",
      "         1.2373, -0.3123, -0.3364, -0.6357, -0.9521, -1.7572,  1.3550,  0.2455],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.7874, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0669,  3.5850, -2.4429, -1.7370, -1.1024,  1.4970, -1.9778, -1.0523,\n",
      "         1.1537, -2.0343, -1.3581,  1.0099,  1.1069, -1.6521, -2.2750, -2.7004,\n",
      "        -3.3923,  1.5240, -1.7004,  1.1822, -1.3219,  2.1825, -2.0395,  1.4535,\n",
      "        -1.2479, -2.0657, -1.3204, -1.3745,  1.8705,  1.0780,  1.4053,  1.4099],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1205,  1.5822, -1.7398, -0.9191,  0.5536,  0.4588, -1.5120, -0.7495,\n",
      "         1.6688, -1.6872, -0.8580,  0.1630,  0.6194, -1.6759, -1.5891, -1.2689,\n",
      "        -1.4094,  1.1170,  0.7250, -0.2531, -0.7408,  1.3608,  0.5178,  1.1690,\n",
      "        -1.0064, -0.1919, -1.3385, -1.1787,  1.7918, -1.5323,  0.7675, -1.2832],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.6516, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0211,  1.0992, -1.8747,  1.9608,  1.2979, -1.4791, -1.0153,  1.3565,\n",
      "        -1.0308,  2.0810,  1.1530, -1.8572,  1.8074, -2.9798, -1.7655, -1.0345,\n",
      "         1.3219, -1.0952, -1.1975,  1.0993, -1.0646,  1.1779, -1.9778,  2.0682,\n",
      "        -1.2783,  1.1993, -1.4855, -3.0000,  1.3711, -1.8572,  1.1871,  1.0119],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.7829, -0.6052, -1.0160,  0.7204, -1.0357, -0.9989, -1.2067, -0.4146,\n",
      "        -1.6127,  2.5222,  1.5300,  0.9126,  0.3578,  0.9117,  0.2689, -1.2648,\n",
      "        -0.8025, -1.6015,  0.0217, -1.7258, -1.4051, -0.2907, -0.9611,  2.0191,\n",
      "         1.0168,  1.0268, -0.1283, -1.0318,  1.0745,  0.1210,  1.4124,  1.4206],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 60 Predict 1118 zeros 565 ones, one bias 0.335710\n",
      "train loss: 2.0201871687419146 dev loss: 1.574981883620308\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.9258, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0774, -2.3318, -2.3536,  1.1183, -3.2627, -1.9678,  2.5546, -1.6924,\n",
      "        -1.7047,  1.8226,  1.4275, -2.0553, -1.1072,  1.7148, -1.2929, -2.0000,\n",
      "        -1.4711, -1.9260,  1.0954, -1.8458,  1.4493,  2.3431, -1.1656, -2.6999,\n",
      "        -1.9069,  2.0079, -1.4365, -2.6640,  1.7300,  2.0506, -1.8319,  1.3580],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4152, -1.9903,  0.8323,  1.5166, -2.0067, -1.4864,  2.8824, -1.5063,\n",
      "        -2.0933, -1.3030,  0.9309, -1.8558, -1.0518,  1.6492, -2.0396, -1.1225,\n",
      "        -1.6334, -1.1020,  1.2525, -0.8290, -0.6481, -1.8864, -1.4175, -0.1538,\n",
      "        -1.1871,  1.1086,  0.5632, -1.8468, -1.4655, -0.2168, -1.9392,  1.7366],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.6162, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.4866, -1.2929,  1.8260, -1.8598, -2.0666, -2.3923, -1.1265, -1.5102,\n",
      "        -1.2129, -1.5661,  1.5003, -1.5208, -1.7744, -2.3738, -2.4780,  1.1839,\n",
      "        -1.5729,  2.6215, -2.1905,  1.2633, -1.3111,  2.2926, -1.1975, -2.1115,\n",
      "         1.7914, -1.1630, -1.1935, -1.2730,  1.3293, -1.9260,  2.2536, -1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4079, -1.8940, -1.0931,  0.9606, -1.8742, -1.7896, -0.4292, -1.8930,\n",
      "        -1.9432, -1.5071,  0.6892, -1.2014, -0.4150, -2.3368,  1.1688,  0.9264,\n",
      "         0.1680, -0.0385, -0.3070,  2.8168, -1.9737,  0.5913,  1.2023, -1.3930,\n",
      "        -0.4776, -0.6935, -0.0993, -1.1183,  0.3264, -0.6928,  0.9477, -0.2429],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.9887, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0506, -1.8228, -3.3219, -1.0658,  1.6818, -1.4533,  2.4156, -2.4417,\n",
      "        -2.4420, -1.9069,  2.2630,  1.3334,  1.6172,  2.7111, -1.8975, -2.3219,\n",
      "         2.7549,  1.2316,  1.0841,  1.3419, -2.4595, -2.6630,  2.0623,  1.2603,\n",
      "        -1.9635, -1.4406, -2.3575, -1.5198, -2.1727, -1.7923, -2.4594, -3.4215],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8594, -1.6129, -1.7780, -1.3793,  1.4012, -0.7384,  1.4038, -1.8370,\n",
      "        -1.6997, -1.4262,  0.9440, -1.2120,  1.1236,  1.4251,  0.6599, -1.4867,\n",
      "         0.0471,  1.2436,  0.9474,  1.1838, -1.6512, -1.2410,  0.7499,  0.6639,\n",
      "        -1.5686, -0.8985, -1.7039, -1.1734, -1.6035, -1.7560,  0.9448, -1.7003],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.6244, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.0511, -1.3785, -1.6130,  1.8826, -2.0937, -2.9696,  1.3219, -1.7029,\n",
      "         1.0902,  1.2538,  1.0054, -1.6889, -2.3003,  1.0677, -1.3765,  1.9689,\n",
      "        -1.9879,  1.5850, -1.7935, -2.5931, -1.9069, -1.2142,  1.0704,  1.4227,\n",
      "         1.3196, -2.4263,  2.2273,  1.1527,  1.5220, -1.5360,  1.1988, -2.5124],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4010,  0.0958, -1.6907,  1.7754, -1.3584, -1.6158,  0.9779, -0.2342,\n",
      "        -1.2766, -0.8051, -0.5693, -1.7704, -1.7769, -0.7334, -1.6910,  0.6187,\n",
      "        -0.2526,  0.8726, -0.4248, -1.6317, -1.2458, -0.6514,  1.0821, -0.1996,\n",
      "        -0.1516, -1.9809, -1.0555,  0.5045,  1.4903, -1.9722, -1.5407,  1.5131],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.8726, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0180,  2.9069,  1.4981, -1.7287, -1.3282, -1.1694, -1.5236,  2.1896,\n",
      "        -1.6908, -1.5850, -1.1155,  4.7944,  1.1669,  1.3498, -1.0999, -1.4451,\n",
      "         2.5850, -1.1155, -1.9778, -1.1459,  1.2988, -2.0000, -1.5271, -1.5194,\n",
      "         1.0452,  1.2002, -1.3149, -1.0870,  1.2752, -1.4594,  1.8931, -2.4595],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1114,  1.5105,  0.6605, -1.0670, -0.4121, -1.8936, -0.6872, -1.7132,\n",
      "        -1.2499, -1.3078, -1.0503,  1.6404, -0.4457,  1.7119, -1.6580, -0.5644,\n",
      "        -1.1221, -1.0592, -1.4401, -1.7497,  0.9501,  0.2037,  0.1757,  1.0159,\n",
      "         1.8882, -0.3584,  0.5234,  0.4665,  1.5513, -1.7608,  1.4170, -1.2640],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.3173, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9778,  2.6800, -1.3624, -1.8365, -2.9265,  2.4328, -1.9635, -2.6214,\n",
      "         1.9662, -1.5475, -2.4829, -1.2613,  1.2303, -1.3204, -1.5850,  2.1467,\n",
      "        -2.3219,  1.0478, -1.0995,  1.3219, -1.7309,  1.4671, -1.7386,  1.7677,\n",
      "         1.9220, -1.2685, -2.3219, -1.4191, -1.2682,  1.9260,  2.9289, -1.3455],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0753,  1.1270, -1.9120, -1.0665, -1.7650, -0.9304, -0.7161, -2.1824,\n",
      "         1.1579, -0.1831, -1.7010, -0.5989, -0.3961, -1.6808, -0.8562,  0.2165,\n",
      "        -0.9004, -0.9671, -1.0657, -0.8989, -1.8121, -1.2614, -1.9559, -0.8594,\n",
      "         0.5613, -0.8934,  1.5295, -1.5796,  0.6409, -1.4559,  1.1241, -1.2176],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 61 Predict 1085 zeros 598 ones, one bias 0.355318\n",
      "train loss: 1.9755358869108346 dev loss: 1.4251694127536119\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.3916, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.6924, -1.1976, -1.5979, -1.1750,  1.8429,  1.3773, -1.2659, -2.7023,\n",
      "         2.9341,  1.5331, -1.8074, -2.0324,  1.0614,  2.1066, -2.1641,  1.0275,\n",
      "        -3.6114,  3.0255,  2.4924, -3.3966, -2.0275, -1.3923, -2.0725, -2.0082,\n",
      "         2.2536,  1.0380, -1.1791, -1.6415,  2.3575, -2.1905, -1.2713, -1.9005],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7728, -1.1983,  0.0318, -1.9140,  1.1631, -1.1882, -0.0623, -1.7157,\n",
      "         1.3637,  0.8972, -1.8172, -1.6967,  0.1780,  0.8407,  0.8333, -1.5914,\n",
      "        -1.0368, -0.2439,  1.2179, -0.3951, -1.5985, -0.2004, -1.6145, -1.4092,\n",
      "         1.3374,  0.8227, -1.6008, -1.6863,  0.2297,  1.6029, -1.6604, -0.0453],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.4902, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3119,  1.2320,  1.5003, -1.5850, -1.0070,  1.3416,  1.8074, -2.3626,\n",
      "        -1.5850, -1.5502, -3.5850, -1.8146, -1.0999,  1.7061, -3.6897, -1.1478,\n",
      "        -1.5492, -1.6129, -2.9696, -2.3219, -2.5469, -1.8258,  1.3219, -2.0502,\n",
      "        -2.1905,  2.1653, -1.9668,  1.4532, -1.8198, -2.0833, -2.7712, -1.8401],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5159, -0.5134, -0.2384, -0.5007,  0.6925,  1.5099,  0.8824, -0.2265,\n",
      "        -1.6674,  0.5124,  1.0870, -1.8023, -1.7760,  1.6341, -2.2069, -1.3616,\n",
      "        -1.9359, -1.7408, -1.1807, -1.0192, -0.5596, -1.8791,  1.0005, -2.0121,\n",
      "        -0.6970,  0.1384, -1.5397,  1.1260, -2.1470, -1.8238, -1.8565, -0.3610],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.0396, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1339,  1.9353,  2.6906,  1.2479, -1.5850,  1.0555, -1.6781,  1.0810,\n",
      "         2.0989,  1.0712, -2.5850, -1.0875,  1.5135,  1.4957, -1.5850, -1.7168,\n",
      "         1.7222, -2.2624,  2.0421,  1.0288,  1.3119, -2.7553,  1.2243,  2.3219,\n",
      "         1.7776, -1.9011,  1.4535, -2.0360, -1.4791, -1.3785, -1.8433, -1.1942],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5985,  1.2973,  1.7414, -0.2183,  0.8424,  0.1370, -1.2386,  2.0725,\n",
      "         0.2601,  2.3782, -1.8004, -1.7385,  1.4082,  1.9855, -1.2371, -1.8676,\n",
      "        -1.1979, -1.3568, -0.5872, -1.7772, -1.0934, -1.6916, -0.9223,  0.8007,\n",
      "         1.3312, -1.5334,  2.6055, -1.9175, -0.8053, -0.8979, -1.3744, -1.8776],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.1146, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3468, -2.6640,  2.8647, -1.6482,  1.4231,  1.5564, -2.1234, -2.7984,\n",
      "        -1.0549, -1.3102,  2.1669, -2.4507,  1.0014, -1.1737,  1.3196, -2.6546,\n",
      "         2.0224, -1.2936,  1.5850, -1.0116, -1.3900, -2.8073,  1.2243, -1.0084,\n",
      "         3.1028,  1.1045,  2.7143, -2.1076,  1.9126,  2.2334, -1.8395, -1.2682],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0595, -2.3296,  3.0253, -1.3397,  2.2802, -0.3809,  1.3753, -2.1082,\n",
      "        -1.7336, -1.7236,  1.2068, -1.3874,  0.9907, -1.0717,  1.2885, -1.7592,\n",
      "         2.0550,  1.1147,  0.1277, -1.1244, -1.6765, -1.5898,  1.0459,  1.0612,\n",
      "         1.2672,  2.0180, -0.2676, -1.6450, -1.0312,  1.1299, -1.4483, -1.0099],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.4996, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9260,  1.5850, -1.8251, -1.3278, -1.8572, -1.1615, -3.7603,  3.1414,\n",
      "        -3.3966, -1.3461, -1.6280, -1.5417, -1.5564, -3.3637,  2.6800, -1.8747,\n",
      "        -1.6888,  1.1826,  1.8403, -2.1993, -2.0478, -1.0084, -1.1296,  1.5330,\n",
      "         1.0841,  1.5110,  1.7453,  2.0655, -2.0725,  1.5850, -2.5850, -1.9633],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1207,  1.8103, -1.2709, -1.7639, -0.3483, -1.4891, -1.8514,  1.6429,\n",
      "        -1.3948, -1.8266, -1.1532, -1.1180, -0.2123, -1.8264,  1.2861, -1.8050,\n",
      "        -0.0208,  1.5716, -0.0056, -1.5354, -1.9323,  1.0481,  0.2571,  2.4132,\n",
      "        -1.0839,  1.4968,  1.8856,  3.6565, -1.9753,  1.3942, -1.7255, -1.6007],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.9198, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0310,  1.0120,  1.2630, -1.6553, -2.1178,  1.4981,  1.1690, -1.4137,\n",
      "        -1.1478, -1.1926,  1.6204, -1.0371, -1.3179,  1.0555, -1.1901, -2.6999,\n",
      "        -2.0000, -1.6130,  2.4060, -2.0351, -1.1726, -2.0657, -1.0948, -1.1211,\n",
      "        -3.0298,  1.4387, -1.0088, -1.4706, -1.8458, -2.8342, -3.7472,  1.8122],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8890, -0.7486, -1.2743,  1.1887, -1.8099,  0.8850,  1.1916, -2.3964,\n",
      "        -1.8777, -2.0537,  0.9411, -0.2894, -1.3778,  0.3889, -2.0373,  0.3188,\n",
      "        -1.3116, -0.0215,  1.3317, -2.3166,  0.0958, -1.1099, -1.9223, -0.9381,\n",
      "        -1.9165,  0.3041,  0.7935, -1.9394, -1.7404, -0.1079, -2.2444,  0.7803],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 62 Predict 1132 zeros 551 ones, one bias 0.327392\n",
      "train loss: 1.9549492527970567 dev loss: 1.3147893995844417\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.8821, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8255, -1.8339, -1.7140, -3.5480,  1.3414, -2.1155, -1.2700, -1.1375,\n",
      "         1.2350, -2.3219,  3.2645,  2.2536, -1.4400,  1.0970, -2.4150, -1.1726,\n",
      "        -2.3003,  1.2167,  1.0993, -2.1727, -3.3575,  1.3196, -2.8524, -1.1810,\n",
      "         1.0120,  1.5850,  1.5661, -1.7843,  1.8960,  1.7162,  2.3219,  1.5187],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2330,  0.1232, -0.6985, -1.8335, -1.0135, -1.2184, -1.7895, -0.8044,\n",
      "         1.0559, -0.4350,  1.1945,  0.7626, -0.4536,  1.1937, -1.3285, -0.5729,\n",
      "        -1.8571, -1.6826, -1.9472, -0.5033, -1.1660,  1.5836, -0.9271, -0.2503,\n",
      "        -1.3129,  0.7681,  1.2313,  0.8782, -0.0155, -0.1086,  0.3437,  1.1867],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.6299, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2232, -1.7662, -4.0000, -1.6510, -2.2865,  4.0875,  3.1414,  1.6157,\n",
      "        -1.4400,  2.6945, -1.3278, -2.9712, -1.5475, -1.4985, -1.3077, -1.3461,\n",
      "        -1.3840,  1.5003, -1.5194, -1.0999,  1.6736, -1.5850,  1.5850, -1.4150,\n",
      "        -1.0650,  1.1024, -1.3219,  3.3788, -1.7655, -1.5850, -1.9069, -3.3709],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8526, -1.2293, -0.8040, -1.3523, -1.8326,  1.2781,  2.2211,  0.0700,\n",
      "        -0.1448,  1.4652, -2.1023, -2.1093, -1.1441, -1.9278, -0.8568, -1.8479,\n",
      "        -1.6430,  0.5787, -0.8517, -2.1452,  1.0047, -1.5509,  0.7017, -1.0038,\n",
      "        -1.6334,  1.1811, -1.0762,  1.8010, -1.8465, -1.6466, -1.6817, -1.2154],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.0812, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0995,  1.2621,  2.1844,  1.5850, -1.2811, -1.6265,  2.0987, -2.8073,\n",
      "         1.1630,  1.0511,  1.0331, -2.8073, -2.8694,  1.3196,  1.3101,  3.2020,\n",
      "        -1.5850, -1.5659,  1.5491, -3.5034,  1.1475,  1.1957, -1.8255, -2.2676,\n",
      "        -1.2547, -1.3905, -1.2158,  1.2838, -1.0870,  2.3219,  1.3069, -1.5320],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3154,  1.2699, -1.2120,  0.1208, -1.5582, -0.2298,  1.0378, -1.3553,\n",
      "         1.4479,  0.8262,  1.0791, -1.6900, -1.1061,  0.9969,  0.9378,  1.5896,\n",
      "        -0.4266, -1.0161,  1.1178, -2.2562, -1.4263, -1.4329, -1.6354, -1.4250,\n",
      "        -1.6223, -2.0180, -2.3371,  0.9393, -1.8301, -0.3470, -0.2672, -0.9944],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.8658, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3547, -2.0704, -1.1625,  1.5360, -1.4044,  2.2603, -2.0279, -1.5834,\n",
      "        -1.2267, -1.3336,  1.9689,  2.0000, -1.0869, -2.7553, -1.8198,  1.1024,\n",
      "         1.0734,  1.1962,  1.9923, -1.7650, -1.6553, -1.5434,  2.1375, -1.4533,\n",
      "        -1.5255,  1.2224,  1.8688, -3.3219, -2.3575, -1.3923, -1.2021,  1.2205],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9916, -1.6248, -1.4381,  1.4408, -1.0119,  1.3947, -1.8209, -2.0527,\n",
      "        -1.6176,  1.0351,  1.0390,  0.4246,  0.8591, -1.7654, -1.9279,  0.8445,\n",
      "         0.4845, -1.4656,  0.5376, -1.7700, -1.0350, -1.1776,  1.3262, -0.6672,\n",
      "        -1.8452, -1.6832,  0.2550,  0.2025, -1.0669, -1.6933, -2.0801,  0.1070],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.4069, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3499, -1.5850, -1.7004,  1.6562,  1.2106,  3.0255, -1.1778,  1.8705,\n",
      "         2.7587, -3.2730, -1.3167, -1.7935, -1.0589, -3.0119, -1.2481, -1.0870,\n",
      "         1.0153, -1.4400, -2.3219, -2.1564, -2.6589, -1.8063, -1.3002,  2.3219,\n",
      "        -1.1806,  1.5491,  1.4150,  1.3416, -1.0431, -2.1091,  1.3949, -1.5255],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3038, -0.4955, -1.3264, -0.7997,  0.9206, -1.2477, -0.8644,  2.0858,\n",
      "         1.5651, -1.3651, -1.0446, -1.8107, -1.6974, -1.7990, -1.2849, -0.9117,\n",
      "        -0.8152, -1.2216, -0.0146, -1.0639, -2.0681, -1.6636, -1.0946,  1.2947,\n",
      "         0.0396,  1.2862, -0.1049, -1.5061,  0.4039, -0.4813,  0.0038, -1.4201],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2274, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4307, -2.2638, -1.0310,  1.3219, -1.0562, -1.3292, -2.2378,  2.0298,\n",
      "         2.4780, -1.0370, -1.1979,  1.1844,  1.6172,  1.3212, -1.2630, -1.3923,\n",
      "        -3.3219,  1.4150, -1.5850,  1.0888,  1.5850,  3.5850, -1.2016, -1.5407,\n",
      "        -1.8784, -1.8804, -2.0516, -1.0995, -1.3167,  1.3683, -2.1997, -3.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1527, -1.8069, -0.3990,  1.2131, -1.7620,  1.3208, -1.0601,  1.6634,\n",
      "         2.1216, -0.9426, -1.5080,  0.6841,  1.5496,  1.3642, -0.9291, -1.6711,\n",
      "        -1.7414,  0.3550, -0.9332,  1.3338,  1.1680,  1.0466, -1.5275,  0.8509,\n",
      "         0.6718, -1.1473, -2.0037,  0.3065, -1.6034,  1.1557, -1.3215,  1.3612],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 63 Predict 1041 zeros 642 ones, one bias 0.381462\n",
      "train loss: 1.976255344075649 dev loss: 1.6231112814176516\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.4571, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3219,  1.5332, -1.1937,  1.5850,  1.5487,  2.4780, -1.2551, -1.5168,\n",
      "         1.0158, -2.3219,  1.1673,  2.1047, -2.7482, -1.4239,  1.0841, -2.2311,\n",
      "        -2.9696,  1.4527,  1.9781,  2.5062, -1.6062,  1.2316,  1.0098,  1.8399,\n",
      "         1.5187,  1.2154,  2.0000, -1.4500, -1.8863, -1.1844,  1.0446, -2.0000],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2064,  1.7700, -0.9775,  1.0106,  1.8721,  1.8806, -1.7807, -2.0964,\n",
      "        -0.4780, -1.0569,  1.4580,  1.5934, -1.4638, -1.2873,  0.5086, -2.0162,\n",
      "        -1.6416,  1.1285,  1.6336,  1.4828, -1.7496,  1.0835, -0.7032, -1.4303,\n",
      "         1.3470, -1.0389,  1.0011, -1.4127, -1.7302, -1.6059,  0.6224,  1.0432],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.9325, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.7497, -2.5469, -1.2374, -1.7633, -1.0536,  2.6906, -1.9260,  2.1773,\n",
      "         1.6017, -2.8073, -2.3842, -1.1296, -1.3902, -1.1284, -1.1624, -2.4420,\n",
      "        -1.5968,  2.1967,  1.1871,  1.5850,  3.1430, -1.9143,  2.4490,  1.6121,\n",
      "        -1.4610, -1.4094, -1.8501,  2.2410,  2.1043,  2.5698, -1.2076,  2.4924],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5588, -0.5457, -1.6677, -1.4908, -2.3259, -0.5151, -1.5007,  1.1659,\n",
      "         1.7402, -1.6221, -0.4543, -1.0896, -1.5479, -1.1703, -0.2816, -1.3874,\n",
      "        -1.6761,  1.5507,  1.1890,  0.8074, -1.3012, -1.2218,  0.8271,  0.4964,\n",
      "        -1.2319, -0.1877, -1.5643, -1.0408,  0.1942,  1.7399, -0.9109,  0.9543],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.6826, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6971,  2.4132,  3.2985, -2.0275, -2.5236, -1.8572, -2.7901, -1.4150,\n",
      "         1.2313, -1.6108,  1.5676,  3.3923, -1.5243, -3.0000,  1.4594, -1.5415,\n",
      "        -1.0088, -1.5407, -1.3809, -2.1255, -1.2801, -3.1699, -1.0716, -1.0327,\n",
      "         1.6568,  1.3196, -1.3055,  3.3173, -1.0389, -1.5236, -1.5360,  1.1865],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7218, -0.9496,  1.4860, -1.5931, -1.6065, -1.2442, -1.0510, -1.5919,\n",
      "         1.0391, -1.6262,  0.6400, -0.0753, -1.5002, -1.1424,  0.5457,  1.1849,\n",
      "        -1.9694,  0.8693, -1.5709, -0.6510, -1.8145, -1.0886, -1.8122, -1.8728,\n",
      "         0.5699, -0.3643,  1.4386,  2.7022,  0.4091, -1.1778, -1.7458,  1.3946],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.9824, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5850, -2.5850,  2.0000, -2.7613, -2.8412,  2.1047,  1.3626, -3.6114,\n",
      "         1.4775, -1.1211,  1.3923, -1.0243, -1.1965, -1.3219,  1.8139, -2.4594,\n",
      "         1.4479, -1.9542, -1.7144, -2.4507, -2.0516, -1.1703, -2.3219, -1.1384,\n",
      "         1.0024,  2.5951, -2.0360, -1.1540, -1.3822,  1.3212, -1.8228, -1.8401],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0228, -1.1665,  1.5901, -0.8155, -1.6422, -1.1314,  1.2096, -1.6092,\n",
      "         0.5603,  0.0292,  1.8001,  0.0790, -1.2753, -1.2713,  1.2555, -1.0815,\n",
      "        -0.5327,  0.7473, -1.4104, -1.5882, -1.5178, -1.4713, -0.9264, -1.5759,\n",
      "         1.4422,  1.2427, -0.0929,  1.1732, -1.2068,  1.5860, -1.5171, -1.1262],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.6243, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0171, -1.9069, -1.2814, -1.4594,  1.1699, -1.3015, -1.6107,  1.0473,\n",
      "        -1.3278,  1.3683, -3.5850, -1.0343, -1.7655,  1.4387,  4.4046,  1.0452,\n",
      "        -1.3388,  1.2167,  1.3337,  1.8171,  4.4313, -1.4137,  2.1066, -1.4372,\n",
      "        -1.1699, -1.6415,  1.2243,  1.1699,  2.7700, -4.8147,  1.3870, -2.4507],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6846, -1.0294,  1.4312, -1.1045,  2.1942, -0.5265, -1.7306, -1.6508,\n",
      "        -1.5362,  1.8331, -1.6853, -1.2001, -1.5831,  0.9551,  2.3421,  1.6046,\n",
      "        -1.3920,  1.2397,  0.9823, -0.4362,  1.6478, -1.7219, -0.2503, -1.5443,\n",
      "         0.1985, -1.5595,  1.3790,  1.4886,  1.2000, -1.3218, -0.7389, -1.4789],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.8157, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.4250, -1.8864,  1.1020, -3.4311, -1.1220,  1.7227, -1.1234, -1.2938,\n",
      "         1.5676, -2.8073,  2.0730, -1.2057, -2.1058,  2.0000, -1.3986, -3.9362,\n",
      "         1.0888, -1.0919,  1.5850, -1.8745, -1.9260,  2.1066, -1.5850, -1.3219,\n",
      "        -1.7001, -1.0233, -1.1890, -1.8129,  1.6172, -2.4908, -1.5850, -3.1936],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9135, -1.9107,  1.5758, -1.9748,  0.9987,  1.4891, -1.4638,  0.8289,\n",
      "         1.0359, -1.3440,  1.4878, -1.8159, -1.5387, -0.4143, -1.6670, -1.8133,\n",
      "         0.4160,  0.0947,  1.3675, -1.3394, -1.4697,  2.0410, -1.0398,  0.9709,\n",
      "        -1.4171,  0.8939, -1.3245, -1.6807,  0.9446, -1.2914, -1.6923, -1.8927],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 64 Predict 1121 zeros 562 ones, one bias 0.333928\n",
      "train loss: 2.006986118549675 dev loss: 1.6990074746882469\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.9917, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5043,  1.0087, -1.6800, -1.1965, -2.5043, -1.1656, -1.0343,  1.5438,\n",
      "         1.0024,  2.0575, -2.0976, -1.7033,  1.3219, -1.0962,  2.3219,  1.2320,\n",
      "         1.0780,  1.0297, -1.3676,  1.0478,  1.0841,  2.6168, -2.5850,  1.3870,\n",
      "        -1.4708, -1.3201,  1.4105, -1.4044, -1.8924,  2.0940,  1.3414, -2.9696],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5276, -1.1937, -0.2311, -1.6474, -1.1786, -1.6653, -1.8131,  1.0791,\n",
      "        -1.3486,  1.2980, -2.0597, -1.9951, -1.1385,  0.5259,  2.2041, -1.8071,\n",
      "        -0.7579, -1.7149,  1.5336,  0.3848,  1.2232,  2.3293, -1.5783,  0.8940,\n",
      "        -1.0691, -2.1092,  0.6303, -0.6740, -1.3269,  1.0820, -1.3335, -1.9840],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.3041, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8745, -1.5247, -1.8791, -2.8651, -2.6640,  1.0669, -1.2955,  1.2198,\n",
      "         1.6067, -1.1631, -1.8747,  2.5504, -2.4041, -2.8712,  1.2712, -1.6717,\n",
      "        -1.5671, -1.5850,  1.8460,  2.3014,  1.4307, -2.1699,  2.2334, -1.4120,\n",
      "        -2.5095, -3.5850, -3.1375, -1.2630, -1.2557, -1.2904, -2.3626, -3.1193],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5085, -1.5285, -1.4934, -1.5258, -1.7189, -1.0787,  0.2408,  0.8395,\n",
      "         1.9416, -1.1643, -1.3924,  1.3820, -1.7424, -1.5980, -0.7356, -1.4811,\n",
      "        -1.6127, -1.2868,  1.9816,  0.3420,  1.7890, -1.5818,  1.1035, -0.6461,\n",
      "        -1.4753, -1.7291,  1.4651, -1.7531, -1.6204,  0.7907, -0.9120, -1.5456],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.2012, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2630,  1.1375,  1.3219,  1.3119, -1.7370,  2.6825, -1.1069, -1.8074,\n",
      "         1.1690, -1.9260,  1.1405, -3.0875, -1.1427, -1.4642, -1.1864, -2.9265,\n",
      "        -1.5850,  1.0067,  3.1699, -1.4894,  2.6699,  1.2895,  1.0056,  1.1024,\n",
      "         1.0669,  1.1715, -1.7194, -1.4739, -1.2682,  1.0680, -1.7140, -1.2599],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5826,  0.6709,  1.2918,  1.1101, -0.1816,  2.4895, -0.8152, -1.5311,\n",
      "         1.1719,  0.3128,  0.6293, -1.4964,  1.1664,  0.6658, -1.9661, -1.4706,\n",
      "        -1.4643,  1.2701, -1.0100, -0.5024,  0.0310, -0.0143, -0.0913, -0.0523,\n",
      "         0.8707,  1.4498, -1.5379, -1.2597, -0.1004, -1.2607, -1.0276, -1.1523],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.6740, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3931, -1.3310, -1.1597, -2.1905,  1.3215, -2.1905, -2.0360, -1.8228,\n",
      "         1.1483,  1.3219, -2.4594, -1.2955, -1.8924, -2.4594,  1.3219, -3.2730,\n",
      "        -1.4132,  1.3172,  1.4594, -2.1445, -1.1422,  3.7635,  1.4695, -1.0310,\n",
      "         2.2480,  1.0841, -1.1265,  1.5676,  1.0841, -2.0324,  1.0555,  1.2475],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3619, -0.9509, -0.9551, -1.2947,  0.1856, -1.2758, -1.2277, -1.7080,\n",
      "         0.8017, -1.4647, -1.2164, -0.9914, -1.7238, -1.2384, -0.8229, -1.7142,\n",
      "        -1.2685,  0.7186,  1.6565, -1.3780, -1.3264,  1.2603,  1.0902, -2.0423,\n",
      "         0.5842,  0.7395,  0.4199, -0.2073, -0.8814, -1.1400,  1.3847,  0.0371],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1790, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1975, -2.0995,  2.6825, -2.4694,  1.9349, -1.2486, -1.5850, -2.9619,\n",
      "        -1.0967,  1.9349, -1.7411, -1.0650, -2.0478, -1.2419, -2.3842, -3.3219,\n",
      "        -2.4586,  1.2111, -1.4636,  1.4099, -1.1890, -1.7411,  1.7287, -1.4598,\n",
      "        -1.0387, -1.5629, -1.3278,  2.3334, -1.5850,  1.6057, -4.7188, -1.5850],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8065, -1.5902,  1.6964, -1.6225,  1.3043, -0.7140, -1.2530, -1.7301,\n",
      "        -1.6232,  1.8021, -1.6283, -1.7784, -1.4562, -1.7609, -1.3433, -1.6518,\n",
      "        -0.1085,  0.3949, -1.5433,  0.6758, -0.4687, -1.4726,  0.4424,  0.5170,\n",
      "        -1.5603, -1.2706, -2.1332, -0.4041, -1.3255, -1.2715, -1.0706, -1.1930],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.5555, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6714, -1.4642, -5.5363, -1.9260, -1.9260,  1.5077, -2.8073, -1.6288,\n",
      "        -1.5660,  2.3219,  1.4854,  2.3334,  1.3196,  1.2224, -1.6717,  1.0841,\n",
      "        -1.1211, -1.3388, -2.1659,  2.1753,  1.6848, -1.1520, -3.2327,  1.3196,\n",
      "         1.3069,  1.7370, -1.3278,  1.3498, -1.3986,  1.0007,  1.2633,  1.4241],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9606, -1.6077, -1.5940, -1.1052,  0.9435, -0.0580, -1.8562, -1.5404,\n",
      "        -1.7955,  0.2783, -1.3140, -0.2615,  1.0776, -1.4765, -1.9523, -1.2925,\n",
      "        -0.4501, -1.7822, -1.9778,  2.0948, -0.6638, -1.7053,  0.9603,  1.0809,\n",
      "         1.4172,  0.9412, -1.9509,  1.4235,  0.6036,  0.1596, -0.5398,  1.0326],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 65 Predict 1069 zeros 614 ones, one bias 0.364825\n",
      "train loss: 1.9907838908846691 dev loss: 1.3758014215733734\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.4301, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7848, -2.0108, -1.0863,  1.6637, -1.8309, -1.7370, -1.1278, -2.2076,\n",
      "         1.9781, -1.5850,  2.6781, -1.3046, -2.8141, -2.0478, -1.9069,  2.6945,\n",
      "        -1.4854,  2.0715, -1.0854,  3.0444,  1.5850,  2.0666, -1.2315, -2.0410,\n",
      "         1.3498,  1.4099, -1.4791, -1.7177, -1.0711, -2.8970, -1.4795, -1.1155],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7179, -1.5621, -1.0678,  0.4441, -1.7061, -1.7247, -1.1734, -0.6664,\n",
      "         1.5879, -1.2111,  0.2590, -1.4136, -1.9711, -1.9043,  0.0715,  1.3508,\n",
      "        -0.6722,  0.4534, -1.5302,  0.4579,  2.1021,  1.1281, -1.0315, -0.7180,\n",
      "         1.1989, -0.0351, -1.0578, -0.5864, -1.1557, -1.5796, -1.4160, -1.1336],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.6647, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5850,  1.1826, -1.3905, -1.0389, -1.1699, -1.4533,  1.7914, -3.3709,\n",
      "         1.1962, -1.5984, -2.1214,  1.2538,  1.5751, -1.3772, -1.0342, -1.4132,\n",
      "        -1.0766, -1.2476, -1.6280, -2.3738, -1.0999,  1.4387,  1.7077, -1.4507,\n",
      "        -2.3219, -1.5850, -1.3450,  1.3986, -1.7370, -1.0609, -1.8571, -1.5887],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3844, -1.2799, -1.8460,  1.0007,  0.4188, -1.0805, -1.0852, -1.6651,\n",
      "        -1.7379, -1.7520, -1.6627,  0.7358,  1.6743, -2.1356, -1.4274, -1.8418,\n",
      "        -1.4716, -1.6211, -0.3062, -1.7833, -1.7408,  1.1892,  0.9705,  0.6025,\n",
      "         0.3487, -1.5599, -1.6990, -0.2108, -1.6212, -1.6516, -1.6848, -1.7268],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.3524, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0686, -2.9493, -1.3111, -2.0455, -1.1508, -1.9635,  1.8592, -2.7370,\n",
      "         1.0098, -1.9260,  2.7143,  3.5850,  1.5850,  2.1625, -1.4454,  1.7627,\n",
      "        -1.8313, -1.1844, -1.2938,  2.0000, -1.8458, -2.3708,  1.8496, -1.0370,\n",
      "        -1.9260, -1.4936, -1.0639,  1.8745, -1.5850, -1.2827,  3.4594,  1.5850],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.4784, -1.6574, -1.5105, -1.6112, -1.7387, -1.0119,  0.1561, -0.9040,\n",
      "        -1.2605, -1.2380, -0.7294,  1.0661,  1.0860,  2.1013, -1.3103,  0.8193,\n",
      "        -1.7704, -1.6978, -1.6512,  0.7618, -0.9110, -1.7760, -0.9455,  0.8940,\n",
      "        -1.5390, -0.7869, -0.4727,  1.4985, -1.0771,  0.2134, -1.2067, -1.4079],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.6364, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8458, -1.2929, -1.4372, -1.7405, -2.5850, -1.5850, -1.9778,  2.9069,\n",
      "        -1.1147, -1.5850,  3.0589,  2.5361, -2.0000, -1.1220, -1.5671, -1.2752,\n",
      "        -2.4594, -1.3278, -1.5475, -1.0815,  1.4651,  1.8122,  1.0067, -1.6553,\n",
      "         2.0589, -1.0356, -2.1375, -1.4354, -1.7991, -1.4256, -1.4533, -3.4215],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9228,  0.1454, -1.7349,  0.2988, -0.6087, -1.2009, -0.9256,  0.3264,\n",
      "         0.5103, -1.1724,  1.6669,  0.4636, -1.3024,  0.2379, -1.2529, -1.7112,\n",
      "        -0.7263, -2.0768,  0.4246, -0.7868,  0.1059, -0.2171,  0.1939, -0.1565,\n",
      "        -1.6502, -0.5520, -1.5625,  0.1792, -1.6770, -0.7489,  0.7713, -1.4741],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.4999, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3167,  2.0421, -1.5984, -1.9778,  1.2801,  1.0297, -1.2730,  1.0690,\n",
      "        -1.3425, -4.6439,  1.0826,  1.0750, -1.1935, -2.7892, -1.3923, -1.1598,\n",
      "         1.6894,  2.0128, -1.1147, -1.9260, -2.9798, -3.7248, -2.8524, -1.6524,\n",
      "        -2.0000, -1.4721,  1.6818, -1.8716, -2.5158, -1.5407, -1.1543,  1.9649],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3170,  0.5806, -1.5324,  0.4076,  0.4048, -0.0706, -1.1218,  0.4686,\n",
      "        -1.6031, -1.5021,  1.0868,  1.6470,  1.1670, -1.7865, -1.1905, -0.0353,\n",
      "         0.7448,  1.5743,  0.4462,  0.0587, -0.1630, -1.4659, -0.9232, -0.1186,\n",
      "        -0.0161, -0.5207,  0.9220, -1.0282, -1.5196, -0.6910,  0.9762,  1.1020],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(4.2807, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1371, -1.2801,  4.0875, -1.6084, -3.0704, -1.1737, -1.7843, -1.4500,\n",
      "         3.9307, -2.0000, -1.9885, -1.1510,  1.3550, -2.4484, -1.3103,  5.1182,\n",
      "        -3.2015,  1.2141, -1.1258, -1.3310, -1.4400,  1.0776,  1.4594,  1.1220,\n",
      "        -2.0277, -2.0255, -1.4458, -2.7482, -1.6614, -1.8339, -2.0106, -1.5024],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2871, -1.7872, -1.3149, -1.3507, -1.6461, -1.6224, -1.5556, -1.7401,\n",
      "         1.1595, -0.1514, -1.4915, -1.5940, -1.8627, -1.7142, -1.0092,  0.9772,\n",
      "        -1.3631, -1.6667,  0.9591,  1.4691, -1.1896,  0.9069,  1.5544,  1.1130,\n",
      "         0.0317, -1.1382, -0.4835, -1.5945, -1.5362, -0.0708, -0.5095, -0.6858],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 66 Predict 1069 zeros 614 ones, one bias 0.364825\n",
      "train loss: 2.008993312578421 dev loss: 1.7679876741520497\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.1056, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1293, -1.2756, -2.2850,  1.6172,  1.4477,  3.5583, -1.5208,  1.8403,\n",
      "        -2.4263,  2.2536, -1.2557, -1.5850,  1.9971,  2.4983, -2.4127, -1.8365,\n",
      "        -1.4150,  1.6894, -1.1375,  1.5624, -2.6955,  2.8821, -2.0050,  1.0788,\n",
      "         1.0669, -1.7370, -1.5025, -1.5984, -1.1844, -3.1699, -1.2854,  2.3421],\n",
      "       device='cuda:0')\n",
      "tensor([-2.7072, -0.8360, -1.8190,  1.8518, -0.8616,  2.1214, -0.9677, -0.7037,\n",
      "        -1.9079,  1.5914, -1.6812, -1.2488,  0.7974,  0.0560, -1.1526, -1.1869,\n",
      "         0.0504,  1.1735, -1.8999,  0.6083, -0.3165,  1.5880, -1.6631,  0.8873,\n",
      "        -0.6778, -1.8382, -1.7198, -1.7970, -1.3804, -1.8848, -1.6843,  0.6635],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.4972, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.2150,  1.9349, -1.7370, -1.3529,  1.7914, -1.6265, -1.5516, -1.1791,\n",
      "         1.1333, -2.8901, -1.0941,  1.5596,  2.3363, -1.9279,  1.5193,  1.0841,\n",
      "        -1.2599, -1.6084, -1.1631, -2.0156, -1.9513, -3.5480, -1.6280, -2.3219,\n",
      "         2.3216,  1.0024,  2.7700, -1.9635,  1.5585,  1.5400, -1.7194, -2.5850],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3538,  2.9994, -1.4067, -1.1300, -1.4510,  0.8342,  0.6715, -1.2053,\n",
      "        -0.8975, -1.8058, -1.7526,  1.4073,  0.0652, -0.5641, -0.1383, -1.7566,\n",
      "        -1.5381, -1.7910, -1.6073, -1.5331, -1.8773, -1.7292, -0.5938, -0.1121,\n",
      "        -0.4241,  1.6282,  1.1455, -1.4631,  1.7866,  0.3797, -1.8247, -1.7036],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(4.7350, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1405, -1.8682,  2.3815, -1.4636, -1.8433,  1.3219,  3.0388, -1.3461,\n",
      "        -1.8977,  2.6375, -1.0233, -1.1368, -1.2153,  1.1988, -1.2680, -1.5850,\n",
      "         1.5850,  1.9126, -2.5850,  2.0000,  2.6647, -2.3219,  3.4594, -2.3526,\n",
      "        -1.4354, -2.2761,  2.7558, -1.9095, -3.1193,  1.4387, -1.5025,  1.5071],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1994, -2.0206, -0.2588, -1.6114, -1.8589,  0.3993,  0.9093, -1.6740,\n",
      "        -1.6695,  1.9625,  1.1555, -1.5939,  1.1735, -1.5430,  1.4202, -1.3368,\n",
      "        -1.1943,  1.1613,  0.6159, -1.6800,  0.7363, -0.7216, -0.1339, -1.8133,\n",
      "        -0.1486, -1.7704,  1.5538, -0.7913,  0.1457,  1.9167,  1.9104, -2.0994],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.9466, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6439, -3.7472, -1.8074,  1.7382, -2.0000,  2.1625,  1.6917,  1.3156,\n",
      "        -1.3530,  1.3580,  1.1020,  1.1699,  1.1226, -1.5475, -1.8458, -1.3202,\n",
      "        -1.9281,  1.6157, -1.0272, -1.7004, -1.4970, -2.8342, -2.1180, -1.9349,\n",
      "         1.5515, -3.5850,  1.6828, -3.0000,  2.2370, -2.5136, -1.2733,  1.1699],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5256, -1.7963, -1.3149,  1.0758, -0.9073,  1.2218,  0.3925,  0.7706,\n",
      "        -1.5905, -0.8060, -1.5307,  0.2883, -0.3544,  1.0369, -0.9702, -1.5898,\n",
      "        -1.6585, -1.4569, -1.7946, -1.5463, -1.7328, -1.0403, -0.4732, -1.6720,\n",
      "         1.2836, -1.3413,  0.2137, -1.7531, -1.7362, -1.3009, -1.6750, -0.6008],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.4590, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6781, -1.8228, -1.2801,  4.3631, -1.9022,  2.7655,  2.5698, -1.2303,\n",
      "        -1.1211,  1.0747,  1.5850, -1.8649,  1.3219, -2.0129, -3.2627, -2.4595,\n",
      "         1.1371, -2.9974, -1.8339, -1.2929, -1.3655,  1.2436, -1.9260,  2.7612,\n",
      "         3.3173,  1.5500, -1.1833, -2.0767, -2.1520, -1.0153,  1.2446, -1.2224],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1135, -1.8863, -0.5868,  3.3249, -0.2238, -1.3202,  0.7984, -1.4967,\n",
      "        -1.1765,  0.2651, -1.1901, -1.9021,  0.0776,  0.4787, -1.9787, -1.7562,\n",
      "        -0.1343, -1.3343, -1.1990, -1.9044, -1.2509, -0.1108, -1.7151,  1.5067,\n",
      "         1.0974,  1.6246, -0.7958, -2.1703, -1.4214,  1.6964,  0.2814, -1.7155],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.1272, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2044,  2.1155,  2.2130,  1.1285, -1.8251, -2.1927,  1.0750,  1.5986,\n",
      "        -1.5850, -1.2848,  1.3424, -2.8524, -1.8572, -2.3318,  2.4060,  1.2955,\n",
      "        -1.0343, -2.3219,  1.4241,  1.3000, -1.0646, -2.7482,  2.0940,  1.0573,\n",
      "        -1.4854, -1.0562, -1.0070, -1.9260, -1.2122, -1.3310,  1.8122,  2.9341],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6257,  1.2826,  0.8082, -1.0489, -1.8311, -2.1990, -0.6505,  0.7224,\n",
      "        -0.0762, -1.6927, -1.8611, -0.7961,  0.0570, -1.6592,  1.6281,  1.3031,\n",
      "        -1.5558,  1.7674,  0.8315, -1.3245, -1.5611, -1.6464,  1.0507, -1.7794,\n",
      "        -0.8440, -1.7991,  0.0808,  0.0728, -1.6473,  1.3042,  1.1440, -0.1882],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 67 Predict 1012 zeros 671 ones, one bias 0.398693\n",
      "train loss: 1.9828240289895653 dev loss: 1.475436363242908\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5834, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0090, -1.1677, -1.0641,  1.1225, -2.1699, -1.2486, -1.8458, -1.5025,\n",
      "         1.3219, -1.3422,  1.0680, -1.9260,  2.1047, -1.0062, -1.9370, -2.7370,\n",
      "         1.0024, -2.5443, -1.2065, -1.9260, -1.6482,  1.3498, -1.6510, -2.0049,\n",
      "         2.0486, -2.2685, -1.8921,  1.5850,  3.0760, -1.2486,  1.6067,  1.0608],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1165, -0.2625, -1.4377,  0.0600, -0.6729,  0.0295,  1.3159, -1.8123,\n",
      "         1.1403, -1.8766, -1.5572, -1.1119, -1.2843,  1.4136, -1.0486,  0.5956,\n",
      "         1.5736, -0.8956, -1.1514, -1.5367, -0.6288,  2.9652, -1.5292, -1.6647,\n",
      "         1.2719, -0.6882,  0.2362,  0.5806,  0.9197, -1.4072,  1.7101,  1.2271],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.6968, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8399, -1.3388, -2.1409, -2.3575,  1.3380, -1.9599, -1.2450,  2.2081,\n",
      "        -2.7793, -3.5850, -2.0657, -1.9746,  1.3196,  1.5193,  1.0841,  1.3626,\n",
      "        -1.8426, -1.9260,  1.5676, -1.0945, -2.0937, -1.0827, -1.6700,  2.8073,\n",
      "         2.4780, -1.1676, -1.9260, -1.9095, -1.1024, -1.5850, -1.1536,  2.9069],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4481, -1.2689,  1.2077,  0.5989,  1.2756, -1.8994, -1.7423,  0.3831,\n",
      "        -2.8388,  1.0183, -1.3110,  1.0299,  1.3274, -0.0310,  0.7618, -1.3389,\n",
      "        -1.9546, -1.6020,  0.2727, -1.0592, -0.6461, -2.0887,  0.0411,  0.9507,\n",
      "         1.4402, -2.2404, -1.1656, -2.2392,  0.2208, -1.4752, -2.6373,  0.9522],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.1098, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8819,  2.5731, -2.5850, -1.2241, -3.5850,  2.6906, -3.8073, -1.1970,\n",
      "        -1.1100,  1.4011, -2.2000,  1.2154, -2.0000,  1.1010, -1.7843, -2.7712,\n",
      "         2.3153,  1.7800,  1.7222,  1.6172,  1.7077, -1.1031, -1.9778, -2.3833,\n",
      "        -1.1147,  1.3399, -1.5833, -1.1043, -2.0704,  2.5361,  5.2785, -1.5475],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8265,  2.6070, -1.6373, -0.5469, -1.0631,  1.7074, -0.8265, -1.7548,\n",
      "        -1.7846,  1.1530, -1.7955, -1.8228, -0.9087,  0.8617, -0.6151, -1.5389,\n",
      "         2.8490,  0.1200, -1.9319,  0.8431,  0.3338, -1.0216, -0.6376,  0.5809,\n",
      "        -0.3325,  1.5206, -2.2419, -2.0275, -1.6451,  2.1006,  1.8387,  0.7040],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.9301, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5979, -3.1699, -1.8882,  2.4060, -1.0028,  1.3212, -2.4432, -1.2682,\n",
      "         1.4076,  1.1782,  3.3626,  1.7414, -1.3809, -3.5850, -1.1538,  2.4525,\n",
      "        -2.5510,  1.3468,  1.4834,  1.2407,  2.6800,  2.0379, -1.9260,  1.8391,\n",
      "        -1.3745, -1.7405, -1.8383, -1.3398, -1.1048,  1.5482, -3.3709, -2.8073],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8656, -1.2469, -2.0535,  1.8618, -1.9773,  1.3666, -1.6533,  0.1072,\n",
      "         0.9723, -0.6507,  1.6557,  1.1191, -1.7407, -0.7748, -1.8873, -0.9106,\n",
      "        -2.0266,  1.7532,  1.6933, -0.3726,  2.0253,  1.8193, -1.2607,  0.7388,\n",
      "        -0.8519, -1.8165, -1.8151, -0.7096, -0.2649,  0.8252, -1.3298, -1.1298],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1492, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.7553,  1.2677,  1.4964, -1.0941, -1.8791,  1.2761,  2.9542, -1.9260,\n",
      "         2.0195, -3.5034, -2.2492, -1.9778, -1.1040, -1.3085,  2.0000,  1.8745,\n",
      "         2.0000, -1.0646, -2.3394, -1.0870,  1.2745,  1.3219, -1.2481, -1.3219,\n",
      "        -1.2630,  1.6147, -1.8539,  2.5487, -1.1597,  1.2224,  1.2538,  1.0286],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8188,  0.3709,  0.8456, -1.5215, -1.8532,  2.1695, -0.2077,  1.1164,\n",
      "         1.3669, -1.9540, -1.9298, -1.3006, -1.0781, -1.6692,  0.4386,  1.4507,\n",
      "         1.3654, -1.4360, -2.2133,  0.1758,  0.3708, -1.7403, -1.0721, -1.9869,\n",
      "         1.7793, -0.0172, -1.6191,  0.1697, -1.3323,  0.1741,  1.9265,  0.1769],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.2593, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3468,  1.7800, -1.1597,  1.7655, -2.8073, -1.9095, -1.1072, -1.1489,\n",
      "        -1.0116,  2.2654, -1.9005, -2.0360,  1.3193, -1.4482, -1.9746,  2.7500,\n",
      "         1.3580, -1.8745, -1.1444,  1.0750, -1.8258, -1.1726, -2.0129, -1.6180,\n",
      "         1.7370,  2.1912, -2.5850,  1.7914, -3.0875,  1.3793, -1.0147, -1.5633],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3972,  0.7349, -1.4281, -1.9112, -1.7291, -1.5352,  2.2293, -1.6632,\n",
      "        -1.3421,  0.2081, -1.4903, -1.4943, -1.2775, -1.1692, -1.1666, -1.6406,\n",
      "         0.4651,  1.2552,  1.1793,  0.4868, -2.0132,  1.0287, -1.6844, -1.7618,\n",
      "         0.8784,  1.1542, -1.1812,  0.0190, -1.2407, -0.1187, -1.6336, -1.0498],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 68 Predict 1083 zeros 600 ones, one bias 0.356506\n",
      "train loss: 1.9957819258285683 dev loss: 1.7918285459084995\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(4.0815, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.0119, -1.1336,  2.3917,  1.1025, -1.6472, -2.4586,  1.9329, -2.0360,\n",
      "         1.3577, -1.2682, -3.3219, -2.6259,  1.2479,  2.9079,  1.5324, -1.2806,\n",
      "         2.1896, -1.5025, -1.9260,  1.1481,  1.5003,  2.3366,  1.0171, -2.0451,\n",
      "         4.7944,  1.1826,  1.1226,  1.8403,  1.4105,  1.5515,  1.5850,  1.8122],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8546, -1.1016, -0.1039,  0.5128,  1.6140, -2.1449,  1.1868, -0.5747,\n",
      "         1.8978,  1.4418, -0.5523, -1.4841,  1.3456, -1.7492,  1.2175, -0.8806,\n",
      "        -1.6789,  0.8693, -0.6064,  2.2322,  0.3508,  1.4764, -1.0633,  0.1261,\n",
      "         1.8337,  0.3350,  2.5619,  1.4112,  0.6582,  1.5046,  1.6634,  1.7496],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.3731, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0827, -3.6114,  3.2721, -1.3292,  1.3931, -1.5850, -1.5255,  2.1123,\n",
      "         1.2263,  2.6521,  2.4270, -1.9875, -2.2330, -1.2737,  1.6883, -1.9005,\n",
      "        -1.8747,  1.7370,  1.6293, -1.3530,  1.0853, -2.2076, -4.2094,  2.6716,\n",
      "         1.2224,  1.5850, -1.6992, -1.1717, -1.7358, -1.2752,  1.5670, -1.9778],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9906, -0.8282,  1.1526,  0.1192,  1.0060,  0.3288, -1.7562,  1.6891,\n",
      "        -0.4146,  1.4163,  0.7777, -0.7330, -1.9066,  0.2614, -0.4692, -1.4027,\n",
      "        -1.9304, -0.6050,  1.2617, -1.7225,  1.8413, -1.2513, -1.1659,  0.9420,\n",
      "         1.2596,  0.8029, -1.8297, -1.7479, -1.0362, -1.7423, -0.6324, -1.2970],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.7333, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0387, -1.1211, -1.6080, -1.1737,  1.1699, -1.8837,  1.1957,  1.3290,\n",
      "        -2.0279,  1.2705, -1.3219,  1.5220,  2.3219, -1.4081, -1.9260,  1.7914,\n",
      "         3.0558,  1.2016,  1.1375, -2.2044, -2.6955, -1.8228, -1.2955, -1.9635,\n",
      "        -1.7655,  1.7225, -2.8073, -1.1975,  2.4841,  1.5585, -1.9149,  1.5400],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6906, -0.0096, -1.7171, -0.9677,  1.1441, -1.7943,  1.3584,  1.2060,\n",
      "        -1.7855, -0.0485, -1.3799,  0.1767,  1.2617,  0.1465, -1.3598,  1.4181,\n",
      "         1.1728,  1.2912, -0.7334, -1.7600, -1.2707, -1.1552,  0.7969, -1.4363,\n",
      "        -2.0665, -1.4537, -1.1299, -0.4772,  0.8862,  1.8256,  1.0317,  0.3727],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.9038, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.2854,  1.2064, -1.1937, -2.0194,  2.0358, -1.6826,  2.0000, -1.0308,\n",
      "        -1.3752,  1.8960,  1.8122, -1.2783, -1.0444,  2.8073,  2.0358, -1.5984,\n",
      "        -2.1641, -1.1699,  2.7816, -1.3529, -1.2227,  1.0669,  2.3153, -1.0342,\n",
      "         3.1075, -2.5374,  1.9723, -2.0000, -1.2111,  1.2167,  1.2082, -1.2630],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2937, -1.1596, -1.6313, -1.0524,  0.8172, -2.2574, -1.5646, -1.3236,\n",
      "        -1.4777,  1.1957,  1.4036,  0.2238,  0.9866,  1.2960,  1.7681, -1.6762,\n",
      "        -1.9356, -1.7303,  1.7228, -1.8749, -1.7763, -1.3388,  1.8761,  0.0178,\n",
      "         2.2228, -1.4752,  1.5256, -0.9581, -1.8252,  0.3156,  1.5565,  1.8675],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.4192, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1444,  2.6676,  1.5850,  3.7635, -1.1155, -1.8433,  2.6800,  1.0961,\n",
      "         1.1453,  2.0209, -2.0255, -1.5178,  2.4780, -2.8073,  1.3094, -2.0657,\n",
      "         1.5090, -1.6228, -2.7896,  1.7222, -3.4311,  1.3968, -1.1459, -1.5660,\n",
      "        -2.0049, -1.5422, -1.2058, -1.2988, -3.4227,  1.1024, -1.2333,  2.6586],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3710,  1.4776,  1.3301,  1.4776, -0.7080, -1.1086,  1.8462, -1.2377,\n",
      "         1.5042,  1.6579, -0.9723,  1.0975,  1.3614, -1.1725, -0.5371, -0.4061,\n",
      "        -0.6692, -1.4363, -1.4315, -1.4715, -1.6830,  1.1298, -0.0813, -1.5435,\n",
      "        -1.3911,  0.8651, -0.2842, -1.4817, -1.4651,  1.3874, -1.0354,  1.3249],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.8551, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0518, -3.3219,  1.6147, -1.5850,  1.6848,  1.2855, -3.5633, -2.7667,\n",
      "         1.2633, -2.4595, -1.9586, -2.2033,  2.8073, -2.0000, -1.5850, -1.0870,\n",
      "        -2.4595, -1.2713,  2.0987,  1.9125,  1.3736, -1.9011,  1.7287, -1.8458,\n",
      "        -1.2891, -1.4423,  1.8592, -1.1155,  1.4594, -1.2988, -2.3219, -1.3443],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0691,  0.5809,  1.4212,  0.7605,  1.0851,  1.7785, -1.9517, -1.1533,\n",
      "         1.3072, -1.4199, -1.6723, -1.9984,  1.5998,  1.1956, -1.6308,  0.0737,\n",
      "        -1.6894, -1.7149,  0.9007,  0.0182,  1.6870, -1.5846,  1.2066, -1.0031,\n",
      "        -1.6675, -1.5835,  1.4911, -0.2304,  0.2380, -1.6835,  2.4197, -1.8665],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 69 Predict 1083 zeros 600 ones, one bias 0.356506\n",
      "train loss: 1.9369590351792714 dev loss: 1.5447111002112484\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5344, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.2048,  1.1957, -1.8190, -3.5850, -2.3795, -1.0116, -1.8146,  2.3334,\n",
      "        -2.9696, -1.6245, -2.4594, -1.6338,  1.2346, -3.0764, -2.4595, -1.7004,\n",
      "        -1.7411, -2.8073, -1.4205, -2.9260,  1.0153,  1.3219, -2.4594,  1.3219,\n",
      "        -1.4150,  1.3414, -1.2486, -1.8465, -2.5850,  2.7111, -1.3455,  1.7000],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2005,  1.2887, -1.1106,  1.1848, -1.4563, -1.0489, -1.1758,  0.5346,\n",
      "        -1.1740, -1.7497, -1.1826, -1.2776, -0.9333, -1.6353, -1.8048, -0.4537,\n",
      "        -1.6977, -1.6789, -1.7550, -1.5980, -1.7714,  0.6540, -1.4141, -0.9384,\n",
      "        -0.0701,  0.1495, -1.4984, -1.1468, -1.6512,  2.2696, -1.0836,  0.9316],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.8032, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.9619,  1.1224, -2.3978,  1.4775, -1.7105, -2.4595,  4.2587, -1.1806,\n",
      "        -1.0064,  1.4382, -1.7370,  3.7726,  2.2721,  1.3219,  1.7692,  2.6800,\n",
      "         1.5850, -1.3105, -2.5850, -1.1487, -1.0343, -1.1543,  1.2630,  1.1375,\n",
      "        -1.5323,  1.5663, -1.0864, -1.1100, -1.9281,  2.1139, -2.3219,  1.7300],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6535,  1.9401, -1.9955,  0.2291, -1.6706, -1.1521,  0.7479, -0.9149,\n",
      "        -1.0192,  1.1640, -1.0840,  1.2604,  1.7377, -1.0310,  0.3557,  1.0606,\n",
      "         1.0715, -1.6401,  0.0439, -0.3441, -1.0223,  1.2541,  1.9229, -0.7161,\n",
      "        -1.7652, -0.5462,  1.4934, -0.4208, -1.9999, -0.5504, -1.0693,  0.1039],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(4.2715, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0455, -2.4021, -2.1375, -2.2076, -2.1526,  1.3949,  1.7788, -1.5729,\n",
      "        -2.1888,  1.1024, -1.9069,  1.7370, -1.9778,  1.5071,  1.0780,  2.0195,\n",
      "         1.0180,  2.7549, -2.5136,  1.1575,  2.9542,  1.0464,  1.1969,  1.1929,\n",
      "        -2.0224, -5.8745, -1.8401, -2.0194, -1.5979,  1.5818, -1.5516, -1.6321],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9886, -1.6970, -1.6223, -1.7808, -2.0095, -0.0267,  0.9137, -1.2193,\n",
      "        -1.6753, -1.6350, -1.0222, -1.0924, -0.8589, -2.3876, -1.6753,  1.2166,\n",
      "        -1.0431,  1.3609, -1.9535, -1.8687,  1.6818, -0.9783,  1.7110, -0.0800,\n",
      "        -1.2738,  0.1716, -1.1837,  0.4875, -1.7007,  1.5252,  0.3685, -2.1572],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.7486, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8467, -2.0952, -2.4595, -1.3167,  1.5850,  1.3022, -1.8571, -1.6912,\n",
      "        -2.4288, -1.2630, -1.3109,  1.7370, -2.4041, -2.3149, -1.1069, -1.3965,\n",
      "        -2.1445, -1.1155,  2.3641, -1.2801, -1.1317, -2.4595, -1.3923, -2.3741,\n",
      "        -1.4636,  2.3541,  3.0502, -1.0738, -1.4866, -2.7667,  1.6293,  2.5025],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4207, -1.1141, -1.1954, -0.3399,  1.2503,  1.3899, -1.8825, -1.6497,\n",
      "        -2.0286,  1.6075, -0.7738, -1.0822, -1.8733, -2.0101, -2.0591, -1.9526,\n",
      "        -2.0805, -1.5930,  1.5689,  0.8193, -1.2099,  0.7725, -1.3799, -1.5270,\n",
      "        -1.4154,  0.4001,  1.4564,  0.7633, -1.9401, -1.6303,  1.6854,  1.3287],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(4.1327, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3683, -1.3138, -2.9386,  1.6201,  1.2224, -1.5198,  1.4904,  1.2224,\n",
      "        -2.9798, -2.5124, -1.0153, -1.1703,  1.4150, -1.2291, -1.9069, -1.5850,\n",
      "         2.0000, -2.1927, -1.2659,  2.6586, -1.1616, -2.3575,  1.4330,  1.4854,\n",
      "        -1.1676, -3.3976,  1.1871,  1.7040, -3.3709,  1.2390, -1.3400, -2.8524],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1059, -1.2252, -1.7935,  1.2815,  0.3994, -0.8770, -1.6075,  1.3800,\n",
      "        -0.8587,  0.6266, -0.9336,  1.1218, -0.5553, -1.7725,  1.0674, -1.1739,\n",
      "        -1.2290, -1.6294, -0.0821, -0.5238,  0.7541,  0.9392,  0.1264, -0.6091,\n",
      "        -1.5647, -1.1930, -1.6649,  0.9990, -0.5452,  1.2453, -1.3449, -1.3945],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.3635, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3085, -1.5850, -2.0241, -1.0444, -1.4359,  1.3814, -1.6118,  1.7077,\n",
      "        -2.0976,  2.5962, -2.6405, -1.9260,  2.4195,  2.0940,  1.7499, -1.8561,\n",
      "        -1.9713,  1.1371, -2.0000,  1.9016, -2.1234,  1.1957,  1.2022, -1.7650,\n",
      "         1.1527, -1.0766, -2.8073,  1.0681,  1.3196, -2.8073, -3.5983,  1.6157],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7776, -1.1828,  0.1851, -0.9159, -1.0540,  1.7775, -0.1365,  1.3126,\n",
      "        -0.2145,  1.6250, -1.6220, -1.1551,  1.0013,  0.9051,  1.8160, -1.7352,\n",
      "         0.2746,  1.5753, -1.7148,  2.2305, -1.2152,  1.3907,  1.1505, -1.9882,\n",
      "         0.5941, -1.0704, -0.9593,  0.6561,  1.1588, -1.7651, -1.0905,  1.1763],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 70 Predict 1024 zeros 659 ones, one bias 0.391563\n",
      "train loss: 1.976439432346777 dev loss: 1.6016610041748265\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.9825, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1770, -1.2479, -1.3015, -2.6955, -1.2194, -1.0064,  4.9357, -1.5671,\n",
      "        -1.9594,  1.4291, -1.1535,  1.0669, -3.1043,  1.6917, -2.9681,  1.1414,\n",
      "        -2.6477, -1.0870, -1.5850,  1.2320,  2.6906, -3.7603, -1.7833, -2.8812,\n",
      "        -2.0395, -1.4708, -1.5309,  1.2546,  1.4854,  2.1066,  1.0194, -1.7923],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8200e+00,  1.2766e+00, -1.2307e+00, -1.2725e+00, -1.6801e+00,\n",
      "        -1.6804e+00,  2.7369e+00, -7.0983e-01, -1.4653e+00, -1.7864e+00,\n",
      "        -1.5535e+00,  8.9589e-01, -1.7725e+00, -1.4177e+00, -2.0489e+00,\n",
      "        -1.7214e-01, -1.3235e+00,  2.3024e+00, -2.3925e-03, -1.3315e+00,\n",
      "         2.4981e+00, -1.9078e+00, -1.6896e+00, -1.1504e+00,  1.0198e+00,\n",
      "        -3.1485e-01,  6.1957e-02,  1.2041e+00, -8.1524e-01,  7.2605e-01,\n",
      "         1.9019e+00, -1.7547e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.3188, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4467, -1.0308,  2.3707,  2.6825, -1.0875,  1.3577,  3.1831,  1.8403,\n",
      "         1.4981,  1.3300, -1.3878,  1.4617, -1.4111,  2.3317, -1.7370,  1.0592,\n",
      "        -1.0995, -2.2033,  2.6800, -1.0873, -1.1937,  3.5626,  1.7994, -2.2016,\n",
      "        -1.1584, -1.7140, -2.5850, -1.4854, -1.0486, -2.1027, -1.5850, -1.2097],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6405,  0.2017, -0.7493,  2.0931, -1.6464,  1.4943,  1.9971,  1.0131,\n",
      "         1.1189, -1.0731, -0.5985, -1.3958, -1.8651,  1.9133, -1.4166, -0.7894,\n",
      "         1.9241, -2.1768,  1.2395, -1.3039, -1.3527,  2.1986, -0.3422, -1.3917,\n",
      "        -0.5402, -0.9673, -0.1233, -1.4613, -1.7762, -1.1771, -1.3396, -1.9415],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.1670, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0618, -2.2865,  1.3119, -2.9260, -1.1970, -1.8611, -1.8473, -1.2732,\n",
      "        -1.8194, -3.5034, -1.6180,  1.3905, -1.4854, -3.5480, -1.7262,  1.6818,\n",
      "        -1.4543, -1.5850,  1.1183,  2.9711, -4.0000, -1.0241, -1.9260, -2.8073,\n",
      "        -2.5850,  1.6706, -1.9349, -2.0360, -1.4054,  1.3119, -1.7908, -1.1336],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7975, -0.7391, -0.9971, -1.8052, -1.8475, -1.9460, -1.7534, -0.2743,\n",
      "         0.9718, -1.8123, -1.3954,  0.6229, -0.5568, -1.9769, -1.9837, -0.0927,\n",
      "        -0.8443,  1.3695,  1.8525,  0.9136, -1.0307, -2.1472,  0.3028,  0.3563,\n",
      "         0.8853,  0.4234, -2.0442, -2.1461,  0.1358,  0.5781, -2.0149, -1.6433],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.6500, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2058, -2.5095, -1.8841,  1.6883,  2.5594, -1.0126,  1.0297, -1.9260,\n",
      "        -1.4454,  1.5784,  1.4231, -3.2327, -1.6553, -2.0305, -1.0522,  1.3196,\n",
      "         1.7914,  1.3322, -1.6818, -2.1722, -1.3033,  1.4773, -1.8954, -1.1942,\n",
      "        -3.3976, -1.9069, -1.0260, -2.3188, -1.5102,  1.6568,  2.0000, -1.3020],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4435, -0.9122, -0.9956, -0.7928,  0.0329,  2.0755, -0.6781, -0.6844,\n",
      "         0.0517,  1.1318, -0.4076,  1.1464, -0.5239,  1.6558,  1.3632,  1.5630,\n",
      "        -1.2443,  1.0262, -1.1910, -2.5451, -1.7259,  1.0188,  0.3070, -1.8018,\n",
      "        -1.2302, -1.0259, -0.6828, -2.1781, -1.9756, -0.2880,  0.8797, -2.1256],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.9224, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1319,  1.0680, -1.3138, -3.2015,  1.1333, -2.9696,  2.1066, -1.6700,\n",
      "        -1.6675, -1.3219,  1.2167, -1.2955, -1.6321,  1.2479, -1.9492,  1.5703,\n",
      "        -1.5850, -1.1317, -1.4256,  3.0444,  2.4328,  1.2167, -1.3185, -1.0827,\n",
      "         1.3814, -3.1936, -1.0589, -1.0766,  1.2303, -1.8313,  1.9523,  1.2941],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6624, -1.3391, -0.5737, -1.6549, -1.0449, -1.5947,  1.1565, -0.0232,\n",
      "        -1.5549, -1.6622, -1.6513,  0.9509, -1.8571,  1.3455, -1.8137,  1.1677,\n",
      "        -1.5285, -0.8882, -0.5532, -1.1684,  1.0651,  1.1066,  0.3517, -0.3814,\n",
      "         2.6458, -1.6670, -1.8888, -1.0288,  1.0144, -0.2970, -1.7351, -0.8371],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4103, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8074,  1.6147,  1.4553,  2.8705, -1.7744, -2.0725, -2.2197, -1.0181,\n",
      "        -2.4010, -2.0034, -2.4420, -1.1155,  1.2412, -1.3036,  1.7746, -2.8073,\n",
      "        -2.1927,  2.0000,  1.0704,  3.2720, -1.1040,  1.8522, -2.0369, -1.1368,\n",
      "        -1.8571,  2.2926, -1.2929, -1.4706, -1.6618,  1.0780, -1.8146, -1.5475],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0524, -0.1628,  2.2803, -0.3833, -1.0056, -2.1000, -2.0247, -1.9365,\n",
      "        -2.3233, -1.2488, -1.7576, -0.6847, -1.5449, -1.4438,  1.5121, -1.0947,\n",
      "        -1.4763,  0.7999, -1.5224,  1.7720, -0.4482,  1.5826, -1.9081, -1.6749,\n",
      "        -1.9602,  1.0721, -2.0956, -1.2119,  1.4408, -0.6554,  1.3618,  0.9693],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 71 Predict 1075 zeros 608 ones, one bias 0.361260\n",
      "train loss: 1.943479247710695 dev loss: 1.3073019190674238\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5544, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4629, -2.4285, -1.3539,  1.5004, -1.2996, -1.1615, -1.0562, -1.1638,\n",
      "        -3.1193, -1.2854, -1.2044, -1.5178, -1.2224, -1.3923, -1.9879,  2.0118,\n",
      "        -1.1317, -2.5850,  1.6591, -2.1155,  1.6818,  2.3431, -1.5850, -1.6980,\n",
      "        -2.4586,  1.1414,  1.2167,  1.6770, -1.0875, -1.3818,  1.7769,  1.5850],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8056, -1.4794, -1.6913,  0.1306,  0.8984, -1.3957, -0.8523, -1.6376,\n",
      "        -1.6332, -1.8154, -1.7224,  1.0931, -1.6987,  0.6241, -0.0185,  1.4901,\n",
      "        -1.3657, -1.6677,  1.2664, -1.0864,  0.5720, -1.5887, -1.5354, -1.3383,\n",
      "        -1.8880, -0.4291, -1.0756, -1.5735,  1.5202, -1.6355,  0.3746, -0.2227],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.0984, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5968,  1.5850, -2.1155, -2.4595, -2.7613,  1.1483, -2.2563, -2.3150,\n",
      "         1.0180,  1.8298, -1.5850, -2.4010, -2.3219, -1.7125,  1.4527, -1.0869,\n",
      "         1.3219, -1.1540, -2.8154,  1.3219,  1.4150,  1.9745,  2.5594,  2.2721,\n",
      "         1.4418,  2.4099, -1.1806, -2.4586,  2.3219, -1.4150, -3.0764, -2.0875],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0644, -0.0414, -1.7819, -1.9715, -0.9747,  0.6001,  0.5901, -2.1263,\n",
      "         0.9569, -1.8738, -1.5171, -1.8736, -1.1968,  0.8445,  0.4022,  1.1592,\n",
      "        -0.3422,  0.6013, -2.0551,  0.9842,  0.8216,  1.1433,  0.2392,  1.1730,\n",
      "         1.1478, -1.7752,  0.6566, -2.4039,  1.0918,  0.7794, -1.9109, -1.7546],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.5314, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1024, -1.1926, -1.0233, -1.2752,  1.6032, -3.2613,  1.8235,  1.7382,\n",
      "        -1.0870, -1.5017,  1.3219, -1.4935, -2.3219,  2.0000, -1.7045, -2.0848,\n",
      "         1.2357,  2.7587, -2.3324, -1.1161,  1.0704, -1.7262, -1.4973, -1.1631,\n",
      "        -1.2730, -1.4150,  1.5311,  1.1375, -1.7593, -1.5971, -1.7309,  1.5090],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6740, -1.4454,  1.3072, -1.2434,  1.3508, -2.0136,  1.5995, -0.0701,\n",
      "        -1.4222, -1.5516,  0.2559, -1.0741, -0.0507,  1.4727, -1.1388, -1.0312,\n",
      "         0.8867,  0.9424, -1.3787,  1.1426,  0.5953, -1.7221, -1.6740, -1.6600,\n",
      "        -1.6542, -1.3429,  0.7113, -1.1874, -1.9715,  0.5806, -1.8207, -1.3072],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.4928, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0343, -1.7029,  2.3541,  2.9069,  1.8235,  2.1066, -1.0522, -2.4285,\n",
      "         1.4150, -1.1726, -1.2854,  1.1871, -3.6897, -1.1258, -1.4610, -1.1676,\n",
      "        -1.1942, -1.0237,  3.4150, -1.5025,  1.5850, -1.4763,  1.6172, -3.2627,\n",
      "        -1.3587, -1.3142, -1.1876, -2.2197, -3.9069, -1.3905, -1.6818, -2.4595],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5955, -1.4617,  1.2226,  1.0759,  1.2915, -0.4699,  0.1978, -1.8747,\n",
      "         1.9030, -1.1583, -1.6677,  1.5492, -1.5678, -0.7792, -1.7731, -1.2229,\n",
      "        -1.4688, -1.5868,  0.8438, -1.0386,  1.0463, -1.6328,  1.1894, -1.8344,\n",
      "        -0.3341, -1.6210, -1.4541, -1.7565, -1.6727, -1.6983, -1.5280, -1.7009],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.7768, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3785, -2.4432, -1.2214,  1.9668, -2.1234, -1.1444, -1.8649, -1.8458,\n",
      "        -1.6787,  1.1782, -2.0215, -1.4374,  1.5004, -1.0583,  1.5187, -3.7603,\n",
      "        -1.9260, -4.3174,  1.0177, -1.8571, -3.4215, -1.5194, -2.3028,  1.6722,\n",
      "         1.0763,  1.1069, -2.2605, -1.3310, -1.4256,  1.4374,  1.3255, -3.0000],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.1501, -1.4822, -0.9074,  1.4659,  1.1183, -1.1797, -1.7750, -0.4824,\n",
      "        -0.0999, -1.0561, -1.6323,  1.1961,  1.0011, -1.7053,  1.3185, -1.6679,\n",
      "        -1.4693, -1.9219, -1.5620, -1.8810, -1.6596,  1.2695, -0.4805,  1.7019,\n",
      "        -1.0777, -1.6048, -1.5639,  1.5060, -1.5496,  1.1150, -1.5789,  1.4078],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.3030, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3332, -1.7011,  1.5240, -2.6623,  4.3219,  1.1506,  1.0912,  1.4557,\n",
      "         1.5850,  1.8263,  1.4143, -1.4109, -1.3529, -3.2327,  1.5585, -2.4413,\n",
      "        -1.4695,  3.2020, -1.5729,  1.3414,  1.1234, -1.0153, -1.6080, -1.0155,\n",
      "         1.7129,  2.1293,  1.0756, -2.1333,  1.7914,  1.1481, -2.6262, -1.2044],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.9977, -1.2592,  1.2468, -1.7847,  1.3231, -0.9113,  1.3172,  1.0484,\n",
      "         0.0425,  0.2234,  0.8962, -0.9749, -1.0249,  0.4330,  1.3487, -1.2802,\n",
      "        -0.7885,  1.4836, -0.6306, -1.0332, -1.8199, -1.0841,  0.7437, -1.9091,\n",
      "         1.0610,  0.8809, -1.7655, -1.9642, -0.3119,  0.3674,  1.0659, -1.8544],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 72 Predict 1090 zeros 593 ones, one bias 0.352347\n",
      "train loss: 1.9272927526923198 dev loss: 1.6110844835506033\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5799, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1979,  3.3219, -2.4586,  1.0888, -2.4507, -1.1405, -1.4795,  2.0611,\n",
      "        -2.4432,  1.5193, -2.0351,  2.6630,  2.6586, -1.5282, -3.1375,  1.0180,\n",
      "         2.9942,  1.1226, -1.0583,  1.1040, -1.5850, -1.0809,  3.0502,  1.1350,\n",
      "         1.5195,  3.2016,  1.1375, -1.3973,  1.7105,  1.0608,  1.7124,  1.6712],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2124,  0.6935, -2.0424,  1.1596, -1.9467,  1.1603, -1.0480,  1.6056,\n",
      "        -1.9161,  0.2389, -1.9323,  2.0470,  1.4959, -0.6804,  0.5974, -0.7163,\n",
      "         1.5250,  2.1145, -2.1193, -0.6752,  1.4785, -1.7868,  1.6911, -0.6207,\n",
      "         1.0069,  1.3327,  1.1324, -0.6208,  1.7559, -0.3907,  0.2496, -0.8223],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(4.1818, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5850, -2.2598, -2.3219, -1.1069, -1.5360,  5.4918, -1.6025, -1.0342,\n",
      "         1.3172,  1.7914, -1.5629, -1.5198,  1.8122, -3.1043, -2.0918, -1.5009,\n",
      "        -1.0375,  1.1846, -1.4519,  2.8073, -1.2904,  1.0067, -1.7570, -1.0774,\n",
      "         1.6917, -2.5095,  1.1690, -1.1478,  1.0841, -1.9260,  1.3219,  1.0841],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8649,  0.9841, -0.2881,  1.0721, -1.6298, -1.0597, -1.4075,  0.5567,\n",
      "        -0.7536, -1.0205, -0.2892, -1.2589,  1.5853, -1.4875, -1.0950, -1.6060,\n",
      "        -1.8438,  0.0564, -1.3921,  2.1473, -1.2990,  0.8041, -0.7443, -0.9871,\n",
      "        -1.0089, -1.3408,  1.8539, -0.6975, -0.0997, -1.1221, -1.6663,  1.6300],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.4050, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4418,  2.1066,  1.3156,  4.0297,  1.1135,  2.3219, -1.4763,  2.7176,\n",
      "         1.3196,  1.5713, -1.5151,  1.9434,  1.6344, -1.6080,  2.3216, -2.3219,\n",
      "        -2.2076,  1.5606, -2.0862, -2.6999, -1.6265, -1.1069,  1.2412,  1.1483,\n",
      "        -2.5469,  1.0680,  1.4775, -4.2094, -1.8480, -2.7004, -1.3755,  1.0680],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.7974, -0.6983,  1.5022,  1.3961,  1.3216,  0.8110, -1.2907,  2.5002,\n",
      "         0.3436,  1.6417, -1.7929,  0.9788, -0.4112, -0.9892,  0.3449, -1.1278,\n",
      "        -0.9907, -1.6192, -1.0571, -0.3945, -0.1511, -0.4710,  1.0218,  0.3141,\n",
      "        -1.0631,  0.3390,  1.3240, -1.0441,  2.0567, -1.2782,  0.5411, -1.4612],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.7124, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0170, -2.8524, -2.8694, -2.0034,  3.7726, -1.4507, -1.5502, -1.3923,\n",
      "        -1.0827, -1.9746,  1.4076,  2.3707, -1.3105, -1.3422, -1.9260, -1.1823,\n",
      "         1.5648, -1.5850, -2.2492,  1.3970, -1.8598, -2.0995, -1.4379,  4.9357,\n",
      "        -2.3318, -2.6999, -2.2076, -1.9386, -3.5607, -1.3785, -2.1180,  1.1699],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6048, -1.5466, -1.4343, -1.3664,  1.0849, -0.8903,  1.0808, -1.6736,\n",
      "        -2.5307, -1.7032,  1.4324, -1.2060, -1.8791, -1.7919, -1.5384, -0.8331,\n",
      "        -0.8017, -2.1824, -1.7874,  0.1731, -1.1371, -1.9535, -0.6798,  2.0207,\n",
      "        -1.9650,  0.1745, -1.4226,  0.0884, -1.8438, -1.4586, -1.3322,  1.0706],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.6791, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5236,  1.2475, -1.3278, -1.0041, -1.5850,  1.0446,  1.4241, -1.5024,\n",
      "         1.5110, -1.9260,  2.9942, -2.2373,  2.0224, -3.5850, -1.4975,  1.2538,\n",
      "        -2.2624, -1.2756, -1.7370, -1.1259,  1.7004,  1.2070, -1.0280, -2.1180,\n",
      "        -1.0987, -1.0863, -1.3785,  1.2705, -2.0251, -1.0870, -1.0181, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8267,  0.5304, -1.9973,  1.3689, -1.7409,  1.0810,  1.7535, -2.1208,\n",
      "         0.6317, -1.6823,  2.5636, -1.5337,  2.2324, -0.6604, -1.9785,  0.7919,\n",
      "        -2.1992,  0.3055, -2.2848, -1.8882,  2.1379,  2.6058, -1.9457, -1.1403,\n",
      "        -1.7524, -2.0578, -0.4997,  1.2891,  2.3140,  1.0824, -2.0417, -1.4949],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(4.6329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3091, -1.3278, -1.1543,  1.5850,  1.1219,  1.6092,  1.3196, -1.8561,\n",
      "         2.2654, -2.5850,  1.4970,  3.4150,  1.7914, -1.1205,  1.5187,  1.5915,\n",
      "         2.4150,  1.4854,  1.9125, -1.2682,  1.2603, -1.8074, -2.0517, -1.2806,\n",
      "         2.4866, -1.9095,  3.1414, -1.0970, -6.6121, -1.0639, -2.8524,  2.4780],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9127, -2.1487,  1.7815,  1.1742, -1.0882,  0.7210,  2.2047, -1.9075,\n",
      "         0.2984, -1.0625,  1.1726,  1.9563, -0.5879,  0.0912,  0.4709, -1.2311,\n",
      "        -1.4530,  0.1797,  1.8294, -1.3975, -1.2837, -2.0011,  0.0196, -0.0396,\n",
      "         1.1005, -1.7382,  0.8870, -0.8781, -1.0912, -1.7359,  0.0987,  1.1822],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 73 Predict 1047 zeros 636 ones, one bias 0.377897\n",
      "train loss: 1.8837470876274116 dev loss: 1.5071839071468964\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.9656, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4594, -1.1630,  2.2410, -1.1069,  5.4918,  2.4150, -1.7250, -1.8467,\n",
      "        -2.4594,  1.2022, -1.1081, -1.3310,  1.6594, -1.2630, -1.9778,  1.1024,\n",
      "        -2.0000, -1.1322, -1.0431, -2.7370,  2.2654, -1.8572, -1.0941,  1.2022,\n",
      "        -1.5151,  1.3219,  2.0000,  1.5585, -2.0725, -1.7609,  2.3219, -1.1844],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2417, -0.1261, -1.2090, -0.7459, -0.5437,  1.2618,  0.4971, -1.1916,\n",
      "        -1.1409,  0.1770, -0.9442,  0.0250,  1.4543,  0.5576, -1.2102,  1.4067,\n",
      "        -0.6939,  1.2775,  0.7525, -0.9531,  0.5797, -1.3036, -1.9181, -0.2171,\n",
      "        -1.8670,  0.2999,  1.5548,  1.3045, -1.8531, -2.2452, -0.7117, -1.7837],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.4376, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.3219, -2.6041, -3.1699,  2.6553,  1.8428,  1.3931,  2.0000, -1.4098,\n",
      "        -2.8694, -2.2569, -1.7447, -1.2116,  1.5105, -1.1631, -1.9401, -2.2016,\n",
      "        -1.5247, -1.5439, -1.1876,  1.0681, -1.1945, -2.3622, -2.0451, -1.2682,\n",
      "        -1.9850, -1.7045, -1.3840, -1.1699, -2.4825, -2.3219, -2.3019, -1.7685],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8593, -1.8316, -1.5186, -0.7113,  0.3109,  1.3639,  1.9444,  0.8652,\n",
      "        -0.1210, -1.7006, -1.7643, -1.4916, -0.3878, -1.5665, -0.9188, -1.3990,\n",
      "         0.6083, -1.8971, -1.1353,  1.1346,  1.6037, -1.6480, -1.7157, -1.3027,\n",
      "        -1.0576, -0.9741, -0.5225, -1.6359, -0.6492, -1.5288, -0.0627,  0.5609],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.5959, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5523,  1.0906, -2.0875, -1.6515, -2.3923, -3.3785, -1.8571, -2.2750,\n",
      "         2.1047,  1.1699,  1.9594, -1.5025, -1.8313,  1.5825,  1.2941, -1.7513,\n",
      "         1.5482,  2.7176, -1.8747, -2.3091, -1.1155,  1.6631, -1.2397, -2.2441,\n",
      "         1.5606, -1.6515, -1.9069,  1.7800, -1.7513,  1.1878,  2.1066, -1.1259],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6505, -1.0291, -0.9098, -1.5624, -1.4826, -1.5963, -1.7459, -1.6043,\n",
      "         1.6277,  1.1258,  0.7835, -1.8880, -1.6604,  0.9012, -0.1783, -0.9951,\n",
      "         1.2403,  1.1519, -1.6891, -1.1354, -0.1929, -0.4037, -1.6967, -1.6075,\n",
      "        -1.6304, -1.6904, -1.0785,  1.1275, -1.0392, -1.4458,  0.9744, -1.0429],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(5.0850, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0485, -1.7001, -1.5078, -2.4285, -2.3219, -1.0773,  3.4594,  1.9260,\n",
      "        -2.1468, -3.3219,  1.7623,  5.2785,  1.1371,  1.5624,  1.1320, -1.7004,\n",
      "         1.3705,  1.2154, -1.5025, -1.2755, -1.5242,  1.2407, -1.8745,  1.0180,\n",
      "         1.5797, -1.2291,  1.0117,  1.3797,  3.0558, -1.7843, -1.8945, -1.9149],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.6515, -2.1208,  0.2133, -1.4592, -0.9650, -1.6682,  1.0413,  0.9652,\n",
      "        -0.7137, -1.1147,  0.9529, -1.3270,  1.3619,  0.4408,  0.4448, -1.5058,\n",
      "        -1.3236, -1.8576,  0.4411, -0.0992, -1.1132, -1.8702,  2.0101, -0.1044,\n",
      "         1.3170, -1.9669,  1.2537, -1.8768,  1.2937, -0.2507, -1.6996, -1.5075],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.6533, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2988, -1.3219, -1.2630, -2.9087,  1.2872, -1.2224,  1.0776, -4.7549,\n",
      "         2.1123, -1.2479,  1.6706, -2.3708, -1.9260, -1.0870,  2.5025,  1.1024,\n",
      "         1.2205, -2.8524,  1.5120, -2.9696, -2.0632, -1.3840, -1.5657, -1.6696,\n",
      "        -2.9681, -1.1147, -1.3278, -1.5439,  3.0255,  1.5986, -1.5850,  4.0786],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4513,  1.1857, -1.2661, -1.8233,  0.9753, -1.3611,  1.0446, -0.3796,\n",
      "         1.3268, -1.7876,  1.6475,  0.8287, -1.1529,  0.9826,  0.7790,  0.2133,\n",
      "        -0.5182, -0.4807,  0.8661, -1.3926, -1.1374, -1.1677, -1.7903, -1.8982,\n",
      "        -1.6168, -0.6548, -1.5765, -2.0310, -1.6230,  1.6496, -1.6446,  1.6597],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.2957, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9260, -1.9722,  1.0545,  2.0000, -1.5984, -1.5439, -1.4047, -2.0429,\n",
      "        -3.7565, -1.3142, -1.6987, -1.3105, -1.1602, -1.7923, -1.9260, -1.2730,\n",
      "        -1.2988, -1.1923, -1.6492,  2.9297,  3.7726,  1.8517, -1.6049, -2.3536,\n",
      "        -4.6049, -2.0395, -1.3923, -1.4336, -2.1905, -2.0410,  2.0471, -1.3870],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4236, -2.1228,  1.4296,  1.6234, -1.6709, -1.9436, -0.1565, -1.1284,\n",
      "        -1.7848, -1.6319, -0.7064,  1.0781, -1.6297, -1.6995, -0.8910, -1.1763,\n",
      "        -1.7126, -1.7009, -0.8950,  0.9713,  0.4437,  1.9458, -1.3841, -0.0524,\n",
      "        -0.2650,  0.8644, -1.6606, -1.1655,  0.6032,  1.1509,  1.1794, -0.9089],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 74 Predict 967 zeros 716 ones, one bias 0.425431\n",
      "train loss: 1.9665028054866778 dev loss: 1.4357373480425215\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.5044, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4111, -1.2090, -2.0875, -1.1945,  1.7601,  1.3219, -1.6003, -2.4432,\n",
      "        -1.3219,  1.5324,  3.0255, -2.1727, -1.8458,  1.3219, -1.0272, -1.9947,\n",
      "         1.1947, -2.8651, -2.4284, -1.0358, -1.5850, -1.0308,  1.0770, -1.1907,\n",
      "        -1.8480,  1.5135,  2.3541,  1.1537, -2.7307,  2.5670,  1.3551, -1.2938],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6277, -0.3897, -1.6826, -1.6784,  0.1945,  0.0637, -1.1746, -1.6246,\n",
      "        -0.5765,  0.8853,  0.1620, -1.0869,  0.1903,  1.4198, -1.6747, -1.7097,\n",
      "         1.3742, -1.6052, -1.4849, -1.6976, -0.1744, -1.3221,  0.9402, -1.4991,\n",
      "         0.2712,  1.4655,  1.3747, -1.0171, -1.7363,  1.6350,  0.0406,  0.3957],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7852, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7935,  2.6625, -1.7415, -1.9260,  1.1575, -1.9260,  2.5025, -1.0115,\n",
      "        -1.5092,  2.4866,  1.5624,  2.1699, -2.5850, -1.4256, -1.9260,  1.9349,\n",
      "        -1.7004, -1.2291,  1.0395, -1.4642,  1.8592, -1.5025, -1.8313, -1.0387,\n",
      "        -1.1155, -1.0181, -3.3424,  2.1967, -1.3923, -1.9539, -1.5271,  2.3431],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6515,  0.8967, -1.8761, -1.2229, -1.7604, -1.5839,  2.4887, -2.0022,\n",
      "        -1.3931,  1.0154,  1.4595,  0.8823, -0.9108, -1.7629, -1.0565,  2.3061,\n",
      "         1.3887, -1.8729, -0.7536, -1.6167,  0.3097, -1.0994, -0.4918, -1.9767,\n",
      "        -1.7025, -1.7211, -1.4153,  2.7319, -1.3041, -1.4704,  1.0641,  0.9651],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.8597, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7769, -1.9778, -1.1543,  1.3565, -1.0869, -1.7250, -1.0870,  3.7635,\n",
      "        -2.0000, -1.0870, -1.5032,  1.8235, -1.5523,  1.3219, -1.8146,  4.1761,\n",
      "        -2.1155,  1.2992,  1.2361,  1.3529,  1.2167, -1.1176, -1.5850, -1.4935,\n",
      "        -1.3878, -3.0704, -3.5607, -1.2687, -1.3278,  1.8723,  2.4060, -1.7046],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5824, -0.3085,  1.2373,  0.2003,  0.6250, -1.5704,  0.0208,  1.9825,\n",
      "        -0.5504,  0.8966, -1.4305,  1.3215,  1.2660,  0.7739, -0.8719,  1.9458,\n",
      "        -1.8839,  0.2438,  0.8776,  1.2820, -1.4266, -1.6516, -1.3684, -1.8338,\n",
      "        -0.1089, -1.8679, -1.2432, -1.6384, -1.8061,  1.5088,  1.6398, -0.8473],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(4.0726, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.1986, -1.0802, -3.3966, -1.2966, -1.5309, -1.6618,  1.1236, -1.7004,\n",
      "         1.8171,  2.7558, -4.7279, -1.2966, -1.6338,  1.9234,  1.0592, -1.9542,\n",
      "         3.0000, -1.1975, -2.1255, -1.9850, -1.1540,  1.4450, -2.1058,  4.7944,\n",
      "        -2.0369,  2.9519, -3.2730, -2.9386,  2.9341, -1.3219, -1.3138,  2.1699],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.3552, -1.4737, -1.0426, -0.6267, -1.0429, -0.3536, -0.5589, -0.0488,\n",
      "         1.1048,  1.1642, -0.4144, -1.5197, -0.1790,  1.2964,  0.5873, -0.7595,\n",
      "         1.6334,  1.3157, -0.7256, -0.5866, -1.4468, -0.0274, -1.5439,  1.0933,\n",
      "        -1.5833,  1.4459, -0.8983, -1.5355,  1.4974, -0.9509,  0.4253, -1.5826],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.2460, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0618, -2.1155,  1.0085,  1.3736, -2.8297, -1.7726, -2.8073, -2.0000,\n",
      "         1.3773, -1.5247, -1.8598, -1.1979, -2.8073, -1.7415, -1.0308, -1.0870,\n",
      "        -2.0275, -1.6825,  1.2907, -2.9493, -1.2547,  2.2021,  1.0728, -2.2441,\n",
      "         1.0098,  1.2633, -3.3424, -1.8309,  1.2992,  2.0195,  1.3196, -3.1993],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7868, -1.1322,  0.8038,  1.8691, -1.6312,  0.2512, -0.8580, -0.7943,\n",
      "        -1.5189, -1.1829, -1.3955, -1.4379, -1.0774, -1.6329,  0.5781, -0.6560,\n",
      "        -1.5885, -1.5622, -1.1868, -1.5355, -1.6456,  0.0805,  1.6855, -1.4584,\n",
      "        -0.7258,  0.8998, -1.0759, -1.6083, -1.5241,  1.6165,  1.4801, -0.9125],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.1647, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6280,  1.0024, -2.1405,  1.8074, -1.2419, -1.6255,  1.2320, -1.0962,\n",
      "        -2.6999, -1.3276, -1.6118, -1.5850, -1.4150,  1.0119,  2.2721, -1.3785,\n",
      "         1.0555, -1.5025,  1.4307,  1.4105, -1.0952, -1.4256, -1.3422, -2.8168,\n",
      "         4.5443,  1.4915, -1.5025, -1.1694,  2.4328, -1.0766,  1.1107, -1.5354],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1018, -0.3007, -2.2690,  1.1297, -1.7540, -1.7223,  1.4040, -1.1594,\n",
      "        -1.0109, -1.1738,  0.0588,  1.0052,  1.0791,  1.7487,  1.4991, -1.0169,\n",
      "         0.0988,  1.6250,  1.1567,  2.0389, -2.1478, -0.8624, -1.9577, -2.0349,\n",
      "         1.7463, -1.6435, -2.0797,  1.0889,  1.5252, -1.2144, -1.7402, -1.4482],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 75 Predict 995 zeros 688 ones, one bias 0.408794\n",
      "train loss: 1.903708440531587 dev loss: 1.5531364246041628\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.5726, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0546,  1.0902,  1.2407, -1.5902,  1.2224,  1.4076,  1.1699, -2.8276,\n",
      "         1.5193,  2.1463,  1.6818, -2.2479,  1.4360, -1.4372, -1.0767, -1.4354,\n",
      "         2.9069,  1.4968,  2.1865, -2.0369, -1.4205,  1.6823, -2.0000,  1.3814,\n",
      "        -1.1100,  1.4228, -1.5151, -1.7004, -2.6323, -1.5850, -1.6700,  1.6714],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.2880, -1.3154, -0.5418, -1.3070, -1.5847,  1.0649,  0.1255, -1.8812,\n",
      "         1.6893,  1.0289,  1.6995, -1.7133,  1.7907, -1.5561, -1.0255, -1.1821,\n",
      "         1.1388,  1.1453,  1.3758, -1.9577, -1.7857, -1.1337, -0.3360,  1.1762,\n",
      "         0.2712,  0.4391, -1.6854, -1.1469, -1.1603, -1.5591, -1.7455,  1.4323],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(4.1010, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4205, -1.5151,  1.9353, -1.4208,  1.0177,  2.5670,  1.7162, -1.0870,\n",
      "         2.1623,  1.9372, -1.4854, -2.6630,  2.9069, -2.9696, -1.0583,  2.3342,\n",
      "        -2.1993, -1.2955,  2.1986,  2.1066,  2.7855, -2.0657,  2.1304, -1.9069,\n",
      "        -4.0000, -3.1193, -3.4594, -1.4044, -2.0410,  1.5090, -1.7289, -1.3278],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9552, -1.1313,  1.8733, -1.2997, -1.6239,  1.1983, -0.2324, -1.6725,\n",
      "         1.2747,  1.3136, -1.2065, -0.4278,  1.6150, -1.4047, -1.6998, -0.3294,\n",
      "        -1.5998, -0.1847,  0.0452,  0.0506, -1.0838, -1.0521,  0.5288, -1.0296,\n",
      "        -0.9188, -1.7414,  0.6859, -1.2545, -1.2784, -1.6806, -1.7092, -0.8944],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.0630, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0952,  1.9386,  1.2538, -1.6924, -1.2224,  2.1196, -2.3003, -2.3801,\n",
      "         1.2752, -1.1165, -1.7923, -2.5136, -1.5439, -2.3547, -1.4936,  1.4387,\n",
      "        -1.0688,  1.0826, -2.0050, -1.7814, -1.9069, -1.3755,  1.0189,  1.3091,\n",
      "        -1.3809, -1.3785, -1.6049,  1.2350, -2.6930, -1.2065, -1.0869,  1.2538],\n",
      "       device='cuda:0')\n",
      "tensor([-2.0379,  0.1253, -1.0695, -1.8793, -0.6756,  0.9487, -1.7333, -1.5921,\n",
      "         0.5696, -1.6372, -1.5810, -1.6959, -2.0936, -2.0016, -1.1449, -0.8483,\n",
      "        -0.2580,  0.9006, -1.7880, -1.4900, -1.2405,  1.0018, -1.3848,  1.5699,\n",
      "        -1.6759, -1.0281, -1.6065,  0.7261, -1.9728, -1.6641, -1.5073,  0.3121],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.9428, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2127, -1.8716, -1.6492,  1.5408, -1.1703, -1.1155,  1.4477,  1.4094,\n",
      "         1.2224,  1.3219, -1.5850, -1.7650, -2.4595,  1.4854,  1.3069, -1.7001,\n",
      "        -1.5850,  2.5025, -3.3219,  2.0000,  1.2022, -3.2525, -1.1273,  1.1527,\n",
      "        -1.4205,  1.2977, -2.5941, -1.6265,  1.2224,  1.3785, -1.6978, -1.2611],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2597, -1.4162, -1.3355,  1.7486,  0.9294, -0.8032, -1.7035, -0.2266,\n",
      "        -1.1684,  1.5925, -0.8651, -1.8798, -1.8002, -1.8222, -0.1226, -1.6380,\n",
      "        -1.4620,  2.1309, -0.6317,  2.1857,  1.0201, -2.1306, -0.4588,  1.1892,\n",
      "        -1.3915,  1.9328, -1.6839,  0.0409, -1.0953, -0.1181, -2.2441, -1.2932],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.9514, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0431, -1.0084, -1.3765, -1.8745,  1.4275, -2.1312, -1.8689,  1.1947,\n",
      "        -1.3425, -1.9513, -1.4054, -1.2241, -1.6415, -1.7405,  2.3366, -1.7370,\n",
      "        -1.9260,  1.8160,  1.3344,  3.4175, -1.1540, -1.0700, -1.9383, -1.7004,\n",
      "        -1.3278, -2.2865,  2.5698, -2.2066, -1.3388,  2.1865, -1.5850, -1.8716],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5110,  0.6646,  0.8882, -1.3036,  1.1776, -1.6991,  1.3356,  1.2529,\n",
      "         0.1170, -1.5039, -0.3773, -1.8501, -1.8411, -0.4883,  2.1192, -1.0543,\n",
      "         0.6023,  0.5280,  0.6887,  1.0531,  0.9477, -1.6473, -1.2792,  0.5302,\n",
      "        -1.9635, -0.4867,  2.2932, -1.6842, -1.7336,  1.3817, -1.4244,  0.3563],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.0265, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0509,  1.4888,  1.2837, -1.8074,  3.1075,  1.6750, -1.2904, -2.4420,\n",
      "        -1.1520, -3.0508, -1.2680, -2.8073, -1.0864, -2.0429,  2.0209,  1.4950,\n",
      "         1.6917, -2.0082, -1.9713, -1.1864,  1.1874, -2.3394, -1.1543, -1.8313,\n",
      "         1.7010, -1.6510,  1.8221, -1.2736, -1.1178, -1.0536,  1.5400,  3.5850],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5660,  0.2518,  1.9081, -1.3703,  1.7459,  1.5534, -1.3858, -0.4901,\n",
      "        -0.6052,  1.0297,  1.2144, -1.4541,  1.0702, -0.9420,  1.5611,  2.1139,\n",
      "        -0.1700, -0.8549, -1.4551, -1.6149, -0.6836,  1.0937,  0.2091,  0.8886,\n",
      "         0.5699, -1.5823,  1.4231, -1.4787,  1.5392, -0.8285,  1.4603,  0.9442],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 76 Predict 1041 zeros 642 ones, one bias 0.381462\n",
      "train loss: 1.8634768973853768 dev loss: 1.6640867860738469\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.7740, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.7384,  4.5071, -2.3575, -1.4917, -1.1839,  2.8378, -1.9260, -2.0901,\n",
      "         1.4374, -1.1937, -2.5850,  1.3785, -1.0774, -2.8745, -1.5850, -1.3655,\n",
      "         3.0760,  1.6714, -1.2557, -1.5154,  1.1699, -2.6955,  1.5850, -2.0632,\n",
      "        -1.4400, -1.2682, -2.3833, -1.6553,  2.9014,  1.8991, -2.0410, -1.8458],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3836,  1.3590, -0.1570, -0.3314, -1.9140,  0.8759,  1.1818, -1.2824,\n",
      "         1.3730, -0.6349, -0.6789,  0.7641, -2.2297, -1.4281, -1.1655, -1.4248,\n",
      "         0.6239,  2.0448, -1.7678, -0.0432,  1.3325, -0.8417,  0.9125, -1.8804,\n",
      "        -1.9241, -0.9372,  0.9431, -1.2568,  1.1015,  1.5455, -1.1874, -0.8665],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.1397, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9885,  2.4132,  1.1929,  2.0000,  1.5596,  2.7777,  1.7318, -1.2730,\n",
      "         2.0682,  1.5850, -2.4432,  2.2716,  1.8105, -1.5475,  1.0841,  2.1699,\n",
      "        -1.0370,  1.3255, -1.0153,  1.3219,  1.3196, -1.4598, -2.2044, -2.9696,\n",
      "         1.5850, -1.1540, -1.8074,  1.3212, -2.5745, -2.0208,  2.0682, -1.8458],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5676,  0.2271,  0.3304, -0.4268,  1.1145, -1.1308,  1.2055, -1.7636,\n",
      "         1.3644,  1.2592, -1.9365,  0.9121,  1.2496,  0.8259,  0.8232,  1.4974,\n",
      "         0.9841, -1.4271, -1.1988,  0.0735,  0.2162, -1.3409, -1.6767, -1.8042,\n",
      "         0.9436, -0.9720, -0.6020,  1.1483, -1.6195, -1.5084,  1.4729, -0.5596],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.9849, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1065, -1.3111, -1.6700, -2.0428,  1.5825,  1.5850, -1.6108, -1.4780,\n",
      "         1.0431,  3.3692, -1.3149, -1.3461,  4.3219, -1.1072, -2.3219, -2.4127,\n",
      "         2.3219,  1.7914, -1.0371,  1.3219,  1.4053, -1.2771, -2.0875, -1.3536,\n",
      "        -2.5095, -2.6739, -1.0308,  2.6825, -3.4811,  1.3022, -2.0000,  3.3173],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2716, -1.5260, -0.7994, -2.0814,  1.7881,  1.1602,  0.9536, -1.6083,\n",
      "        -0.3998,  1.5893, -0.6307, -1.5796,  1.0453, -0.0274,  0.2790, -1.1016,\n",
      "         1.9789, -0.4750, -1.4119,  0.9696,  2.0202,  0.5463, -1.6606, -0.9861,\n",
      "        -1.1439, -0.6817,  0.1790,  1.7725,  0.1422,  2.3269,  0.6829,  1.3550],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.6158, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1508, -1.6010, -1.9260, -1.8251, -1.0870,  1.7746, -1.2224, -1.0139,\n",
      "        -2.0451, -1.4137,  3.0444, -2.9265,  1.1201, -1.0870, -2.8342,  2.4938,\n",
      "         1.5315,  2.1047,  2.6825,  1.7162, -4.7549,  1.1779, -1.1375, -1.8708,\n",
      "        -1.1520,  1.3196,  1.6379,  1.5624, -2.3842, -1.3624,  1.0047,  1.5332],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9326, -1.6768, -0.4927, -0.3309, -1.3060,  1.4335, -0.6067,  0.8426,\n",
      "        -0.6654, -1.7640,  1.7569, -1.6293, -0.9391, -1.0210,  0.0040,  2.6747,\n",
      "         1.8199,  1.3391,  0.2622,  1.3234, -0.1560,  1.2935, -1.3500, -0.9062,\n",
      "         0.3305,  1.6086,  1.6773, -0.0053, -0.8767, -0.5400, -1.0758,  1.0722],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.7434, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5661,  1.7800, -1.2988,  1.2167, -1.4137, -1.0841, -4.5850, -2.1180,\n",
      "        -4.7549, -1.3450,  1.1822,  2.5754, -2.1905,  2.0000, -1.1823,  3.4525,\n",
      "        -2.9696, -1.8977, -1.8747, -2.3219,  1.1555,  1.5825,  1.5001,  2.1986,\n",
      "         1.8403,  1.0452, -2.2569, -1.3055,  1.3332,  1.1024,  1.4208,  1.0841],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1925,  0.4075, -1.4783,  1.3099, -1.4194, -1.5524, -1.5548, -1.1152,\n",
      "        -1.0790,  0.8740, -1.4983,  1.1958, -0.3325,  1.1787, -0.8579,  1.3208,\n",
      "        -1.7389, -1.8032, -1.4228, -0.4465,  1.3180,  1.0724,  1.7227,  0.0721,\n",
      "         0.8091,  2.1122, -1.5787, -0.8460,  1.2683, -1.2093,  0.7436, -0.8795],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.7946, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1375, -1.5671, -2.5850, -1.7970,  1.3468, -1.2158, -1.9260, -1.0041,\n",
      "        -1.8571, -1.5151, -1.6008, -1.4044, -1.4642,  1.4307, -1.5092, -1.7370,\n",
      "         2.7111,  1.2224, -2.4041,  2.3219, -1.8158, -1.0738,  2.0451, -1.2222,\n",
      "         4.0416,  1.6567,  2.0000,  2.5698, -1.1778,  1.3219,  2.3692,  2.0946],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.4888,  0.8037, -1.3930, -0.2090,  0.8485, -2.2500, -1.5183,  1.3351,\n",
      "        -1.6055, -1.3044, -1.3221, -1.7839, -1.8462,  1.8025, -1.7578, -0.1475,\n",
      "         2.8067, -0.1967, -0.0582,  0.3220, -0.9831,  1.1377,  0.5289,  0.3759,\n",
      "         2.3689,  1.1413,  1.6384,  1.6776,  0.4542, -0.0910,  0.7845,  0.6744],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 77 Predict 1125 zeros 558 ones, one bias 0.331551\n",
      "train loss: 1.895786134828347 dev loss: 1.431947003582416\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.3429, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.5731, -3.8073,  1.7565,  2.2721, -1.2682, -1.8745,  1.7677, -1.6707,\n",
      "         1.1602, -1.1375,  1.2390, -2.0767, -1.0869, -2.4595,  1.3196, -3.3219,\n",
      "        -1.1508, -1.7843,  3.1414,  1.9323,  2.8073, -2.0251,  2.0682, -1.5850,\n",
      "        -1.1844,  1.6562, -1.4354, -1.0064,  1.1076, -1.9260, -1.8864, -1.8977],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3257, -1.2404,  0.8410,  0.8222,  0.6639, -0.1849, -1.1602, -0.9788,\n",
      "         0.1931, -0.7002,  1.0142, -2.3556, -1.8141, -1.7566, -1.5992, -1.7045,\n",
      "        -1.4923, -1.8376,  0.7653,  1.4877,  1.4820, -0.0296,  1.0459, -1.5283,\n",
      "        -1.1948, -0.7407, -0.3807, -1.8405, -0.7156, -1.8529, -1.5683, -1.9938],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.5775, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7045, -1.1726, -2.8290, -1.2630, -1.7004,  1.0618,  1.1371,  1.6883,\n",
      "         2.5850, -2.5850, -1.4935, -3.1509, -1.7045, -1.6700,  1.5850, -1.3838,\n",
      "        -2.3738, -1.8539,  1.0024, -2.6363,  1.1200, -1.9260,  1.3022, -2.9358,\n",
      "         2.0506, -1.2851, -1.9947,  1.1871, -1.7628, -1.5850,  1.3219, -1.7047],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8267, -1.6321, -1.8761, -1.4628,  0.5228, -1.0483, -0.2585, -0.9426,\n",
      "         0.8927, -0.8626, -1.8093, -1.7134,  0.5604, -1.3220,  0.8330, -1.7412,\n",
      "        -1.7848, -1.9914,  1.5708, -2.2119, -0.1699, -0.7711,  1.5993, -2.0212,\n",
      "         0.2418, -1.9025, -1.6199,  0.5262, -0.7906, -1.7893,  0.1506, -2.0313],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.4518, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5850, -1.5730,  2.2334, -1.5538, -1.1754, -2.2816, -4.1430, -1.5170,\n",
      "        -1.1375, -3.3628,  1.2685,  1.0888,  1.4518,  2.0989,  1.6147, -1.8313,\n",
      "        -2.7553, -3.2613,  1.4773,  2.0209, -1.8708,  1.2685,  1.5105,  1.9668,\n",
      "        -1.7004,  1.4374,  1.6204,  1.1264,  1.3670,  1.9781,  1.4150, -2.7346],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8775,  0.2249,  0.2375, -1.9200, -1.6988, -1.2332, -0.4371, -1.3099,\n",
      "        -1.0914, -1.2180,  1.5766, -1.3420,  0.5652,  0.9292,  0.1964,  0.9025,\n",
      "        -1.6884, -1.9947,  0.8503,  1.5032, -0.8334, -0.6059,  1.2514,  0.6977,\n",
      "        -1.1890,  1.4130,  1.2194,  1.7232,  1.7619,  1.7453,  1.3101,  0.0258],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.6943, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7912, -1.4354, -1.3624, -1.1813,  2.2869, -1.4513,  3.1075, -1.1203,\n",
      "         2.3366,  1.9260, -1.2752, -1.0377,  1.2224,  1.0545, -1.9143, -2.7760,\n",
      "         1.1947, -1.6288, -1.4256, -1.6059, -1.2663, -2.1905, -2.8073,  5.2785,\n",
      "         1.3219,  4.7944, -1.5417, -1.2675, -1.6482, -1.3263,  1.8403,  2.0919],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9533,  0.8899, -1.8210, -1.8898, -1.1970, -1.6245,  2.5325,  0.5768,\n",
      "         1.9374,  0.9443, -2.2714, -1.7662,  0.7057,  1.6017, -1.6004,  0.7445,\n",
      "         1.4265, -1.5255, -0.9076, -1.7708, -1.8345,  0.1418, -0.2887,  0.6535,\n",
      "        -0.8656,  1.4024, -1.4688, -1.2064,  0.0157, -1.2268,  1.2135,  1.2705],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.8069, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5374, -2.9087, -1.2152,  1.1826,  3.1414,  1.0841,  1.0577, -1.8470,\n",
      "        -1.2851,  2.0810, -2.0220, -1.5850, -1.8433, -1.8864,  1.2436,  3.1075,\n",
      "        -2.3028,  1.9971, -2.0000, -2.3219, -1.1621,  1.7605,  1.1481, -1.5633,\n",
      "         2.1325,  1.2320,  1.4773, -1.3388, -1.5746,  2.4195,  1.5135,  1.8496],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2854, -1.9635, -0.2574, -0.0907,  1.9799,  1.0823,  1.3273, -1.4545,\n",
      "        -0.8880,  1.6180, -1.1632,  0.7733, -1.8857, -1.9286,  0.8448,  1.9454,\n",
      "        -2.0093,  1.2876,  0.5833,  2.8080, -1.2509, -0.5231, -1.1700, -1.2845,\n",
      "         1.4137,  0.6329,  1.1047, -1.7385, -1.3400,  0.4262, -1.6350,  0.0726],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2313, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0809, -1.8074, -1.6908, -1.2966, -2.1113,  2.1155,  1.1475, -1.9778,\n",
      "        -1.5024, -1.2848,  1.1183,  1.4387, -1.5730, -2.5850, -2.6658, -1.0870,\n",
      "        -1.9005, -2.1918, -1.0613, -1.5850, -2.5850,  1.0237, -1.8598,  1.8403,\n",
      "         1.5330, -1.7991, -2.0275, -1.3105, -1.4167,  1.6897, -2.8073,  1.8122],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0590, -1.6381, -1.1137, -1.1382, -1.7973,  1.1855,  1.3526, -0.9807,\n",
      "        -2.2028, -1.2800,  0.8130,  0.1474, -1.3653,  0.8973, -1.3659, -0.4743,\n",
      "        -0.7341, -1.6311, -1.1856, -1.5386, -1.9057,  1.1159,  1.5279, -1.1325,\n",
      "         1.8305, -1.2510, -1.7915, -1.5941, -0.9808, -1.7358, -0.9446,  1.5124],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 78 Predict 1137 zeros 546 ones, one bias 0.324421\n",
      "train loss: 1.9045634937553513 dev loss: 1.788809956432027\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.7023, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1445, -2.0920, -2.4595, -1.8074, -1.3167, -2.0050, -2.4417, -1.9539,\n",
      "        -2.1226,  1.5803, -2.7613,  1.6172,  1.3219, -1.0870, -2.1226, -2.6924,\n",
      "         1.5502,  2.2630, -1.7908,  2.1463, -3.9449, -1.5850,  1.3499, -3.0119,\n",
      "        -1.8716,  1.2320,  1.3219, -1.8138,  2.4841, -2.8073, -2.0360,  3.9986],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8082, -2.3058, -1.6840, -1.3550, -1.5174, -2.2651,  1.0094, -1.9387,\n",
      "        -1.3085,  0.1484, -1.8301,  0.6464, -1.1770,  0.9813, -1.7394, -2.0326,\n",
      "         1.2816,  0.0515, -2.1448,  1.1387,  0.5446,  0.7582, -0.4454, -1.8903,\n",
      "        -1.7549,  0.8653, -0.0300, -2.1371, -1.2364, -0.7119, -1.1453,  1.3836],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.1240, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3398, -1.7004, -1.0875, -3.2912, -3.3966,  1.6567, -1.9539, -1.9421,\n",
      "        -1.0115, -2.0451,  2.0000, -1.2801,  2.6786,  1.7370, -1.3923,  1.8403,\n",
      "         1.8221, -1.4359,  1.9372,  1.2303,  3.1414, -1.4611, -1.3105,  1.1699,\n",
      "         1.8496, -1.4894,  1.7914, -1.0773, -2.3708, -2.4780, -2.8297,  1.3212],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2852, -1.2213, -1.3003, -0.7284, -1.6944,  1.2008, -1.7641, -1.2965,\n",
      "        -1.8946, -1.3478,  1.4550, -0.6083,  0.8819, -0.6766, -1.8006, -1.1198,\n",
      "         1.0716, -1.4464,  2.0751,  1.1334,  0.9392, -1.8961, -1.6849,  1.3878,\n",
      "        -0.0970, -0.1001, -1.4745, -1.6619, -1.7642, -2.0618, -1.9387,  1.2888],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.0324, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9260, -1.0803, -1.1258, -3.2015,  1.5624, -1.5422, -3.6897,  1.4475,\n",
      "         3.1075, -2.6521, -1.6280, -3.6075, -1.0237, -1.9143,  1.6722, -1.1628,\n",
      "        -1.4936, -1.3940, -1.5850, -2.0241,  1.5305, -1.3923,  2.3219, -2.9798,\n",
      "        -1.7140,  1.5850, -1.2977, -1.5708, -2.7370, -1.9349,  1.2515,  1.2111],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4794, -1.8580, -1.1534, -1.7854, -0.1983,  1.1127, -1.8341,  1.2950,\n",
      "         1.2289, -0.0831, -2.0054, -1.8098, -1.4083, -1.9546,  0.0624, -1.7280,\n",
      "        -0.1776, -1.9051, -1.5192,  1.4803,  1.0741, -1.8138, -1.2327,  0.4588,\n",
      "        -1.4628, -0.2633, -1.6847, -1.6109, -1.7839, -1.4178,  0.2251,  0.9368],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.9929, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1155, -2.3708, -1.6826, -1.7144,  3.5850,  1.7776, -1.9260,  1.1226,\n",
      "        -1.3204, -2.1927,  2.0810, -1.1255,  1.0776, -1.1147, -2.1445,  2.6586,\n",
      "        -1.4055, -1.9713,  1.8403,  1.5784,  1.3414,  2.8431, -2.5395, -1.2070,\n",
      "        -1.9260,  1.1865, -1.4359, -1.4795, -1.8074, -2.0792, -1.1935, -2.8073],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3422, -1.5302, -2.2000,  0.9831,  1.1787,  1.4423, -1.2340,  0.5525,\n",
      "        -1.9105, -1.7247,  1.3754, -0.9902,  0.8616, -1.1006, -1.3248,  1.1278,\n",
      "        -1.3505, -1.7927,  1.1329,  1.3280, -1.1751,  1.6768, -1.4890,  1.8674,\n",
      "         0.9468, -1.0617, -1.1207, -1.8285, -1.8041, -1.9002, -1.7507, -0.4187],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.5493, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3624, -2.7004, -2.2492,  1.8122, -1.3785, -1.0641,  1.5850,  1.1016,\n",
      "        -1.0358, -1.8819, -1.5242,  2.6051,  1.3814, -2.1905, -1.2630,  2.6800,\n",
      "         1.1957, -1.5417,  1.5648,  1.8884, -1.2955, -2.7004, -2.0000, -2.0395,\n",
      "         1.1226,  1.0810, -1.0248, -1.9260,  1.9069,  2.4150, -1.6338, -1.7938],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5116, -1.8425, -1.9733,  1.1727, -0.5216, -1.4876,  1.2776, -1.5373,\n",
      "        -1.7360, -1.6683, -1.1778,  1.0740,  1.1051,  0.4242, -1.3139,  1.6822,\n",
      "        -0.2902, -1.4140, -0.9416,  1.0320,  0.5973, -1.6412, -0.9489, -0.7448,\n",
      "         0.9575,  1.3412, -1.5790, -1.3155,  1.5398,  1.4312,  1.0772, -0.9910],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.2151, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5136, -1.1630, -2.2292,  1.5105,  1.9723, -1.6280, -2.0767, -1.1726,\n",
      "         1.6499, -1.1060, -1.2682,  1.2857, -2.2569,  1.4076, -1.6265, -2.0305,\n",
      "         1.5004, -2.0275,  1.4594, -1.5502, -1.6084, -3.2854,  1.2167, -1.0870,\n",
      "        -1.5538, -2.0000, -1.5247,  1.7974,  2.4060, -1.3109, -2.0241,  2.0000],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6688, -1.6700, -1.7289,  1.4442,  1.4979, -0.1637, -1.8598, -1.4477,\n",
      "         1.5280, -1.9154,  0.1775, -1.2405, -1.6766, -1.0966, -1.7626,  0.0090,\n",
      "        -0.6829, -1.7671,  1.1808,  1.3148, -1.0687, -1.3121,  0.6037, -1.2458,\n",
      "        -1.6103, -1.1860, -1.8742,  1.5032,  1.4060, -1.2853,  0.9300, -1.5053],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 79 Predict 1013 zeros 670 ones, one bias 0.398099\n",
      "train loss: 1.8993150208228058 dev loss: 1.590188200313516\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.0670, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7004, -1.5850,  1.6121,  1.0554,  1.8460,  2.6716,  2.5359, -1.8158,\n",
      "         1.0688,  1.1699, -2.3526,  1.4307, -1.3167, -1.5660,  2.0358, -2.3188,\n",
      "        -1.4150,  1.8160, -1.4812, -1.7923,  1.7010,  3.0255,  1.4387, -4.6049,\n",
      "        -1.6496,  1.5850, -2.0939,  1.3101, -1.4791,  1.2954, -1.6208,  2.0000],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6790, -1.4663, -0.3736,  1.4168,  1.4645,  1.5358,  1.8409, -0.9709,\n",
      "         0.1148,  0.3328, -1.2045, -0.5942, -1.6611, -1.8600,  1.5675, -1.4811,\n",
      "         0.1090,  1.1163, -0.1335, -1.6233,  1.7143,  1.1141,  0.9477,  1.1073,\n",
      "        -1.3670, -0.9837, -1.7150,  1.5651, -0.8220,  1.3869, -1.1633, -1.3832],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7666, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5705, -1.4359,  1.0324,  1.0749,  1.3101, -1.1444,  1.3536, -3.2525,\n",
      "        -3.2730, -2.8073,  2.9519,  1.5850, -1.8383, -1.2900, -1.5729,  1.8074,\n",
      "        -1.5850, -1.4132, -1.3292,  1.5676, -1.3388,  2.0623,  1.3498, -2.0451,\n",
      "         1.1020, -1.9635,  1.6701, -1.1510, -1.2682, -1.2977, -1.1368,  1.2685],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3927, -1.0750,  1.3976, -0.4356,  1.4686, -1.2103,  0.6085, -1.9768,\n",
      "        -1.4887, -1.8282,  0.6332,  0.8095, -2.0231, -1.9568, -1.2450, -1.7661,\n",
      "        -1.4751, -0.0272, -1.7545, -0.5402, -2.1525,  0.9851,  2.3658, -0.5277,\n",
      "         1.7013, -0.8323,  0.6077, -1.0993, -1.7744, -1.6684, -1.4226, -1.0503],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.1502, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9260, -2.1641,  1.8074,  1.2022, -1.7744,  2.9069,  1.1575, -1.5629,\n",
      "         1.6362, -2.0395,  1.4031,  2.1699, -1.6280,  1.3498,  1.2165,  2.2654,\n",
      "         2.3696, -3.3785, -1.0549, -1.2675,  1.3773, -2.2076, -4.0000,  2.0211,\n",
      "        -2.4595, -2.9696, -1.8658,  1.3711, -1.5884,  1.0177,  2.5359, -1.8950],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3793,  0.1893,  1.3017,  2.1256, -0.9382,  0.7080,  1.0431, -1.4623,\n",
      "        -1.0115, -0.3333,  0.0221, -1.3192,  0.3360,  1.3440, -0.9336,  1.1973,\n",
      "         2.0512, -1.9906, -1.6585, -0.9604, -0.6109, -1.1812, -1.1088,  0.6717,\n",
      "        -1.6527, -1.2355, -1.4720,  1.3120, -1.0438, -1.5159, -0.3193, -1.2430],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.3642, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3978,  1.5624, -2.0000, -1.4721,  1.9723, -2.2605,  2.1057, -1.0827,\n",
      "         1.5001,  1.4105, -1.1211,  1.4594,  1.5337,  1.4579, -1.0463,  2.3219,\n",
      "        -2.3219,  3.2843,  2.3334, -1.2680, -1.9635,  1.3484, -2.9696, -1.4336,\n",
      "        -1.7909, -1.4132, -1.6180, -1.0387, -1.2680,  1.8592,  1.1690, -1.9069],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5145,  0.4555,  1.0277, -0.7927,  2.9034, -1.5481,  0.7986, -1.6290,\n",
      "         1.7421,  1.3488, -0.3450,  0.9615,  1.1008,  1.3873, -1.2867, -0.0619,\n",
      "         1.0048,  0.8869,  1.4504,  1.0004, -1.2584,  1.9210, -1.2676, -1.1485,\n",
      "        -1.1764,  0.2770, -1.5743, -1.5181,  1.0092, -0.8488,  0.8654, -0.8101],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.5495, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2814,  1.2518, -1.0928, -1.4137,  1.5850, -2.3058,  1.5713,  1.9809,\n",
      "         1.5850, -1.7370, -1.0766, -2.3219, -1.9005,  2.4328, -1.4150, -1.8977,\n",
      "        -1.3219, -4.6439,  1.1699, -1.1737, -3.9449,  2.0000,  1.3529, -3.6114,\n",
      "        -2.3061,  2.4924,  1.2436, -1.6084, -1.5452, -1.8841,  1.1993,  2.6215],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1734,  1.4613,  0.2334, -1.3189,  0.0059, -2.0142, -1.1481, -1.4640,\n",
      "         2.0810, -1.0740, -0.9733, -0.7057, -1.7292,  1.6595, -1.7221, -1.7122,\n",
      "        -1.3341, -1.5267, -0.8630,  0.1738,  0.8366,  0.3904,  1.3690, -1.7682,\n",
      "        -2.1554,  1.7959,  0.7805,  0.3694,  0.9175,  0.7170,  1.4290,  2.3451],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.7506, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1527, -1.0995, -3.2627,  1.2320,  1.2538, -2.7370, -1.6118, -1.4499,\n",
      "        -2.1803,  5.2785, -1.0863, -1.5850, -1.3494, -1.3033, -1.4159, -1.0070,\n",
      "        -2.1312, -1.6338, -1.1630, -1.4854,  1.1319, -2.6439, -1.9279, -1.4088,\n",
      "        -1.5850,  1.1236, -1.0181,  1.1512, -3.5034, -1.2801, -4.6439,  1.0970],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5150,  0.5150, -1.8673,  1.5484,  1.7176, -1.7524, -1.1327, -0.5507,\n",
      "        -1.3788,  1.6387, -0.1933, -0.0191,  0.0896, -0.2196, -2.0566, -0.8396,\n",
      "        -1.8096, -1.1675, -0.7927, -0.5229,  0.3232,  0.8859, -0.2927, -1.7964,\n",
      "         0.2706,  1.4128,  1.6743, -1.6824, -1.8166, -1.4528, -1.7822,  1.6477],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 80 Predict 1052 zeros 631 ones, one bias 0.374926\n",
      "train loss: 1.8446882275563072 dev loss: 1.482413251296457\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.6627, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1929,  1.5220,  3.3788, -1.4191, -2.0279,  1.4387,  1.4105, -1.9260,\n",
      "         1.4227, -1.4159, -1.9400, -2.2676, -1.7370, -1.6118, -1.5243,  2.2334,\n",
      "        -1.3245, -1.2530,  3.3219,  1.4854,  2.0327, -1.3655, -1.8309, -1.3878,\n",
      "        -1.1375, -2.5136,  1.1435,  1.8403, -3.0000, -1.6321, -1.0310, -2.3708],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.5718,  0.7992,  1.8718, -1.6800, -0.5119,  1.0148,  0.5753, -0.9004,\n",
      "         0.9154, -1.2474, -1.2294, -0.7963, -1.7524, -1.3491,  0.1583, -0.6229,\n",
      "        -1.5504, -1.1758,  0.7271,  0.8069,  0.6107, -0.0635, -1.8849, -1.1600,\n",
      "         1.1345, -1.0954,  1.2058,  1.1091, -1.4954, -1.6988, -1.8869, -1.1301],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.7321, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3626,  1.5850,  1.3014,  2.5850, -3.3219, -2.0657, -1.8232,  1.3219,\n",
      "         1.5850,  1.3219, -3.1936, -1.5224, -2.7641, -1.0641, -1.6781, -2.6439,\n",
      "        -1.5635,  1.1718,  1.0090, -2.2933, -1.3975, -1.8858, -1.2267,  3.2327,\n",
      "         1.5003,  1.1739, -2.7274,  1.4518, -1.8580, -2.0129, -1.6118, -1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6246, -0.9663, -0.1414, -1.3308, -1.3760, -1.0982, -1.4443,  0.8811,\n",
      "         0.7022,  0.9789, -1.6302, -1.6308, -1.1200, -1.2775, -0.9801, -1.2902,\n",
      "        -1.7565,  0.6282,  1.8563, -1.5843, -1.2574, -1.5587, -1.6699,  1.0380,\n",
      "         1.0963, -1.7078,  0.8469,  1.1012, -1.7109, -1.6084, -1.1107, -1.6157],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.7755, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4205, -1.5168,  1.5850,  2.0948,  1.1020,  1.7769, -1.1656, -1.6044,\n",
      "        -1.2890, -2.5395,  1.1453, -1.9778,  1.0841,  1.3196, -1.8171, -1.9778,\n",
      "        -3.5034, -1.8921, -1.3017, -1.1737,  1.1220, -2.4594, -1.1737, -1.0370,\n",
      "         1.5670, -1.4159,  1.1993, -1.3964,  3.7635,  1.1201, -2.5850, -1.0371],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8455, -1.7379,  1.0161,  1.5197,  1.3870, -0.5830, -1.2667,  0.1359,\n",
      "        -1.9224, -2.0838,  1.2450, -1.5326, -1.3009, -0.0632, -1.6625, -1.2415,\n",
      "        -1.7080, -0.8626, -1.1657, -1.8757, -0.4512, -2.2085, -1.5709, -1.2278,\n",
      "        -1.9268, -1.9601,  1.1848,  0.2348,  1.3750, -0.9395, -1.9796, -1.6012],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.9338, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.7497,  2.4841,  1.6842,  1.0912, -2.1703,  2.2334, -1.1393, -1.9418,\n",
      "        -1.8921,  2.0327,  1.9349, -2.7397, -1.5492, -2.3219, -1.4159, -3.9307,\n",
      "        -1.3665,  1.4338, -1.5170,  2.8073,  1.1844,  1.8429, -1.1444, -1.5337,\n",
      "        -1.5635,  1.8792,  1.5487, -2.5850, -1.4919,  1.3300,  1.7843, -1.8339],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7641e+00,  6.2401e-01,  1.3642e+00, -1.7018e+00, -1.7372e+00,\n",
      "         1.1523e+00, -1.8245e+00,  1.2129e+00, -1.8528e+00,  1.0484e+00,\n",
      "         1.6262e+00, -1.9669e+00, -2.0212e+00, -7.9094e-01, -1.0332e+00,\n",
      "        -1.7804e+00, -1.8400e+00, -2.7179e-04, -1.7905e+00,  4.5900e-03,\n",
      "         7.5685e-01,  1.2220e+00,  1.3423e+00, -7.0934e-01, -1.6542e+00,\n",
      "        -1.1596e+00,  1.4351e+00, -1.6342e+00, -1.7464e+00, -1.0990e+00,\n",
      "        -9.3380e-01,  1.0115e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.1653, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3550, -1.6084, -2.1234,  1.3414, -1.0941,  1.2479,  1.8122,  1.7370,\n",
      "        -1.1750, -1.3278,  1.5090, -2.6999,  1.6883,  1.1016,  2.7294, -1.5850,\n",
      "         1.0841,  2.4780,  2.5962, -1.5850, -1.5394, -1.3292,  1.3949, -3.4215,\n",
      "        -1.0766,  1.8415,  1.0750,  1.3196, -1.3167, -1.3870,  1.0024, -2.9696],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7622, -0.9854, -0.0642, -1.6149, -2.0946,  1.2361,  1.4122,  0.9905,\n",
      "        -2.2405, -2.3867, -1.6803,  0.4194,  0.8359, -2.1402,  1.4376,  0.7107,\n",
      "        -0.7863,  1.3377,  1.0685,  0.1196, -1.4179, -0.7310, -0.6336, -2.3985,\n",
      "        -1.4091, -0.6119,  1.1633,  0.9013, -0.8793, -1.0848, -0.5532, -1.0214],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.9308, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.6047,  1.0680, -1.2139, -2.0666, -1.7512, -1.2122, -1.2224,  2.4250,\n",
      "        -1.5850, -1.9586, -2.0939, -1.1679, -1.1791,  1.0794,  1.3550,  1.6562,\n",
      "        -1.3655, -2.8524,  2.0682, -1.6818, -1.9069, -2.8524, -1.7386, -1.7472,\n",
      "        -1.2267,  2.3153,  1.6300, -1.2730,  2.8705,  5.8826,  1.6172,  2.7201],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1530, -1.3195, -1.3690, -0.5931, -0.3269, -1.8504,  0.6676,  0.0678,\n",
      "        -1.9609, -1.7198, -1.3989, -1.6803, -1.4273, -1.8531, -1.7077,  1.4624,\n",
      "        -0.7525, -1.0942,  1.7010, -1.0719,  1.2918, -1.8800, -1.6702, -1.6788,\n",
      "        -1.9368, -0.9353,  1.2570, -0.7257,  0.8480,  0.9221,  1.3572,  0.2247],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 81 Predict 1101 zeros 582 ones, one bias 0.345811\n",
      "train loss: 1.8723977836805334 dev loss: 1.469977484296859\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.0647, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.5850,  1.0718, -2.7004, -1.3000, -2.8073, -1.0716, -2.7155, -1.8658,\n",
      "        -2.6739, -1.3219, -1.0115,  1.6121, -2.2338, -3.0704, -1.8458, -1.4854,\n",
      "        -1.9260, -1.0308, -2.3626, -1.5224,  1.1414, -1.4150,  1.0090, -1.1211,\n",
      "         1.7227,  3.4525,  2.4918, -1.3624, -2.5158,  1.7499,  2.0940, -1.3450],\n",
      "       device='cuda:0')\n",
      "tensor([-0.7411, -1.7078, -1.4603, -1.7182, -0.9496, -1.7759,  0.8273,  0.3105,\n",
      "        -0.2713, -1.2985, -1.9021, -0.5299, -1.7173, -1.6814, -0.6109, -1.3008,\n",
      "        -0.6904, -1.6602, -1.1663, -1.6791, -1.1824, -1.1302,  2.3327, -0.9304,\n",
      "         1.2398,  0.6134, -0.7450, -0.8679, -1.6603,  1.3215,  1.3182, -1.7109],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.5017, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0841,  2.4270,  1.7004,  1.8367,  1.1959, -1.5827, -1.4372, -1.1165,\n",
      "        -1.8228,  1.1555,  1.5850, -1.5715, -2.9696,  1.5850, -1.4372, -1.2090,\n",
      "         1.2988,  1.6897, -1.2241, -1.2070, -2.7482, -2.0370, -2.8073, -2.4694,\n",
      "         1.8122,  1.0728, -1.1737, -1.9808, -1.3102,  1.9403, -2.3547,  1.3196],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0476, -0.1378,  1.3907,  1.1404,  1.0033, -1.3933, -1.9584, -2.0955,\n",
      "        -1.3431,  0.9169,  1.4588, -1.3293, -1.3237,  0.9031, -1.8502, -0.3689,\n",
      "         0.1788, -1.6658, -0.8600, -0.1106, -1.7914, -1.8309, -1.3925, -1.6495,\n",
      "         1.6215,  1.1595, -1.6212, -1.7558, -1.9665, -0.5055, -1.8961, -0.5294],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.1054, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3318, -1.6265, -3.0704, -1.6854, -1.1679, -1.9260, -1.6003, -1.9349,\n",
      "        -1.6658,  1.0336, -1.2890, -1.7105, -2.0129, -2.4344, -1.0815, -1.8931,\n",
      "         1.7914,  3.5089, -1.2671, -1.0375,  3.0760, -1.2955, -2.0767, -2.5064,\n",
      "        -1.3530,  1.4579, -1.1975,  3.0000,  2.4071, -2.1801, -1.2025, -1.1459],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9327, -1.8995, -1.8701, -1.3386, -1.8133, -1.5239, -1.7831, -1.6699,\n",
      "        -1.5993,  1.3763, -0.1365, -1.6999, -1.3553,  0.1164, -1.5762, -1.7854,\n",
      "        -0.0213,  1.2902, -1.7175, -1.8415,  1.6390, -1.8545, -1.7454, -1.8077,\n",
      "        -1.7340,  1.2381, -1.0581,  1.2705,  1.5327, -1.5713, -1.7152, -0.7611],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.6317, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1069, -1.3105,  1.5850, -2.6939,  1.0912, -1.9386, -2.0370,  1.8826,\n",
      "        -3.3637, -3.0704,  1.2475, -1.1478,  1.9126, -1.1844, -1.1973,  1.5109,\n",
      "        -2.9696, -2.3388, -1.8313, -2.3003, -1.2291,  1.0666, -1.0827, -1.2996,\n",
      "         1.8122, -1.1703, -2.4448, -2.0666, -1.6694,  1.6580,  2.3692, -1.3900],\n",
      "       device='cuda:0')\n",
      "tensor([-0.5816, -1.1808,  1.2836, -1.8305,  1.6647,  0.2810, -1.9263,  0.8463,\n",
      "        -1.6278, -0.7112,  0.1291, -1.3139,  1.4727, -1.7299, -0.8356,  0.1638,\n",
      "        -1.2616, -1.7287, -1.6532, -1.4697, -1.8119,  1.2295, -2.2119,  0.5541,\n",
      "         1.8866, -1.2294, -1.4178, -1.2440,  0.6888,  1.7539, -0.1290, -1.5025],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.3295, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0189, -3.7603, -1.7033, -3.5034,  1.5332, -2.9696, -1.4354,  2.0358,\n",
      "         2.8705,  1.0776, -1.9704,  1.4475, -1.4711, -1.2419, -1.0343, -2.0194,\n",
      "         1.0177, -1.1165,  1.4374, -3.3709, -2.3219, -1.1375, -1.1100,  1.4785,\n",
      "        -1.8228,  4.3631,  1.8074,  1.6439, -2.8073, -2.1801,  1.3416, -2.3454],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6298, -1.6795, -1.9746, -1.7399,  1.3494, -1.6413, -1.1018,  1.2117,\n",
      "        -0.7503, -0.6329, -1.1151,  0.7156, -1.4732, -1.7582, -1.7056,  1.0428,\n",
      "        -1.6734, -1.3985, -0.4999, -1.3772, -1.2319,  0.4127, -1.7201,  1.0853,\n",
      "        -1.7690,  1.7216, -0.0673, -1.1342, -1.0086, -0.5366, -0.6827, -1.5505],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.5786, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3292,  1.4052,  3.0502,  1.5624, -1.0641, -1.9149,  2.7111, -1.5309,\n",
      "        -1.9260,  2.9341,  1.2062, -1.9260,  2.3153, -1.3655, -2.5095, -1.0536,\n",
      "        -2.1699,  2.1783, -2.2311, -1.2599,  1.4122,  1.2708,  1.0452, -1.8649,\n",
      "         2.2370, -1.2514, -1.3278,  1.6410,  1.1926, -2.2569, -1.8977,  1.8226],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7150,  0.6382,  3.8037,  0.8011, -0.6119, -1.7840,  1.2156, -1.5085,\n",
      "        -0.2241,  1.3136,  0.7003, -1.4480,  0.8521, -1.4686,  0.6034, -0.4309,\n",
      "        -1.2071, -0.2764, -1.7461, -1.6357,  1.2251,  1.7646,  1.2857, -1.7544,\n",
      "         0.4099, -1.8226, -1.7809,  0.7938,  1.2675, -1.9123, -1.7275, -0.4286],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 82 Predict 1058 zeros 625 ones, one bias 0.371361\n",
      "train loss: 1.8242856832034524 dev loss: 1.6996506892237757\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.1009, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5242, -2.1234,  1.6446, -2.0553, -1.5242, -1.5598,  1.1024, -2.7380,\n",
      "         3.1497, -2.5850, -2.6439, -1.4812,  1.0014, -1.2630, -1.4520, -2.8073,\n",
      "        -2.0241, -2.6656, -1.9746,  1.1520,  1.3728,  1.9635, -1.0576,  1.2316,\n",
      "        -1.4636, -2.2638,  2.4328,  1.2842, -1.1375, -2.1699,  2.0774,  1.2979],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7798, -1.5084, -0.1920, -1.8274, -2.0713, -1.7859,  0.4600, -2.1619,\n",
      "         1.9524, -0.9501,  0.6028,  0.7168,  0.1774, -1.5887, -1.8367, -1.9166,\n",
      "         1.4760, -1.6646,  0.0138,  1.2849, -1.0897,  1.5659,  0.1558,  0.7224,\n",
      "        -1.3973, -2.1118,  2.0360,  0.2477, -0.7369, -1.9243,  1.8048, -1.3456],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7124, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0431, -1.3684, -2.4406, -1.2929, -2.4909, -1.0768,  1.3119,  1.0281,\n",
      "        -2.9712, -1.0766, -1.0446,  2.0358, -1.0370, -1.9778, -1.2514, -1.0962,\n",
      "        -1.3215, -2.7241,  1.2320,  1.4913,  1.9971, -3.3628, -1.4855, -2.6323,\n",
      "        -1.4594, -2.4922, -1.2730,  1.1414,  1.0904,  1.1658,  2.2119,  2.6738],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6035, -1.2360, -1.6894, -1.6193, -1.8904, -1.2956, -0.2261,  0.8436,\n",
      "        -1.9465, -1.3201, -0.3662,  1.6486,  0.3137, -0.3395, -1.8253,  1.4768,\n",
      "        -1.7062, -1.8327,  1.7845, -0.7001,  1.4749, -1.8837, -0.3651, -0.0679,\n",
      "         1.3745, -1.8996, -1.8514,  0.2823, -0.1846,  0.8911,  0.6428,  1.5801],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.3331, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3624, -1.2547, -1.5850, -2.1641, -2.8073,  1.1020,  1.4962,  2.6088,\n",
      "         2.6738, -1.0875, -1.5729, -2.0251,  1.3215,  1.2110, -1.3624, -1.1375,\n",
      "        -1.0064, -1.9358,  1.1947, -4.8147,  1.0853, -1.1375, -1.5170,  1.4517,\n",
      "        -3.8000, -2.6640, -1.3655, -1.8965, -1.3745,  2.6716,  2.3219, -1.1624],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7268, -1.8516, -1.6191, -1.7322, -0.0992, -1.5544,  1.2021,  1.5547,\n",
      "         1.2437, -0.1282, -1.3351, -0.8863,  0.5534,  0.4518, -1.6648, -2.1300,\n",
      "        -1.8134, -1.7425,  1.9637, -1.2540,  1.0516, -1.7542, -1.3745,  0.4099,\n",
      "        -1.8169, -1.8847, -1.3043, -0.8864, -1.4051,  1.4293, -1.2584, -1.7460],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.2560, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8403, -1.0342, -1.5452,  2.0506,  1.7227,  1.6439,  1.3046,  4.5443,\n",
      "        -2.8073,  2.1773, -1.2801, -2.9681, -1.3388, -2.1801, -1.5850, -1.7370,\n",
      "        -3.5850, -1.2966, -1.5242, -2.1888, -2.0305, -1.6003,  1.3322, -1.4336,\n",
      "         2.6800, -1.0327, -2.1801, -1.0344,  1.8429, -1.3624,  1.5722,  1.1929],\n",
      "       device='cuda:0')\n",
      "tensor([-0.0061, -1.0960, -1.1239,  0.7573,  1.5618, -1.1283,  0.6905,  1.6378,\n",
      "        -1.8090,  1.6453, -1.1678, -2.3506, -1.7025, -0.1810, -1.6047, -1.9936,\n",
      "        -1.7921, -1.6321, -1.9432, -1.7256,  0.9232, -1.7709,  1.4636, -1.8872,\n",
      "         1.5664, -1.7065,  0.9088, -1.7594,  0.7228, -0.2343,  0.5928, -0.8405],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.0168, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6826,  2.0940, -1.0870, -1.8745,  3.0760,  1.4411,  2.3431,  2.1047,\n",
      "         1.7914,  1.7914, -3.4594,  1.3468,  2.7612,  3.7635, -1.5422, -2.6363,\n",
      "        -2.3219, -1.3539, -2.0000, -1.8561,  1.6637,  1.6157, -2.7004, -1.1631,\n",
      "        -2.0351,  1.9923, -1.0999, -1.3574, -1.6618, -1.2158,  1.3219, -1.5194],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9485, -0.6320, -1.3314,  0.4374,  1.9163,  0.9703,  0.7609,  0.2712,\n",
      "         1.2801,  0.3195, -1.6291,  0.8184,  1.5797,  2.1873,  1.1993, -2.1135,\n",
      "        -2.2417, -1.6499, -1.1955, -1.6215,  0.7342,  0.2833, -1.7922, -1.9983,\n",
      "        -2.1845, -0.2641, -1.6313,  0.5936, -0.7845,  0.2234,  1.2883, -0.8179],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.9780, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.6076,  1.5915,  1.7420, -3.3637, -1.7046, -1.2730, -2.4594, -2.0000,\n",
      "         2.0666,  1.2022, -1.5629, -1.3219, -2.1468,  3.4740, -2.8745, -2.2076,\n",
      "        -1.3292,  2.3153,  1.1285, -1.4795, -1.0999, -2.8524, -1.2058, -1.5629,\n",
      "         1.7382, -1.8686, -1.5968, -1.5850,  1.0098,  1.2022, -2.2033,  1.7061],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8919,  1.4114,  1.7042, -1.6426,  0.1019, -1.5081, -1.5784,  1.0960,\n",
      "         0.5555, -1.0700, -1.4198, -1.2003,  0.8432,  3.5055,  0.0618, -1.1387,\n",
      "        -1.1420,  0.1569, -1.2124, -1.3934, -1.8331, -0.7404, -0.6972, -0.3361,\n",
      "        -0.0380, -1.5568, -1.7954, -1.1256, -0.8267,  1.3401, -1.9779,  1.0316],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 83 Predict 1068 zeros 615 ones, one bias 0.365419\n",
      "train loss: 1.865534998378577 dev loss: 1.6544191104042467\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.6858, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5541, -1.3219,  1.6172, -1.6482, -1.7447, -1.7260,  1.2320,  4.2587,\n",
      "         1.5564, -1.4854,  1.3332, -1.1791,  1.5195,  2.1047,  1.1929, -1.8863,\n",
      "        -3.1699,  1.2979, -1.9069,  2.3541, -1.8074,  1.2606, -2.1722,  2.7425,\n",
      "        -1.1459,  1.1739, -1.1103,  2.1139,  1.9016, -1.5705, -1.2955, -1.3085],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6742,  0.7103,  1.6381,  0.6446, -1.2755, -1.1373, -0.6980,  1.1853,\n",
      "        -0.3100, -1.4986,  1.4969, -1.4317,  0.8076,  1.7711, -0.1410, -1.8767,\n",
      "        -1.2713, -1.0017, -1.4913,  0.6041, -1.6513, -1.7265, -2.5778,  1.3458,\n",
      "        -1.7924, -1.7329, -1.8165,  0.5147,  1.6855, -1.8239,  0.6361, -1.2915],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.9259, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4594, -1.7405, -4.5850, -1.8682,  1.3196, -1.3040,  1.3468, -1.3587,\n",
      "         2.6630, -1.3219, -1.8784, -1.2955, -1.8793, -1.9260, -1.3157, -2.0730,\n",
      "        -1.8580, -1.2988, -1.8686, -1.9722,  1.2538, -1.4791, -1.9386, -1.7262,\n",
      "        -1.3388,  1.3332,  2.0000, -1.1703,  3.3923, -2.4595, -1.0370, -1.5968],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0795, -1.0586, -1.5987, -1.8016,  1.6120, -0.7108,  0.6418, -1.8539,\n",
      "         1.5570, -1.0983,  0.0140, -1.7149, -1.3486, -1.1080, -1.5759, -1.7404,\n",
      "        -1.6291, -1.6947, -1.9347, -2.1698, -1.1308, -1.7754, -1.3015, -1.7289,\n",
      "        -1.6974,  1.5697, -0.3775,  1.5379, -0.2370, -1.8033, -0.3331, -2.0197],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.2901, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3196,  1.3683, -1.1444, -2.8073, -1.4150, -2.3219, -1.2888, -1.5850,\n",
      "        -2.9696,  1.4532, -2.1442,  1.7914,  2.6800,  1.0750, -2.5510,  1.3219,\n",
      "        -1.5475,  2.2331,  1.0014, -3.3966, -1.0431, -1.4795, -1.1197,  2.0358,\n",
      "        -1.0978,  2.5384, -2.5324, -1.0809, -1.8074, -2.6589, -2.2441, -1.2481],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3974,  1.7992, -0.5820, -1.0704, -0.8381, -0.0214, -1.8834,  0.4896,\n",
      "         0.4410,  1.4049, -1.4351,  0.1222,  2.4534,  1.4930, -1.7200, -0.7667,\n",
      "        -0.2542,  0.3837,  1.0366, -1.5990,  0.3481, -1.9060,  1.4548,  1.3970,\n",
      "        -1.2500, -0.3347, -1.5888, -1.6096, -1.9812, -1.8247, -1.7777, -1.6032],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.3688, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.0715, -1.6675, -1.4058, -1.2838, -1.5025, -1.9260, -2.4594,  2.3219,\n",
      "        -1.5502, -1.1737, -1.0875,  1.6736,  1.7914, -3.3219, -1.1535, -2.3708,\n",
      "         1.1718, -1.4081, -1.3745, -2.8297, -1.4058, -1.6700,  2.5731, -1.3923,\n",
      "         2.0500,  2.9014,  4.4046,  1.4322, -2.4344,  2.2331, -3.4594,  3.1983],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3259, -1.8431,  1.6461, -1.8427, -1.5341, -1.0599,  1.0951, -1.0259,\n",
      "         0.7929, -0.7577, -1.2097,  1.4327,  1.1715, -1.4983, -1.9228, -1.9731,\n",
      "         0.8895, -1.5605,  0.5124, -2.0202,  1.2096, -1.4420,  1.1374, -1.0602,\n",
      "         2.1527,  1.4025,  1.3819, -1.5444, -1.0322,  1.0902, -1.7381,  0.8946],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.2397, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5025,  1.3300, -1.8682,  1.1530, -1.7358, -2.4285, -1.2227, -1.4256,\n",
      "         2.2869,  1.4143,  2.3219,  1.5001,  1.8160, -2.3219, -1.5729, -1.7975,\n",
      "        -1.0343, -1.8561, -2.1905, -1.1155, -2.8290,  1.5146, -1.2158,  1.9649,\n",
      "        -1.0087, -1.4022, -1.5534, -1.2070, -1.9095, -1.0995,  1.3565, -2.7482],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4369, -0.8019, -2.0771,  1.6097, -1.3572, -1.9264, -1.9739, -1.1213,\n",
      "         1.5286,  0.7078,  0.3806,  1.8619,  1.1379,  1.0596, -0.2201, -0.6231,\n",
      "        -2.0614, -1.7588, -1.3900, -0.2978, -1.9758, -0.5147, -2.1428, -1.4125,\n",
      "        -1.7566, -1.0554, -0.9893,  0.3933, -1.9746,  0.4867, -0.8468, -1.6014],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4346, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1527,  2.2370, -2.1905,  1.0331,  1.2108,  1.1871, -2.4041, -2.9712,\n",
      "        -1.5971, -4.5850, -2.5043, -1.5705, -2.7370, -1.9069, -1.6472, -2.0000,\n",
      "         1.5624,  1.8207, -1.2854, -1.0738, -3.0875,  1.8931,  2.4841, -1.3757,\n",
      "         1.5110,  1.1605,  1.2658,  1.6323, -1.9539, -1.2687, -2.3028,  1.9434],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.8673,  1.0349, -0.8423,  1.2391, -0.8206, -1.2323, -1.2239, -2.5544,\n",
      "         0.2730, -1.6134, -1.1799,  0.8151, -1.2380, -1.4026, -1.2253, -0.1433,\n",
      "         1.0579,  1.5930, -1.8027,  0.9027, -0.9895,  1.3285,  0.8989, -1.3115,\n",
      "         0.5646, -0.9826,  1.7876, -0.0672, -1.8028, -1.1566, -0.8078, -0.1401],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 84 Predict 1187 zeros 496 ones, one bias 0.294712\n",
      "train loss: 1.9670158393217094 dev loss: 2.0296398637409654\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.8616, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.2985, -2.0275, -2.5850, -2.3785, -1.0371,  1.8826, -2.0000,  2.7500,\n",
      "         1.3091, -1.1679, -2.3219,  1.0408, -1.5850,  1.9349, -2.4041, -2.9386,\n",
      "         1.4448, -1.4854, -1.8846,  1.4154, -1.4454,  1.4518, -1.1536, -1.6781,\n",
      "        -1.8765, -1.9395, -1.2996, -1.0064, -2.2569, -1.0393, -2.2676, -1.1459],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9394, -2.0067, -1.8175, -1.8027, -2.1156,  1.5196, -1.5076, -1.7289,\n",
      "         0.7746, -1.8979, -2.1575, -1.1183, -1.3308,  1.8694, -2.3367, -2.1099,\n",
      "         1.3898, -0.3896, -1.6254,  1.0588, -1.8393, -0.5884, -1.8846,  0.5157,\n",
      "        -1.3337, -1.9375,  0.1249, -0.1737, -1.8748, -0.4018, -1.5924, -1.5716],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.9124, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0704,  1.1371, -1.5623,  1.0532, -1.9778, -1.3201, -1.9069, -1.7001,\n",
      "        -1.1060, -1.7512, -2.5850, -1.9383, -1.6107, -1.2224, -2.1165, -2.5136,\n",
      "        -1.3621, -5.1069,  1.4105, -1.1069, -1.3655,  2.0379,  1.2022, -1.4150,\n",
      "         1.1082, -1.8640, -1.3870, -1.5589, -1.5850,  1.2087, -1.8572, -1.2996],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9605,  0.6694, -1.1476,  1.0515, -0.5294, -1.5487,  0.8798, -1.0805,\n",
      "        -2.0522, -0.2742,  0.0108, -1.5606, -1.5307, -1.1269, -1.5454, -1.3920,\n",
      "        -1.4901, -1.0134,  1.7820,  0.0216, -1.1358,  1.3420,  0.7479, -1.7926,\n",
      "         0.4639, -1.6304, -1.0273,  0.2591, -1.2157,  0.3770, -0.2175, -0.0227],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(1.4326, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5850, -1.8921, -2.5324,  1.3532, -2.0444, -1.1165, -3.8073, -1.9370,\n",
      "         1.4535, -1.4706,  1.4360,  1.6379, -2.1076, -1.5850, -1.5850, -1.6717,\n",
      "        -1.8571, -1.0697,  1.8207,  1.4594, -2.0657, -1.4706, -1.7923, -1.8258,\n",
      "         1.1226, -1.9260,  1.3069, -3.0677,  1.3193, -1.6118,  1.1435,  1.1375],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9170, -1.3103, -1.5238,  0.4094, -0.6608, -0.2926, -1.3867, -1.2270,\n",
      "         2.0210,  0.2372,  2.2142,  1.0809, -0.3552, -1.5785, -1.1852, -1.6581,\n",
      "        -1.9070,  1.2968,  1.0523, -0.3501, -1.2607, -1.6870, -1.5653, -1.9476,\n",
      "         1.4202,  1.0102,  1.0043, -1.6372,  0.6639, -1.6263,  1.4145, -0.0686],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.8196, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2914,  4.3631, -1.9260, -1.7097, -1.1291,  1.9126,  1.2992,  1.4307,\n",
      "        -1.0116, -1.5850, -2.0050, -1.5198,  1.7010, -4.0000,  1.3069,  1.2621,\n",
      "        -3.0508, -2.5580, -1.4482,  2.6716, -1.9260,  1.6032, -1.2682,  1.0511,\n",
      "         2.0500, -1.0664, -2.1722,  1.8745,  2.1196, -1.4302, -2.4041,  1.1024],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.6237,  1.3154, -1.4432,  1.1237,  0.5255,  0.4079,  0.9006,  1.1296,\n",
      "        -1.2730, -1.5631, -1.7319, -1.5811,  1.1943, -1.2434, -0.9273,  1.7884,\n",
      "         0.7546, -1.9034, -0.1472,  1.7210, -0.9443, -0.9894, -0.6870,  0.8668,\n",
      "         1.5003,  1.0515, -1.4236,  0.6295,  2.3376, -1.5615, -0.7186, -0.7678],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.2052, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6843,  1.7914,  1.4557,  1.5193, -1.9370,  2.2603, -1.1737, -1.9376,\n",
      "        -2.1727, -2.1801, -1.8250, -1.0522,  2.0000, -1.1211,  1.1969,  1.5897,\n",
      "         4.0297,  1.3670, -1.6229, -2.7641,  1.4448, -3.3219,  1.5400,  2.3014,\n",
      "         1.2633,  1.5850,  2.7143,  1.7914, -1.2996, -2.1927, -1.5729, -1.3700],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7172,  0.7601, -0.0192, -0.2419, -0.2835,  1.2048, -1.0806, -1.6265,\n",
      "        -0.9675,  0.8709, -2.0142,  0.6635,  1.5829, -0.4855,  1.4415,  0.7106,\n",
      "         1.1005,  1.3497, -0.0329,  1.7487,  0.8346, -0.8005,  0.4898,  0.4905,\n",
      "        -0.0425,  1.0005, -0.0387,  0.9226, -0.9502, -1.6909, -0.1409, -2.0988],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.6599, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3532,  1.0770,  1.3399, -1.1737,  1.8496, -1.9260, -1.6980, -1.0815,\n",
      "         2.0000,  1.5596, -1.5671,  1.2988, -1.8924,  1.9102, -1.8426, -1.5025,\n",
      "         1.7800, -1.1520,  1.2588, -1.1615, -1.3036,  1.2538, -1.4055,  3.0760,\n",
      "        -1.7370, -1.2801, -1.5984, -1.1540, -1.0870, -2.5850, -1.1630,  1.2977],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3786,  0.3856,  1.5723, -1.2740,  0.0230, -0.7511, -0.6725, -1.8267,\n",
      "        -1.3896, -0.1847,  0.9109,  1.7851, -1.2309,  1.7104, -1.6868,  1.4979,\n",
      "         1.1461,  0.5168,  1.1120, -1.0494, -0.0910, -0.4136, -0.9639,  2.8703,\n",
      "        -1.8654, -1.2788, -1.4727, -1.0821,  0.1622, -1.3848, -0.2053, -0.3624],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 85 Predict 1097 zeros 586 ones, one bias 0.348188\n",
      "train loss: 1.8061530947608184 dev loss: 1.6934565478744144\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(4.4232, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.4250, -3.0508,  1.6712,  1.2988,  1.7677,  2.2885, -2.4304, -1.9778,\n",
      "        -1.3167, -2.0000,  1.3814, -1.6553, -1.5850, -1.3536, -1.7051,  1.1555,\n",
      "        -2.7023,  1.5482,  1.2224, -1.7004, -2.4780, -1.0431,  2.2536,  3.3847,\n",
      "         1.1082, -1.9018,  4.4313,  2.3115, -1.4208,  1.0452,  2.3575, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1642, -0.6522, -1.1427, -0.2190, -0.8944,  1.6320,  1.7402,  0.4982,\n",
      "        -0.3459, -1.2126,  1.5748,  1.2170, -0.0568, -0.9757, -1.5972, -0.9055,\n",
      "        -1.8328,  0.8766, -1.7302,  0.4949, -0.8238,  1.1880,  1.3546,  0.1061,\n",
      "         1.7479, -1.7926,  1.9494,  1.6254, -0.8486,  1.1738,  1.5085, -1.2763],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7787, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3101, -2.6656, -2.1234, -1.6854,  1.3156,  1.8592, -1.1096, -2.9681,\n",
      "        -3.1509, -1.0646, -1.0945, -1.5633, -1.9260,  1.6323, -2.2569, -1.3050,\n",
      "        -1.5708, -1.1428,  2.2081, -1.5589, -2.2378,  1.3219, -2.3219, -2.2076,\n",
      "        -2.4507, -1.3020,  2.5025, -1.2682,  1.2082,  1.8122,  2.6738,  1.4387],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5116, -1.6957,  0.8731, -2.7397, -1.4989,  1.1365, -2.3747, -2.0797,\n",
      "        -1.7499, -1.8143,  0.7710, -2.0240, -1.5595,  0.0644, -1.9013, -2.0535,\n",
      "        -1.9404, -1.0839, -0.5301, -1.0503, -1.7640,  1.3050, -1.0119, -1.4814,\n",
      "        -1.6499, -2.1940,  1.0891, -1.8003, -0.4103,  1.2735,  1.1872,  1.2912],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.3492, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.9696, -1.9746, -1.8882, -1.2224,  1.9240,  1.0902, -1.0431, -1.4055,\n",
      "        -1.7370,  1.7287, -2.0034,  1.4527,  2.0000, -2.0351,  1.5624,  2.7798,\n",
      "         2.3115, -1.8330,  1.4525,  2.2869, -3.0609, -1.2214, -4.2813,  2.3835,\n",
      "         1.0750, -1.8747,  2.0940, -1.2682, -1.1543, -1.8804, -1.9421,  3.5744],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6735, -1.4975, -1.6137, -1.1193, -0.2343,  1.3280,  1.9139, -0.9286,\n",
      "         0.2668,  0.7737, -1.4639,  1.4172,  1.6722, -1.7835,  1.1414,  0.7584,\n",
      "         1.5061,  1.0091, -0.2237,  1.7239, -2.0207, -1.4355, -1.7957,  1.0073,\n",
      "         1.3097, -1.5753, -0.9714, -1.5765,  1.7399, -1.3646, -1.5018,  2.0438],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.4219, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0171,  1.6796, -1.0863, -2.0767,  1.8711, -1.1069,  1.1082,  1.7914,\n",
      "        -1.5025,  2.4328,  1.9126, -2.0502,  1.0704,  1.4518, -2.9798, -1.3587,\n",
      "         2.8705, -1.9069,  1.2167,  2.5731,  2.0987, -2.4854,  1.4854,  1.2080,\n",
      "        -1.3530, -1.1597, -1.0308,  1.1947, -1.8977,  1.4594,  1.9267,  1.3333],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9674,  1.6651, -1.3955, -1.7978, -1.6208,  0.5175,  1.6542, -1.4721,\n",
      "         1.6829,  1.7563,  1.2226, -1.9840, -1.0291,  1.0784, -1.3092, -1.7237,\n",
      "        -0.1930, -1.0091,  0.0385,  1.7003,  1.0256, -1.1135,  1.5377,  1.9012,\n",
      "        -0.6392, -1.3663,  0.0419,  1.5896, -1.9414,  0.9512,  1.2643, -1.0467],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(4.7294, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6379,  5.2785, -1.0522,  1.3196, -1.9307, -2.4432, -2.4594,  2.9069,\n",
      "         1.7605,  3.5349, -1.5850,  1.1718, -1.2685, -1.3219, -1.7370, -1.2222,\n",
      "        -2.3219,  1.7077, -1.4894, -1.8339, -1.5422, -2.0265, -3.3709, -1.4205,\n",
      "        -1.2936, -2.0000, -1.8689, -1.2929,  2.0715, -1.2065, -1.3138, -1.9778],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0437,  0.8701,  0.7219,  1.3004, -1.7580, -1.9618, -1.7338, -0.6031,\n",
      "        -1.2320, -1.5696, -0.6123, -0.4736, -0.9660, -1.0917, -1.3501, -1.4654,\n",
      "        -0.4988,  0.7687, -1.7971,  1.3892,  1.4521, -0.7927, -0.9462, -1.1117,\n",
      "         0.9528, -0.1170, -0.8817, -1.9729,  0.5229, -1.6913, -1.4737, -1.4448],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.9566, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 4.1761,  1.8171, -2.9696, -1.7405,  3.2591, -2.8182,  1.6562,  1.2312,\n",
      "        -1.3182, -1.8977,  1.4532, -1.9778,  1.2685, -2.8745, -2.3161, -3.2613,\n",
      "        -2.8342,  1.2545, -1.8401,  1.2167,  1.5825, -1.9260,  2.4270, -2.4239,\n",
      "        -1.1679, -2.4239, -1.7262,  1.0704, -1.5469,  1.1236, -1.0815, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.3081, -1.3712, -1.7370, -0.6132,  2.0628, -1.3296,  1.0066,  1.0659,\n",
      "        -0.9197, -1.6356,  1.6634, -0.8937,  0.1981, -1.3460, -1.7029, -1.9473,\n",
      "        -1.3948,  1.0170,  1.0407,  0.7929,  1.1350, -1.3077, -0.4426, -1.6654,\n",
      "        -1.8859, -1.2132, -2.0271,  0.6470, -1.6750,  1.5362, -1.0854, -1.7926],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 86 Predict 1074 zeros 609 ones, one bias 0.361854\n",
      "train loss: 1.8151812928423134 dev loss: 1.5393077975437088\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.1854, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4150, -1.0658,  1.2002, -1.8747, -2.0444, -3.7603,  1.6722,  2.2410,\n",
      "        -1.5113, -1.8480,  4.5071, -1.8470,  1.7300, -1.5406, -1.0867, -1.5516,\n",
      "        -3.9449, -2.1312, -2.0920,  1.4915, -2.5136, -1.5705, -2.9696,  1.4143,\n",
      "        -1.0371, -1.9748, -2.2569, -1.7046, -1.1478, -1.0387, -1.9260, -1.2058],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7414, -1.0897, -0.2643, -2.0777, -0.1413, -1.6244,  1.4539,  0.6313,\n",
      "         0.5301, -1.4544,  2.0764,  0.6579, -1.3118, -1.0416, -0.6121, -1.2681,\n",
      "         0.0518, -1.8586, -1.4106, -1.6135, -0.7839, -1.4953, -1.6205,  1.0492,\n",
      "        -1.7565, -0.2169, -1.0793,  0.6445, -0.0829, -1.6662, -1.6420, -0.2505],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.7092, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5617, -1.9778,  1.1267,  3.4150,  1.1555, -1.9069, -2.0000, -1.2713,\n",
      "        -2.8412, -1.0243, -1.3772, -2.6477, -1.5850, -1.2966, -1.2685,  1.5193,\n",
      "        -1.5850,  1.9723, -2.1993,  2.7855, -1.8975,  1.1547, -1.6717, -1.2194,\n",
      "        -2.1027, -1.2778, -1.0156, -1.4454, -1.6912,  2.4156, -1.0869, -1.4432],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0886, -1.0879,  0.8576,  1.1814,  0.9046,  1.5678,  1.4122, -1.6743,\n",
      "        -1.7861, -1.8297, -1.7749, -1.4951, -1.2657, -1.5599, -1.1795, -0.9388,\n",
      "         1.4877,  3.0201, -1.1512, -0.9729, -1.2624,  1.4365, -1.6219, -1.5744,\n",
      "        -1.4620, -1.5738, -1.6808, -1.1159, -1.8124,  1.9511,  2.0286, -2.2973],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.9945, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3167, -1.0486,  1.6293, -1.0617, -2.9696, -1.3700,  2.0451, -1.3424,\n",
      "         1.9388, -1.7262, -2.5850,  2.2701,  2.5546, -1.3020,  1.0177,  2.0486,\n",
      "        -2.1468,  4.7944,  1.1962, -3.1936, -1.2955,  1.5713, -1.2304, -1.5417,\n",
      "         1.9809,  2.4270, -1.2419,  1.0153, -1.0343, -1.1631, -1.8745,  1.6714],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4950, -1.6171,  1.4938, -1.5498, -1.7920, -2.0002, -0.9314, -1.6563,\n",
      "         0.5340, -1.9438, -1.2581, -0.3254,  1.7920, -1.7452, -1.2064,  1.2379,\n",
      "        -1.8087,  1.2467, -1.6013, -1.6025,  1.1324,  0.0778, -1.3394, -1.6228,\n",
      "        -1.5543,  0.0834, -1.6705,  1.0217, -1.1131, -1.7153, -1.6439,  1.1839],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(1.2886, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0000, -1.6987, -1.5255,  1.5187,  1.9353, -1.0875,  1.1107, -2.6924,\n",
      "         1.8192, -2.1174, -1.5224, -1.3487,  1.2436, -1.3310, -1.9809, -1.3179,\n",
      "         1.8391, -1.0646,  1.6157,  2.3824,  1.3388,  1.0763, -1.0375,  2.3835,\n",
      "        -1.5208, -1.9260, -1.4626, -1.8977, -2.0096, -1.1810,  1.2090, -3.7472],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1591, -1.5835, -1.7241,  2.5978,  1.8003, -1.5766, -2.0415, -1.8433,\n",
      "         1.4825, -1.8696, -1.5814, -1.8661,  0.1743,  1.2929, -1.1996, -2.0248,\n",
      "         1.2827, -1.7701, -0.2024,  1.7124,  1.0188, -0.7777, -2.1463,  1.2575,\n",
      "        -1.6522, -1.2043, -1.7793, -1.7393, -1.3395, -1.1131, -0.8313, -1.9507],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.9731, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5960,  1.0014, -1.1532,  1.8403, -2.3061, -1.0875, -1.0945, -2.1155,\n",
      "        -2.0000, -1.9454,  1.7010,  1.3219, -1.3823,  2.2885, -1.5979, -1.9586,\n",
      "         1.0704, -1.4374, -1.6843, -1.3040, -1.1317, -1.6675, -1.0518, -1.5971,\n",
      "        -1.7287, -1.6353,  2.1293, -2.1155, -1.1259, -2.5850,  2.0000, -1.2479],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.8769,  0.9347, -0.9120, -0.4301, -1.8528, -1.1759, -1.3129, -1.6159,\n",
      "         1.1310, -1.2979,  1.3626, -1.0615, -1.5143,  1.2884, -1.3594, -1.7772,\n",
      "         0.3721,  1.2487, -1.0416, -1.3395, -1.5360, -0.5504, -1.0242, -1.7675,\n",
      "        -0.5885,  0.2823, -1.7671, -1.8016, -1.1056, -1.1669,  1.0265, -1.9183],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.5707, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8745, -1.8465,  2.0682, -1.7355, -1.3219,  1.4532,  2.8431,  1.5433,\n",
      "        -2.4595, -1.6618, -1.0704, -1.5657, -6.4702, -1.1069,  1.5057,  1.7726,\n",
      "        -1.8194,  1.7004, -3.1699,  1.3683, -2.4595,  1.2685,  2.3707, -1.1699,\n",
      "        -1.4123, -3.7603,  4.4046,  1.2354,  1.2979, -1.5850,  1.4312, -1.6781],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1710, -1.3861,  1.5167, -1.6682, -1.1263,  0.8846,  1.3224,  0.7146,\n",
      "        -1.7208, -0.5357,  0.5831, -1.3697, -1.8815, -1.9745,  1.1228,  0.2605,\n",
      "         1.4034,  1.2966,  0.2706,  1.1861, -0.7654,  1.0510,  0.8791, -0.4397,\n",
      "         0.8511, -2.1521,  1.6206, -1.2201, -0.4583, -0.7130,  0.4095, -1.2623],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 87 Predict 1115 zeros 568 ones, one bias 0.337493\n",
      "train loss: 1.8250146549699944 dev loss: 1.7128342696416243\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.5490, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4825,  1.5850,  1.2538, -1.1975,  1.1962, -3.3966, -1.8580, -1.1259,\n",
      "         1.0841, -1.0962,  1.0478,  1.1575, -2.3536, -1.0051, -1.5746,  1.5330,\n",
      "        -3.3219,  1.8122, -1.2756,  1.9267,  3.0255, -1.1535,  1.0014, -1.3149,\n",
      "         1.8991, -1.3219, -1.0391, -1.0875,  1.0554, -1.3400, -6.4702,  1.0770],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9960,  0.2939, -0.5963, -2.4848, -1.7043, -0.7828, -1.9095, -1.6606,\n",
      "        -0.2393, -1.6282,  0.7924, -2.0855, -1.6578, -1.1015, -1.8402,  1.7137,\n",
      "        -0.7191,  1.3613, -1.1556,  0.3237, -1.2745, -1.4250, -0.2294, -1.7256,\n",
      "         1.1647, -1.6031, -1.5969, -2.0302,  1.2504, -0.8188, -1.9650,  1.1210],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.2999, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1973, -1.5850,  1.8367,  1.0749, -1.8747, -1.6129,  1.7613, -2.0194,\n",
      "        -1.8504,  1.2390,  3.7726,  1.6796, -2.6640, -3.8073, -1.4919, -1.1211,\n",
      "        -1.7125, -2.4177, -1.1375, -1.3320, -2.1155, -1.1048,  1.0761,  1.0098,\n",
      "         2.1047,  1.0554, -1.7923, -2.8073, -1.1993, -1.2730, -2.1050, -3.0000],\n",
      "       device='cuda:0')\n",
      "tensor([-0.2758, -1.6515,  1.4083,  0.7693, -0.7122, -1.4324, -0.5581, -0.2837,\n",
      "         0.0378,  1.6625,  1.2226,  1.3451, -1.7911, -2.2717,  0.0050,  0.1979,\n",
      "         0.9506, -1.6532, -1.4463, -0.3101, -1.5167,  1.4635, -0.9669, -1.0505,\n",
      "         1.1220,  0.9757, -1.4274, -2.3591, -1.8270, -1.1099, -1.9042,  0.4343],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.4135, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0767, -2.2816,  1.0772, -1.9386, -2.7643, -2.8755,  1.8991, -1.8458,\n",
      "         1.1069,  1.1699, -1.7103, -2.8342,  2.4060,  2.9380,  1.3069, -1.5850,\n",
      "        -1.1048, -2.1155,  1.4105, -2.3318, -1.2685, -1.1258,  1.6204, -2.0833,\n",
      "        -3.3219,  1.4387, -1.8682, -1.4594, -1.0518, -2.1122, -3.3557,  2.6781],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3654, -1.1926, -0.6472,  0.2274, -0.2466, -2.1660,  1.1705, -1.7583,\n",
      "        -1.1936, -0.1774, -1.6826,  0.6837,  1.7661,  1.0929,  0.9986,  1.3521,\n",
      "         1.0920, -1.7549,  1.8281, -1.6031, -0.4477, -1.6953, -0.4060, -1.8709,\n",
      "        -1.6170,  0.3215, -1.9618, -1.6856,  0.0922, -1.1148, -1.9387,  2.2150],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(4.2269, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.7901, -2.4150,  1.2174, -1.4132, -2.0251, -1.0864, -1.5323,  2.0358,\n",
      "        -1.8182, -1.9378, -2.0360, -1.9631,  1.6446, -1.1100, -1.1726, -2.8745,\n",
      "        -2.2783,  1.6190, -1.3490, -1.1255, -1.0802,  4.2970, -1.0617,  3.0000,\n",
      "        -1.4047,  1.1375,  1.9594,  1.3450, -1.1063, -3.2854, -3.2627, -3.3709],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.7233, -1.2247, -1.0061,  1.5180,  1.3659,  1.6036, -1.9828,  1.5661,\n",
      "        -1.4990, -2.3802, -1.1255,  1.1601,  0.0647, -1.7259, -1.1691,  0.8426,\n",
      "        -1.7261, -0.7705, -1.7025,  0.2433, -1.2211,  1.8038,  1.1115,  2.3714,\n",
      "        -0.6775,  0.4249,  0.9841, -0.7708, -1.8470, -0.6606, -1.8034, -0.7384],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.4215, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3986, -1.5850, -1.0155, -2.2441, -1.8924,  1.7309, -1.7045,  1.1226,\n",
      "         1.2110,  1.2357, -1.9778,  2.1196,  2.1066, -1.3765, -1.6492, -1.1791,\n",
      "        -1.6656, -2.0279, -2.5850, -2.3166, -1.0387,  1.3720, -1.4523,  1.1947,\n",
      "        -1.0181,  2.0810,  2.9542, -2.3219, -2.3150, -2.2569, -2.0918,  2.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5610, -1.2296, -1.5920, -1.7392, -1.1212,  1.3146,  1.4065,  2.5904,\n",
      "         3.0332,  1.3983, -1.3745,  1.3963,  1.6033,  0.1371, -1.2166, -1.3530,\n",
      "        -1.6140, -0.8770, -1.5513, -1.9105, -1.6002,  0.7076, -1.1067,  1.7355,\n",
      "         0.4410,  1.3367,  0.9194, -0.4586, -1.8253, -1.4797, -1.4774, -0.0411],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.0623, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.7855, -1.6724,  2.0000, -1.0875,  1.3498, -1.0870, -1.4807, -2.8073,\n",
      "        -1.3840,  2.0224, -1.5208,  1.2496, -1.5242,  2.1047, -1.3692, -2.0277,\n",
      "         1.5663, -3.0677,  1.1520, -2.5850, -1.3033, -1.8313, -2.3019, -1.9260,\n",
      "        -1.2814, -2.6363, -1.1945, -1.3455, -2.2076, -2.7274, -2.5095,  2.3317],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8116, -1.6837, -1.0840, -0.9958,  1.4401, -1.8405, -1.9122, -1.5915,\n",
      "        -0.7100,  2.0349, -1.6034, -1.9454, -0.4385, -0.3307, -0.2620, -1.1521,\n",
      "        -0.6993, -1.6596,  1.2832, -0.5890, -1.3357, -1.1762, -1.3325, -1.1730,\n",
      "        -1.0915, -2.2057,  1.0469, -0.7264, -1.2384, -1.8586, -2.0737,  1.1041],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 88 Predict 1055 zeros 628 ones, one bias 0.373143\n",
      "train loss: 1.7886645470783387 dev loss: 1.6652333386096125\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.0654, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.8975, -1.5360, -3.6075,  3.3626, -2.4420, -1.2224, -2.2441, -4.0395,\n",
      "        -1.1597,  3.5744,  2.5670,  1.6323,  1.5915, -1.2713, -1.3487, -2.0666,\n",
      "        -2.4594, -2.7949,  1.5305, -2.6258, -1.2397, -1.4533,  2.0000, -1.9260,\n",
      "         1.3292,  2.8826, -1.2021, -3.7472,  1.7148,  2.7855,  1.6293, -2.5964],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.1357, -1.7353, -1.2808,  1.7527, -1.2703, -1.5898, -1.6419, -0.7509,\n",
      "        -1.2643,  1.7910,  2.7440,  1.0763, -1.0989, -1.6902, -1.7988, -1.6888,\n",
      "        -1.6932, -1.7680,  1.3816, -1.2803, -1.7960, -1.1513,  1.5397,  1.5671,\n",
      "         0.9169,  1.1057, -1.8807, -1.6408,  0.1854,  0.0280,  1.4292, -0.4841],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.6503, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3655, -1.8074,  1.7382, -1.0952,  1.5676, -1.2825, -1.1726, -2.3003,\n",
      "         3.0760, -1.4044,  1.0881,  1.4957,  2.6168, -1.9279, -2.1234, -2.2605,\n",
      "        -1.5368, -1.8074, -1.3202,  2.3317, -4.2479,  1.1699, -1.4336,  2.2926,\n",
      "        -3.5443, -1.2752,  1.3196, -2.3219, -1.6374, -2.0129,  2.6625,  1.0761],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3563, -2.0725,  1.6257, -2.3416,  0.0900, -1.2573, -0.9896, -1.8623,\n",
      "         1.5179,  0.7523,  0.6035,  1.7132,  1.0491,  0.4355, -0.3767, -0.3877,\n",
      "        -1.8597, -0.6925, -1.7772,  2.2241, -1.9395, -0.8206, -0.6180,  0.9803,\n",
      "         0.6137, -2.6236,  1.6669,  0.2887, -2.2753, -2.0900,  1.2020,  1.1611],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.8329, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9778,  1.7287, -2.7023, -2.0369, -2.3669, -1.2479, -1.0919,  2.0451,\n",
      "        -1.5850,  1.0780, -1.2070, -1.6265, -1.6854,  1.6722, -2.9500, -1.0795,\n",
      "         1.8745,  1.3334,  1.8122, -1.5850, -1.3263,  2.0875, -1.3310, -1.5850,\n",
      "        -1.0393,  2.0000, -1.9347,  1.4011,  2.3815,  2.1047,  2.2979, -1.1901],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3673,  0.1362, -1.8095, -1.6676, -1.7789, -1.3996, -1.2019, -0.8914,\n",
      "        -1.2606, -0.9729, -1.4914, -1.6641, -1.8682,  0.3344, -0.6264, -1.9643,\n",
      "        -0.8749, -1.0661,  0.6308,  1.3920, -2.0004, -1.4695,  1.3517, -1.1558,\n",
      "        -1.3012,  0.5449, -1.5272,  1.8839,  1.0374, -0.1670,  2.1104, -1.7654],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.4775, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3450,  1.4854,  1.2538, -1.0243,  3.4594, -2.0395, -1.2530, -1.2936,\n",
      "         2.8647, -1.8924,  1.9016, -1.5434,  1.7004,  1.1926, -1.3046, -1.9586,\n",
      "        -2.1659, -1.8689, -1.9069,  1.5500, -2.9696,  1.8460,  2.4841, -2.8073,\n",
      "        -1.9260, -3.5850, -1.7843,  1.4241, -1.7447,  1.3785, -1.0827,  1.3931],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7639,  0.3961, -0.8736,  0.9150,  1.2305, -0.3419, -1.2523, -1.3658,\n",
      "         0.3538, -1.6561,  2.9748, -1.3462,  1.3498,  1.7019, -1.2308, -2.0109,\n",
      "        -1.5859,  0.5003, -1.4549,  0.9884, -0.2835,  1.5927,  0.5937,  0.0593,\n",
      "        -1.7476, -1.8489,  0.5503,  1.3676, -1.6835, -0.7607, -1.8241,  0.5480],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.0629, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0952,  1.8403, -1.0371, -2.7685, -1.8251, -1.7004,  1.1547,  1.1962,\n",
      "        -1.3785, -2.4594,  2.2481,  1.5596,  1.0688, -2.2492,  1.2224,  1.7565,\n",
      "         1.1555,  3.0255, -2.0369, -1.5884,  1.2357, -1.1656,  1.1537, -1.6268,\n",
      "        -1.5850,  1.4854,  1.4651, -1.1165, -1.3684, -2.0976, -1.0766, -1.1211],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6787,  0.4774, -1.5574, -1.5905, -0.4658, -0.2036,  1.2662, -1.3569,\n",
      "        -0.8003, -1.3777,  1.4788,  1.5866, -0.6455, -2.1834, -1.3780,  0.7033,\n",
      "        -0.9395,  0.0649, -0.8504, -1.7078, -1.2853, -0.1382, -1.1956, -1.7939,\n",
      "        -1.7392, -1.0393,  0.9280, -1.3383, -1.2595, -1.5036, -1.1208, -0.7854],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.3709, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0875, -2.3388, -1.8458, -1.7168, -1.1444, -2.5850,  1.8016,  1.9267,\n",
      "        -1.0342,  1.3414,  1.1435,  2.3835,  1.9349,  1.8122,  3.4594,  1.5003,\n",
      "        -2.0725, -2.8832,  1.3785, -1.9069, -2.0395,  1.8105,  1.0904,  1.5850,\n",
      "         1.2496, -1.2016, -1.2752,  1.2857,  1.3219,  4.0875, -1.2102, -1.2730],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1578, -1.6798, -0.1897, -1.6662, -0.3264, -0.4605,  2.3327,  1.8107,\n",
      "        -0.9437, -0.9266,  0.5377,  1.7304,  1.6358,  1.8223,  1.1008,  0.0041,\n",
      "        -1.7632, -1.3189,  0.7878, -0.1376, -0.3415,  1.7197,  1.1875,  1.3113,\n",
      "        -1.6614, -1.1101, -1.3266, -0.2993, -1.6833,  1.4265,  0.8741, -1.7029],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 89 Predict 1081 zeros 602 ones, one bias 0.357695\n",
      "train loss: 1.7943400181821902 dev loss: 1.505089860597868\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(4.1557, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3626, -1.8074,  1.3119, -1.2801, -1.7472,  2.0315, -1.5415, -2.3029,\n",
      "         1.2316, -1.0869, -2.9696, -1.9011, -1.2065, -3.1043, -2.9798, -1.6439,\n",
      "        -3.0875, -1.9260, -1.3765, -2.4595, -1.4917,  2.5731, -3.0704, -2.8073,\n",
      "        -3.0875, -1.9560, -1.7004,  2.3692,  1.3332, -1.5633, -1.4047,  1.0841],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0630, -1.8025,  2.2181, -0.1473, -1.5716,  1.0481, -0.0605, -1.3674,\n",
      "         1.2826,  1.1385, -1.1971, -1.5544, -0.9612, -1.8622,  1.1163,  1.3584,\n",
      "        -1.6432, -1.1992,  0.7343,  0.2124,  0.0238,  1.4096, -1.4089,  1.2240,\n",
      "        -1.1173, -0.4589, -0.6697, -1.0618,  0.7613, -1.7150, -1.2952, -1.5685],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.8898, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0076, -2.3795, -1.1699, -2.0279, -2.5099, -1.8313, -1.2486, -1.8689,\n",
      "         1.5850, -2.3219, -1.9260, -1.5817,  2.5731, -2.2292,  1.6701, -1.8190,\n",
      "        -1.0389,  1.0734, -2.1771,  2.1255, -1.4354,  3.1699, -2.9696, -1.5984,\n",
      "        -1.4894, -1.3450,  1.1782,  1.3419,  1.2167, -2.3738,  1.2165, -2.0875],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0348, -1.7376, -1.3552, -1.1921, -1.7631,  0.0400, -2.3708, -1.7203,\n",
      "        -0.1502, -1.3122, -0.2526, -2.2499,  1.5051, -2.1392,  1.2643,  0.0256,\n",
      "         1.1198,  1.2674,  0.1343,  0.5698, -1.9486,  1.7916, -1.8126, -2.1623,\n",
      "        -0.9177, -1.9722, -0.8836,  1.6824, -1.1793, -1.9943, -2.1275, -1.0270],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(4.3675, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0429, -2.0937,  1.6439, -1.1060, -3.5850, -6.4702, -1.1631, -2.0324,\n",
      "        -4.2813, -1.8330, -1.8745,  1.1183,  1.8723, -1.1212, -3.4215,  1.3219,\n",
      "        -1.5850, -1.6781,  2.5850,  2.2993, -2.5620,  1.2496,  1.1699,  1.2675,\n",
      "        -1.5443, -2.4417, -1.3785,  1.3931,  1.8192, -1.2756, -2.1325,  1.9403],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6156, -1.2555,  1.4034, -1.5882,  0.5072, -1.7282, -1.6644, -0.6611,\n",
      "        -1.7286,  1.2791, -1.8729,  1.4237,  1.3239, -1.5671, -1.6474,  0.3506,\n",
      "        -0.3297, -1.9185, -0.3849,  2.3336, -1.5936, -0.0935, -1.1404, -0.9687,\n",
      "        -0.7508,  1.5220, -1.6286, -0.0267,  0.8151, -0.2982, -1.6569,  1.7445],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.0630, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3055, -1.3684,  1.4970, -1.2756, -2.0194, -1.3036, -1.8716, -1.7140,\n",
      "        -1.9260,  2.7549,  2.6051, -1.9260, -1.9005, -1.1211,  2.1123,  1.1699,\n",
      "        -1.8198, -1.0562, -2.1722, -1.1955,  1.1024,  1.1375, -2.5850, -2.6515,\n",
      "        -2.3324,  3.5349, -3.6114, -2.2441,  1.7370,  1.2633, -2.0995, -1.4132],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1521, -1.8219,  0.4096, -1.3743,  0.3640, -1.6127, -0.4904, -1.1246,\n",
      "        -1.4575, -1.2503, -0.4881, -0.4568, -1.7391, -1.0627,  1.4147,  1.3487,\n",
      "        -2.0750, -1.7997, -3.1281, -1.6715, -1.4505, -0.3167, -1.1422, -1.9844,\n",
      "        -1.4468,  0.3560, -0.9392, -2.0137, -0.8260,  1.9250, -2.1280, -0.6652],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.6989, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1926,  2.4195, -2.7397,  1.4360,  1.8244, -2.6300,  1.3399, -2.0096,\n",
      "        -1.1923, -1.3831,  1.5850,  1.9353,  1.8122, -1.0870,  1.2243, -1.2557,\n",
      "        -1.4499,  1.7914,  1.6379, -1.0875, -2.5850, -1.3785,  3.5084,  1.7004,\n",
      "         2.3696,  1.5324, -2.1445, -2.2538, -1.0028, -2.5158,  1.8260, -2.6546],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6614,  1.5002, -1.6684,  1.0379,  1.6543, -1.9140,  1.1472, -1.8038,\n",
      "        -2.4777,  1.4316,  0.5444,  0.5568,  0.4916, -0.9526, -0.8101, -2.0391,\n",
      "        -1.8115, -1.1339,  0.7284, -1.7730, -1.1172, -1.1948,  1.2848,  1.4197,\n",
      "         1.6150,  0.0985, -1.5165, -1.9419, -1.7253, -1.7642, -0.1954, -1.8357],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4609, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0345, -1.1100, -1.3587, -1.3085, -1.1864, -3.2730, -1.3905, -1.7406,\n",
      "         3.4175, -1.6938,  1.1817,  1.4105,  2.0810,  1.1699,  1.5297,  2.0940,\n",
      "         1.1155, -2.1927, -2.8073,  1.2538, -2.1180, -2.2066,  1.1203, -1.1833,\n",
      "         1.2357, -1.3105, -1.0084,  1.7800,  3.5850, -2.0000, -1.9260,  1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.0909, -0.0348,  0.7929, -1.4661, -1.7391, -1.6780, -1.8907,  0.6054,\n",
      "         2.8977,  0.7395, -1.0764,  2.1487,  1.3491, -1.2240,  3.3468,  1.4061,\n",
      "        -0.9909, -1.3152, -1.1620, -1.2238, -0.0912, -1.7093,  1.4896, -1.1107,\n",
      "         1.5170, -0.8956,  1.3478,  1.0191,  1.0638, -0.0195, -1.9173, -0.4966],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 90 Predict 1006 zeros 677 ones, one bias 0.402258\n",
      "train loss: 1.8436199067302161 dev loss: 1.5405834416843893\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.9888, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1107, -1.4313, -1.1778,  1.7077,  1.5606,  1.0780, -2.0275, -3.3709,\n",
      "        -1.2955,  1.2346, -1.2224, -2.4432, -2.0000, -1.8611, -1.8383, -1.9260,\n",
      "         3.3173, -1.8160, -2.3394,  2.6625, -1.5502, -2.1949,  1.0888, -1.2685,\n",
      "        -1.1444,  1.7726, -2.4594,  1.7914, -1.0863, -5.5363, -1.7472,  1.8826],\n",
      "       device='cuda:0')\n",
      "tensor([-1.2829, -1.5581, -0.6970,  0.1779, -1.6546, -1.0069, -1.8605, -0.9299,\n",
      "         1.8788, -1.3647, -1.2361, -1.9255, -1.3003, -2.0723, -1.7113, -1.5269,\n",
      "         2.1682, -1.6166, -1.5650,  1.0393,  0.8924, -1.6459,  0.3366, -1.0577,\n",
      "        -0.8676,  0.4207, -1.7248, -0.9489,  0.0327, -1.6904, -1.5908,  1.8416],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(4.0269, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.0658,  1.8025, -1.9395,  2.3824, -1.2756,  1.2633,  2.5025, -1.0446,\n",
      "        -1.2814, -2.2441, -1.3785, -1.5502,  2.5850,  1.2708, -2.7808, -1.9358,\n",
      "         1.3905, -1.5971,  1.4150, -1.9260,  4.2587, -2.9798,  1.3949, -2.1727,\n",
      "        -1.5360,  1.5400, -1.8501, -1.1726, -1.2977, -1.2142,  1.0841,  4.7944],\n",
      "       device='cuda:0')\n",
      "tensor([-0.9434, -0.9239, -1.8477,  1.4470, -1.9294,  1.8008,  0.3460, -0.3962,\n",
      "         0.2824, -1.9529,  0.5124,  0.7716, -0.8743, -0.4113, -1.7527, -1.9771,\n",
      "        -0.7515, -1.5132,  1.9203, -1.4863,  1.2531,  1.2271, -0.0641, -1.1107,\n",
      "        -0.5882,  0.4913, -0.2637, -0.6264, -1.6214,  0.8013, -1.5807,  1.2541],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.0270, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-4.0395, -1.8921, -1.9778,  1.0497,  1.1375, -2.4041, -1.1155, -1.4636,\n",
      "         1.9649,  1.0704,  4.1761, -1.9069, -1.9307,  1.3931,  1.2320,  1.3219,\n",
      "        -1.7045, -1.1824, -1.1960, -1.4850, -1.8864, -1.1155,  3.5084, -2.7482,\n",
      "         3.1983, -1.1699,  2.8126, -2.3003, -1.2890, -1.1211,  1.5676,  2.4328],\n",
      "       device='cuda:0')\n",
      "tensor([-2.9472e-01, -1.8142e+00, -1.0521e+00, -1.3247e+00,  2.0832e+00,\n",
      "        -1.5157e+00, -1.1673e+00, -1.7845e+00, -1.0472e+00, -1.6761e+00,\n",
      "         1.5139e+00, -1.0149e+00, -1.8021e+00, -4.6250e-04,  1.4272e+00,\n",
      "        -4.3667e-01,  1.4118e+00,  1.1808e+00, -6.4688e-01, -1.1421e+00,\n",
      "        -1.9713e+00, -8.7060e-01,  1.4358e+00, -1.7956e+00,  2.3378e+00,\n",
      "        -1.0273e+00,  1.7613e+00, -1.6937e+00, -1.8367e+00, -8.4014e-01,\n",
      "        -8.3465e-01,  1.2795e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.5424, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.7046, -2.6502,  1.9594,  1.2954, -2.7482,  1.4651, -1.1444,  2.0429,\n",
      "         1.6630,  1.6379, -1.5168, -2.5668, -2.7380,  1.3196, -1.2486,  1.1225,\n",
      "        -1.6818, -1.9704,  1.8960, -1.1058, -1.1368,  1.2954, -1.3727,  2.6845,\n",
      "         2.1304, -1.8682,  2.9069, -1.5417, -1.2630,  2.0000, -1.3219, -1.6524],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1363, -1.5071,  1.0811,  1.8086, -2.0306,  1.3713, -0.8774, -2.0305,\n",
      "        -0.3794,  1.4706, -1.8488, -1.7354, -3.1736,  0.2382, -1.6006,  0.1369,\n",
      "        -1.9222, -1.7238,  1.0765, -1.2780, -1.9474,  1.4523, -0.6809,  2.7788,\n",
      "        -1.3857, -1.9398, -0.4184,  0.0514, -1.9364, -0.3650, -1.1240, -0.2468],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.4586, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1864, -1.1615,  2.2091, -1.1155, -1.5829,  1.3215,  1.0841, -1.8745,\n",
      "        -1.1656, -1.1806, -3.1193, -1.3870,  1.8960, -1.1976, -1.8580, -1.5850,\n",
      "        -1.7046, -1.9421, -1.2397, -1.9022,  3.4175, -1.9260,  1.4970, -2.5850,\n",
      "        -1.9778, -1.1677, -2.6739,  1.2538,  1.6172, -1.2730,  1.6594, -1.1926],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5900, -1.4472,  1.6988, -0.9951, -1.2932,  2.1534,  0.5017, -1.8014,\n",
      "         0.4294, -1.8317, -1.1120,  0.1024,  1.3999, -1.7384, -1.2794, -0.8669,\n",
      "         1.5950, -1.5685,  1.3862, -1.5852,  1.9280, -1.3218,  1.3067, -1.8821,\n",
      "         0.3264, -1.7405, -1.3884, -0.3192,  2.5051, -2.0602,  1.0024, -1.9372],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.7454, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.1481, -3.7603,  1.5585,  1.4053,  2.9069,  1.3399,  1.7746, -2.4432,\n",
      "        -2.2492, -2.4417, -1.4520,  1.5850,  2.7370, -2.0939, -1.2397, -1.5078,\n",
      "         2.4270,  1.8429,  2.0715, -2.4595,  2.0000, -2.6262,  2.1196,  2.0298,\n",
      "        -1.2450, -1.3624,  1.4532,  2.8073, -3.1827,  1.7453, -1.1375,  2.1844],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9931, -1.8794,  2.0291,  1.5800, -1.2039,  0.9802,  0.6997, -1.7705,\n",
      "        -1.8947, -1.5311, -1.9151, -1.7423, -0.1514,  1.5219, -0.4885, -1.2485,\n",
      "         1.1147, -0.8184,  1.2990, -1.7047,  1.2782,  0.3788,  0.4989,  1.4245,\n",
      "        -1.7177, -1.8183,  2.1084,  2.6403, -1.1556,  1.5766, -1.5626, -0.6519],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 91 Predict 1012 zeros 671 ones, one bias 0.398693\n",
      "train loss: 1.8312317222594392 dev loss: 1.6845045724417183\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(1.9354, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6529, -2.7553, -3.0119, -1.9704, -2.5920, -1.1960,  1.0229, -1.2988,\n",
      "         1.5311, -1.5083,  1.6439, -1.1155, -3.6897, -1.2955, -2.2783, -2.4150,\n",
      "        -2.8024,  1.6614, -1.4374, -2.8024, -1.0952, -1.7845, -1.5834,  2.0000,\n",
      "        -1.2801, -1.4205, -2.0395,  1.4477, -2.8712,  2.0358, -1.1628, -1.0064],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.0187, -1.6718, -1.7562, -0.2365, -0.6136,  0.2119,  1.1263, -1.8579,\n",
      "         2.0400, -1.7108,  0.7046, -1.6669, -1.7032,  0.3209, -1.1843, -1.4780,\n",
      "        -2.2298,  1.0612,  2.0970, -2.0742, -1.7206, -0.9393, -2.0570, -0.0934,\n",
      "         0.6800, -1.7334, -0.4275, -0.8522, -1.4622,  1.3000, -1.8493,  0.1831],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.2013, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2390,  1.3137, -1.3476, -1.5850, -3.3966, -2.6589,  2.3153, -1.6268,\n",
      "        -2.5095, -1.1579, -2.5620, -1.2854,  1.3196, -1.1205,  1.2167,  1.0452,\n",
      "        -1.7408,  1.2988, -2.0451,  3.5744, -3.2854, -2.1180, -1.2224, -1.1677,\n",
      "        -1.3900,  2.1669, -2.7004,  1.6206,  1.0193,  3.2720, -1.9260, -1.6483],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6243,  1.1457,  1.4049, -1.4220,  0.3524, -1.7916,  1.2720, -1.7348,\n",
      "        -1.2067,  2.0348, -1.7141, -1.6008,  1.1477,  0.9704,  1.2871,  1.0843,\n",
      "        -1.5964,  0.3592, -2.1106,  1.2410, -2.0130, -0.5242,  0.7590,  0.2716,\n",
      "        -1.7088,  2.0013, -1.6529,  1.3183,  0.7785,  1.2212, -1.4280, -1.6811],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.7849, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.1945,  1.1957,  1.0680,  1.7650, -1.9349, -1.6590, -3.0511, -1.7744,\n",
      "        -2.2441, -1.2778,  1.1016, -1.2665,  3.4150,  2.3262, -1.2685,  1.5332,\n",
      "         1.0408,  1.8122, -1.8667, -1.1679, -2.3019,  2.5571,  2.3219, -2.6955,\n",
      "        -2.3219, -1.7105, -1.3149,  3.7726,  1.4387,  1.2224, -1.2419, -1.2479],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8548,  0.6010, -0.5767,  1.1741, -2.0559, -1.7417, -0.2018, -1.3586,\n",
      "        -1.8843, -1.6639, -1.6145, -1.8452,  2.1669,  1.2506, -1.1973,  0.4630,\n",
      "         1.1701,  0.3494, -1.9473, -1.5239, -0.7949,  0.9723,  0.6319, -1.0557,\n",
      "         0.6389, -1.7525,  0.3571,  0.1810,  1.2373, -0.9296, -2.2682, -1.2240],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(0.9330, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0194, -1.4132, -1.1979, -2.4908, -2.3219, -1.8250,  1.5850, -1.3033,\n",
      "        -1.7936, -1.5502,  1.0014,  1.5330, -1.5850,  2.4841,  1.0085, -1.7923,\n",
      "         1.0712, -1.5850, -3.6897, -2.1993,  1.4517,  1.4950,  1.7004, -1.1726,\n",
      "        -1.4205, -1.2419,  1.0193,  3.0809,  1.3196, -1.9260,  1.2685, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([-0.6670, -1.8099, -1.2337, -1.8246, -1.3569, -1.7113,  1.1047, -1.2346,\n",
      "        -1.7411, -1.6676,  1.2984,  1.2614,  0.7242,  0.9924,  1.2939, -1.8715,\n",
      "        -0.1490, -1.2053, -1.9693, -1.3317,  1.5424,  2.3378,  1.4794, -0.7144,\n",
      "        -1.2158, -2.0526, -0.1184,  1.7510,  1.4237, -1.7620,  1.2029,  0.2824],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.8952, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-3.0677,  1.5360,  1.7914,  2.0989,  1.6057, -1.5320, -1.1205, -2.9696,\n",
      "        -2.3152, -3.4811, -1.6826, -1.1901, -2.1888, -2.8480, -1.4721,  2.7612,\n",
      "        -2.1722, -2.1325, -1.4739, -1.3167, -1.5850, -2.6400, -2.2066,  1.4150,\n",
      "         1.3219, -2.4432, -2.3219,  2.0987, -1.4507, -1.1833, -3.4227, -1.5025],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8350, -0.3627, -1.9879,  0.8363,  1.4511, -1.8678,  0.2186, -1.8793,\n",
      "        -2.2581,  0.9749, -2.0230, -1.9334, -2.4476, -0.6336, -1.2977,  1.6546,\n",
      "        -1.3438, -1.6908, -0.7986, -1.1111,  0.1795, -1.7194, -1.5865, -0.7061,\n",
      "         0.1632, -1.5995, -1.7179,  1.7110, -1.0528, -1.0336, -1.7297,  1.5224],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.5763, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0841,  1.5315,  2.3219, -2.3219,  1.2062,  1.1988,  1.4105,  2.3219,\n",
      "         1.5337, -1.6980, -1.4088,  1.6273, -1.7370, -1.7004,  2.5025, -1.9492,\n",
      "         2.0987, -1.2682, -1.5659, -2.7482, -1.8881,  1.0511, -2.0082, -1.1597,\n",
      "        -1.5850,  2.0429, -3.3966, -3.2525,  1.0452,  1.1454, -1.3167,  1.2768],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7776,  0.7252,  0.7358, -1.7129,  1.6824, -1.7032,  1.6631, -0.7236,\n",
      "         0.9373, -1.7034, -1.7889, -0.7128, -1.5994, -0.3261,  0.6566, -1.6442,\n",
      "         1.8822, -1.7161, -1.2807, -1.6148, -1.8862,  1.9561, -1.6867, -1.6337,\n",
      "         0.4639, -1.6351, -1.6370, -1.8687,  2.1328,  0.7062, -1.1446, -0.6337],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 92 Predict 1031 zeros 652 ones, one bias 0.387403\n",
      "train loss: 1.796882424984377 dev loss: 1.6145231882636566\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.6260, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.2378,  2.6625, -1.8977,  1.1699, -2.8342, -2.8970, -1.8250, -1.3278,\n",
      "         1.1289,  3.4594,  2.2869,  1.3333, -1.9069,  1.5606, -3.1699,  2.6800,\n",
      "         2.3219, -2.0275,  1.3162, -2.4595, -2.9696,  2.8073, -1.1508, -1.4845,\n",
      "        -2.0194,  1.6562, -1.1489, -1.3167, -2.6924,  2.0682, -1.3450,  1.0841],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7948, -0.0979, -1.6283,  1.6888,  0.1841, -1.7449, -1.8363, -1.5020,\n",
      "        -0.0162,  2.2234,  1.7478,  0.2488, -0.7598, -1.2700,  0.1333,  2.1681,\n",
      "         1.7088, -1.6221,  0.9836, -1.5318, -1.1947,  2.7624, -1.7309, -1.7884,\n",
      "         0.3806, -0.6095,  1.0447, -1.0424, -1.6797,  1.4094,  0.3636,  1.1194],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.8803, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.2768,  1.6848, -1.8561, -1.1630,  1.0592, -2.0129,  1.2022, -1.7843,\n",
      "         1.3943, -1.1375, -1.6980,  1.4330,  3.1831,  1.0014, -1.0869, -1.2021,\n",
      "        -3.5034, -1.1806, -3.5443,  2.2654, -1.6338, -1.0536, -2.1520,  1.5850,\n",
      "        -1.1165, -2.5931,  1.7148, -2.1927, -2.1214, -1.8649, -2.8073, -2.1993],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.1163,  1.4158, -1.7372, -0.7670,  1.4003, -1.6138, -0.6898, -1.7169,\n",
      "         0.9470,  0.3861, -1.9378, -1.6317,  2.3011, -0.1729, -1.7006, -2.1022,\n",
      "        -1.5179, -1.0906, -0.6973,  1.2738, -0.7265, -1.8676, -0.7768,  1.0636,\n",
      "        -1.8539, -1.9322, -1.1437, -1.7904, -0.8883, -2.1274, -1.2133, -0.9874],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.5007, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6567, -1.9746, -2.0630, -1.1726, -1.4191,  2.3421, -1.5850, -2.5794,\n",
      "         3.0704,  1.3711, -1.6710, -1.6912, -2.1741, -1.5753,  1.1690,  2.1066,\n",
      "         1.3773, -1.3726, -3.0000, -1.1197, -2.0630, -1.5265,  1.0056, -1.6492,\n",
      "         1.8192,  1.7382,  1.2111,  1.3479, -1.7370, -2.9696, -2.1758,  1.5193],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.7636, -1.6607, -1.1905, -1.1254, -1.5846,  0.8946, -0.6099, -0.3253,\n",
      "         1.4068,  1.7038, -0.5602, -1.9306, -1.8114, -1.6956,  0.9232, -0.8871,\n",
      "        -0.0662, -1.7049,  0.8198,  1.2132, -1.1002, -1.5530,  1.2043, -1.1329,\n",
      "         0.8415, -0.8495, -1.1541, -0.7125, -1.0641, -1.2558, -2.0596,  1.3432],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.2424, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1437, -3.3709,  1.1024,  1.8517,  1.8429, -2.1375, -1.7454, -2.1180,\n",
      "        -1.1205, -1.2811, -1.4114,  2.3219, -4.1699, -1.4432, -2.1641,  1.4105,\n",
      "         1.0490,  2.8821,  1.1444, -2.6259,  1.2167,  2.3917,  1.5850,  2.1155,\n",
      "        -2.4041, -1.9347,  3.1075,  1.2224, -1.5492, -1.8784,  2.3317,  1.2167],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7316,  0.1439, -0.5477,  2.2607,  0.8526, -1.0704, -0.3183,  1.0993,\n",
      "         1.3993, -0.3908, -1.1230,  1.8800, -1.0701, -1.6905, -1.3071,  2.1987,\n",
      "         0.9791,  1.0401, -0.3328, -1.5689,  1.3802,  0.2958,  1.3199,  0.9707,\n",
      "        -1.0565, -1.3134,  1.9243, -1.4967, -1.7952,  1.2752,  1.5699, -1.1389],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(4.7904, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2267,  1.6439,  1.3001, -1.1444,  1.9016, -2.1116, -1.9542,  1.3392,\n",
      "        -2.1722, -1.8171, -2.3219,  1.6917, -1.3000, -1.5850,  1.1537,  1.3773,\n",
      "         2.2022, -2.8580, -3.7549,  1.5146, -1.3823,  2.0841, -1.1935,  1.0841,\n",
      "         1.1040,  1.7148, -1.5247, -3.2439, -2.9500, -1.6108, -1.1679, -1.3530],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6856, -0.6052,  1.5321, -1.1729,  1.2721, -1.7506, -0.2693,  1.6257,\n",
      "        -1.6792, -2.0361, -1.8539, -1.4416, -1.8558, -1.2494, -0.7798, -1.6642,\n",
      "         1.9332,  0.7316,  1.2230, -1.6442, -1.7097, -0.2210, -2.0205, -1.0965,\n",
      "         2.2816, -1.5091, -1.6669, -1.9395,  1.2684, -1.7681, -1.6099, -1.8992],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(3.1691, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.4055,  1.4970, -3.9362, -1.2058, -2.9681,  1.0251, -2.8073,  1.4518,\n",
      "        -1.3831, -1.0827, -1.8658, -1.5271, -1.0711, -1.2557, -1.7370, -2.4041,\n",
      "        -2.1180, -1.0738, -1.9814,  1.0680,  2.7855, -1.0661,  1.3510,  1.0776,\n",
      "         1.7800,  3.0809, -1.3745, -1.0041, -1.1338, -3.1699, -2.2865,  1.2518],\n",
      "       device='cuda:0')\n",
      "tensor([-1.0061,  1.2885, -1.3246, -0.6031, -1.9930,  1.0805,  0.0968,  1.1015,\n",
      "         1.3897, -1.6139,  0.8569,  1.0925, -0.7189, -0.8366, -1.7937, -1.0093,\n",
      "        -1.6756, -0.2811, -1.5552, -1.0509,  1.1205, -1.6816,  0.1260,  1.2031,\n",
      "         0.8991,  0.9080, -1.3445,  1.3601, -1.2881,  1.5018, -1.6861,  1.9019],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 93 Predict 1025 zeros 658 ones, one bias 0.390969\n",
      "train loss: 1.7969806129576393 dev loss: 1.8328437489600922\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.7681, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.4525,  1.5722, -1.3303,  1.2837,  1.7599,  2.0000,  1.7600, -1.8846,\n",
      "         1.7041,  1.8931, -1.8689,  1.8192,  1.5408, -1.6614,  1.0912, -1.5564,\n",
      "         1.5036, -1.4523, -2.2479,  1.1183, -2.4639,  3.1414, -2.1641,  1.5004,\n",
      "        -1.9370,  1.9492, -1.0536, -1.2476, -2.5651, -1.1890, -2.2033, -1.1176],\n",
      "       device='cuda:0')\n",
      "tensor([-1.9413e-01,  1.9001e+00,  1.1445e+00,  1.6057e+00,  3.3008e-04,\n",
      "        -2.5299e-01,  1.2454e+00,  1.2203e+00, -7.1702e-01,  1.1794e+00,\n",
      "        -1.6613e+00,  7.9418e-01,  2.4488e+00,  8.2551e-01,  1.9501e+00,\n",
      "         9.0040e-02,  2.1552e+00, -1.7962e+00, -1.5660e+00,  1.5283e+00,\n",
      "        -2.0167e+00, -9.2768e-01, -1.8222e+00,  9.3475e-02,  7.2407e-01,\n",
      "         9.4439e-01, -1.8300e+00, -2.2080e+00, -1.2737e+00, -1.3047e+00,\n",
      "        -1.8111e+00, -1.6883e+00], device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.2953, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3785,  1.5408, -3.1699, -2.0324,  1.4593,  1.4411, -1.5110,  2.4060,\n",
      "        -2.0939, -2.6739, -1.9400, -1.9260,  2.2331,  2.8647, -2.0049,  3.2095,\n",
      "         1.4651, -1.0454,  1.2621, -2.2378, -2.1178,  1.5850, -1.5432,  1.0841,\n",
      "         1.0349, -1.4498,  2.1375,  1.0888,  1.2685, -1.4132, -1.9260,  1.2559],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.2939,  1.2890, -0.9998, -1.0937, -0.9200,  1.7398,  1.1134,  1.2513,\n",
      "        -2.0226, -0.1439, -1.6728, -1.3793,  0.4442,  0.6710, -1.5126,  1.6395,\n",
      "         1.4495, -1.8915,  1.1465, -1.5832, -1.5837,  1.1673, -1.3308, -1.7590,\n",
      "         0.8466, -1.6487, -1.1185, -0.2720,  0.0859, -0.8388, -0.8074,  1.0991],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.2305, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.6736, -1.5660,  1.3219,  1.5071,  3.2720,  1.9809,  1.2224, -1.5850,\n",
      "        -2.9500,  1.5324, -1.9279, -1.1155,  1.6594,  1.2745, -1.0156, -1.0870,\n",
      "        -1.3054, -1.5850,  1.7148,  2.9542, -1.9778, -1.0815, -1.1630, -2.8755,\n",
      "         1.3293, -1.3587, -1.5009, -1.4845, -3.0508,  3.3219, -4.1430, -1.3648],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.1199, -1.8784, -0.0357, -1.8832,  2.5064, -1.7372, -1.8976, -1.3343,\n",
      "        -1.3458,  1.2138,  0.9081, -0.9601,  0.5835,  0.8429, -1.5550,  1.0522,\n",
      "        -1.0743, -1.6719, -0.9276,  2.3720, -1.9604, -1.7787, -1.2097, -1.7795,\n",
      "         1.2500, -0.9159, -1.7166, -1.6042,  0.7236,  2.0902, -1.5258, -1.7696],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.0345, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1833, -1.2988,  1.6147, -1.3111, -2.0976, -1.2486,  1.2412,  1.2390,\n",
      "        -1.6323, -1.8561, -2.4420, -2.3388, -2.0730, -2.8157,  1.2630, -1.4454,\n",
      "        -1.3986,  4.3631,  1.6157,  2.2869,  1.6562,  2.4841, -1.8458, -2.4595,\n",
      "        -2.1255,  1.0452,  2.7655, -2.5745,  1.5146,  1.5120,  1.9329, -1.8804],\n",
      "       device='cuda:0')\n",
      "tensor([-1.1363, -1.7209,  1.4154, -1.4753, -1.8807, -1.7187, -1.7236,  1.9138,\n",
      "        -1.3913, -1.9580, -1.7429, -1.7621, -1.9056, -1.9364, -0.8368, -0.2706,\n",
      "         1.4535,  1.9074,  1.5853,  1.2681, -0.6659,  1.2143, -1.9469, -1.6874,\n",
      "         0.2199, -0.2542, -1.7480, -1.9560, -1.2429, -1.0396,  1.2190, -2.0418],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.1618, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2630, -1.9778, -3.0000, -1.6553,  1.3949,  3.0704, -2.2441,  1.2559,\n",
      "         1.2062, -1.5746,  2.3692, -1.3133,  1.0490,  1.1069, -1.1058,  2.2721,\n",
      "        -1.1535, -1.7975,  1.8235, -2.8073,  1.7061, -1.9678, -1.5078,  2.0940,\n",
      "         3.7726, -1.7045,  1.2801, -1.0237,  1.5487, -1.8922,  1.2022, -1.9281],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7395,  0.0120, -1.2580, -1.1297, -0.4506,  1.1384, -0.1062,  1.5779,\n",
      "         1.7763, -1.6514, -0.1153, -1.6508,  1.2820, -0.4800, -1.6487,  1.5929,\n",
      "        -1.6602, -0.7908,  1.1254, -0.8417,  1.3625, -1.6168, -1.4619,  0.2975,\n",
      "         0.0396, -1.2678,  0.5649, -1.7080,  1.5230, -1.8363,  1.4117, -1.6988],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(0.9162, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1628, -1.1540, -1.0941, -1.1598, -1.7593, -1.8405, -2.0666, -1.9069,\n",
      "         2.1252, -1.5850,  1.7893,  3.1767, -1.8658, -1.9850, -1.3823, -2.4829,\n",
      "         1.8122, -1.2224,  1.3041,  1.7914,  3.0502,  1.4105, -1.7998, -1.5850,\n",
      "         1.8522, -2.0502, -1.9358, -2.1699, -1.4795, -1.0795,  1.6379, -2.8073],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6247, -1.6028, -1.2565,  0.8817, -2.0316, -1.8322, -1.3488, -1.2485,\n",
      "         1.4894, -0.8297,  1.0171,  2.4846, -1.6734,  0.0455, -1.6801, -1.6544,\n",
      "         1.2272, -1.7648,  0.4400, -1.3674,  2.7897,  1.7346, -1.9114, -1.5821,\n",
      "         2.4340, -1.6955, -1.5374, -1.6619, -1.6102, -1.6178,  1.6558, -1.6332],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 94 Predict 1126 zeros 557 ones, one bias 0.330957\n",
      "train loss: 1.8135722464360289 dev loss: 1.6178505751861127\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.5460, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.3479, -4.0875,  3.1949,  1.8429, -1.2682, -1.0864, -1.3215, -3.1699,\n",
      "         1.1204,  1.2801,  1.6842, -2.1234, -1.5850,  1.6147,  1.9723, -1.4711,\n",
      "         1.2633,  1.5850, -1.6694, -2.7199, -1.5629, -1.4791, -2.7918, -1.3185,\n",
      "        -1.2814, -1.6229, -2.5136, -1.5574, -1.3310,  1.5803,  1.3219,  1.8210],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8326, -1.7663,  1.6361,  1.4147, -1.0317,  1.1157, -1.0173,  0.7357,\n",
      "        -0.3561,  0.6309,  1.4345, -1.3635, -1.6465,  1.1935,  2.4425, -1.6509,\n",
      "         0.4669, -1.1026,  0.5265, -1.1271, -0.7691, -1.7343, -1.7243,  0.2173,\n",
      "        -1.6517, -0.1704, -1.7481, -1.7765,  0.9216, -1.6332,  0.4886,  1.4771],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(2.3907, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.3219, -1.3425, -1.3099, -1.0064, -2.3842, -1.0996,  1.0047,  1.2677,\n",
      "        -1.6268, -1.0356,  2.2327, -1.2002, -1.6930, -4.0000,  2.0451, -1.4354,\n",
      "         1.7300, -1.9175, -1.0181, -1.5729, -1.1535,  2.0358, -2.7497, -2.7655,\n",
      "         3.1028,  3.4594,  1.6594, -2.1091, -3.3785, -2.5502, -1.3219, -1.3219],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7740, -1.6343, -1.2811, -1.0993, -0.5837, -1.7919, -1.0614,  1.4050,\n",
      "        -0.1957, -1.4607, -0.4682, -1.8464, -1.7514, -1.2254,  0.0764, -1.1018,\n",
      "        -0.9035, -1.9176, -1.7660,  0.0100, -2.2144,  1.7231, -2.0487, -1.9089,\n",
      "         1.9876,  0.1853,  1.9371, -1.3853, -1.5841, -1.7153,  0.1783, -1.1217],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.4260, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0067,  1.3613,  1.7162, -1.6062,  1.1865, -1.2064,  1.1371,  1.9016,\n",
      "        -1.0280, -2.4010,  5.2785,  2.7655, -1.2158,  2.3219, -1.2659,  2.2091,\n",
      "         1.4307, -2.1727,  3.0000, -1.6781, -1.2854, -1.0343,  1.5850,  1.5960,\n",
      "         1.7225, -2.4432, -1.4644,  1.6818, -1.8580, -2.8073, -1.2267, -1.5242],\n",
      "       device='cuda:0')\n",
      "tensor([ 2.0862, -1.1992, -0.0325, -1.8252,  0.3572, -1.5195, -0.3340,  2.1893,\n",
      "        -1.9662, -2.0542,  1.5238, -1.4656, -1.9056,  1.0860, -0.6951,  1.4559,\n",
      "         1.2047, -1.7823,  1.9562, -0.2598, -1.7471, -1.0937,  0.9891,  0.8719,\n",
      "        -0.1616, -1.8798, -1.7574,  0.7452, -1.7271, -1.7487, -1.8703, -1.1314],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.8626, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.9778, -2.7497, -1.9069,  1.0545,  1.9580,  1.7414, -1.1211, -1.6321,\n",
      "         1.3479, -2.0995,  2.5670, -1.0841, -1.0583,  1.0749, -1.5884, -1.7047,\n",
      "         1.2022, -2.3219, -3.2613, -1.2680, -3.6897,  1.1483, -2.3741, -1.4132,\n",
      "        -1.9260, -3.0298, -2.2816,  2.9014, -1.1651, -1.8433, -4.8147, -1.8480],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1610, -1.5673, -0.4351,  1.4202,  1.0816,  1.0173, -0.4947, -1.2357,\n",
      "         0.4952, -1.4520, -0.2219, -1.5159, -1.4482,  0.4030, -1.3941, -1.4916,\n",
      "         1.3836, -1.2275, -1.4292,  1.0639, -1.5974,  1.4165, -1.5222,  1.0840,\n",
      "        -1.3434, -1.3947,  0.2044,  1.5698, -1.4120, -0.4770, -1.1732,  1.0881],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.0914, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0000, -2.5850,  4.7944, -2.8073, -1.2682,  1.1203,  1.1225,  1.5850,\n",
      "        -1.6696, -3.4594, -2.5642, -1.9069, -1.3310, -1.3310, -3.5633,  1.2064,\n",
      "         2.4841, -2.9087,  1.3219, -1.5657, -1.1806, -1.4205,  1.5648, -1.2752,\n",
      "        -1.8580, -2.4594, -2.3219, -2.6623, -1.1543, -3.0508, -1.9824, -1.9260],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.8000, -1.5832,  1.2632, -1.1976, -1.2356,  1.6988,  0.2697,  1.5051,\n",
      "        -1.7629, -1.9778, -1.9350, -1.0200,  1.8972,  0.9418, -1.4395,  0.6518,\n",
      "         1.3278, -1.7017,  1.5425, -1.6271,  0.0359, -1.7215, -1.0031, -1.8287,\n",
      "        -1.8997, -0.9622, -1.3919, -1.5577,  1.1943,  0.1646, -1.8299,  0.0728],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.7850, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8429, -1.0153, -1.1368, -1.4359, -1.7168, -1.8313,  1.3941,  1.6796,\n",
      "         2.2885, -1.7370, -1.1975,  1.3498,  1.5606,  3.1028,  1.0728,  1.3333,\n",
      "        -1.8745,  1.3785,  2.2021, -1.0486,  1.5142, -1.2682,  1.6562,  1.4387,\n",
      "        -1.9746, -1.5309, -2.3219, -1.5850,  1.5110, -1.3626, -1.8931, -2.3219],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.0220, -1.5858, -1.6651, -1.7954, -1.8406,  0.5212,  1.1003,  1.3502,\n",
      "         1.7573, -1.0619, -1.6648,  1.5246, -1.7574,  1.4754,  2.3558,  1.5436,\n",
      "         1.2899, -1.3894,  1.0710, -1.7846,  0.4755,  0.1618,  1.0649,  0.5595,\n",
      "        -0.7709, -1.5557, -1.0671, -1.3581,  1.2442,  0.2260, -1.5830, -1.6342],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 95 Predict 1101 zeros 582 ones, one bias 0.345811\n",
      "train loss: 1.7770443590929015 dev loss: 1.6237669914411264\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.6229, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5170,  1.1871, -2.5428, -2.9696, -1.3857, -1.9069, -2.2311,  1.7414,\n",
      "         1.0331,  1.2022,  2.5850, -1.8881, -1.2682,  1.2122,  2.0000,  3.5850,\n",
      "         3.1155, -1.6472, -1.1942, -3.5034,  1.0452, -2.7397,  1.7526, -1.0155,\n",
      "         2.7467,  1.0992, -1.3425, -1.6280, -1.4354, -1.8361, -2.8651,  1.5915],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7390,  1.4059, -1.7073, -1.5702,  0.1259, -0.2996, -2.0073,  1.2457,\n",
      "         1.2868, -1.1193, -1.1858, -1.6759,  1.1942,  0.7285,  1.3269,  0.0108,\n",
      "        -0.9870,  1.9799, -1.6856, -1.9712,  0.9208, -2.3225,  1.0985, -1.5574,\n",
      "         1.6222, -0.8366, -1.9815, -0.3454, -0.9904, -1.6777, -1.2066, -0.3887],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.7688, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8122,  2.3815, -3.1936, -1.4739, -1.2106, -1.5850,  1.0473, -1.0697,\n",
      "        -3.6114,  2.6630, -1.1375, -1.3487,  2.0232, -2.4021,  1.3968,  1.5663,\n",
      "        -1.0356, -2.5850, -1.1375,  2.3998,  2.3153, -2.5850,  2.1123,  1.8230,\n",
      "         2.5325, -2.1091, -1.3961, -1.8146, -1.5850, -1.1598,  3.3788, -1.0987],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.3038,  1.2640, -1.5893, -1.7736, -1.6543, -1.6164, -1.6958, -0.0902,\n",
      "        -1.6146,  1.2609,  0.8622, -1.7855,  1.0720, -1.1506,  1.2940,  1.0649,\n",
      "         0.2321, -1.3433, -0.5194,  1.5108,  0.3853, -0.6747,  1.4256,  0.9627,\n",
      "         0.6083, -1.3112,  0.5456, -1.3590, -1.3637, -0.6074,  2.1088, -1.8831],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(3.7230, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7596,  3.0558,  1.2538, -1.5633, -1.6980, -1.9018,  3.3219,  1.5850,\n",
      "        -1.3755,  3.1414, -1.5850, -2.9087, -2.0368, -2.5502,  1.0686,  1.0858,\n",
      "         1.0669, -1.8784, -1.6280,  1.9809, -1.2419,  1.3219, -1.3085,  3.5850,\n",
      "        -1.1970,  1.5850,  1.4525, -1.1699, -1.5406, -1.5671,  3.5744, -1.1444],\n",
      "       device='cuda:0')\n",
      "tensor([-0.3708,  0.6934,  0.5190, -1.5789, -0.9056, -1.9849, -1.7136,  0.4396,\n",
      "         0.0722,  2.1331, -0.3867, -1.9338, -0.0817, -1.9476,  1.6145, -1.4293,\n",
      "        -0.9601,  0.9904,  0.6892, -1.3281, -1.6944,  1.0940, -1.5571,  1.5668,\n",
      "        -1.9632,  1.8348, -0.5819, -0.2735, -1.4389, -1.6323,  1.6488, -0.6106],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.0345, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1791,  1.2992, -1.4336,  1.4525, -1.1628,  1.6848, -2.7057, -1.8383,\n",
      "         1.3943,  1.6032,  1.3468, -2.3626, -1.5850,  2.1375, -1.0100, -1.3676,\n",
      "         1.2106, -1.3020, -1.5422,  2.4270, -1.9542, -1.5224, -1.5422,  1.1988,\n",
      "        -1.2630,  1.2167, -2.9500, -1.0705, -2.4586, -1.7370,  1.3949,  1.1224],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4764, -1.2257, -1.6603, -0.6448, -1.6324,  1.4061, -1.3422, -1.7860,\n",
      "         0.7250, -0.1654,  0.5673, -1.1465, -1.3040,  0.9021, -1.6845,  1.3857,\n",
      "         1.0263, -2.0179,  1.0203,  0.3984, -0.0474, -1.2529, -0.3662, -1.6714,\n",
      "        -1.6650, -0.6797, -1.0711, -1.3453, -1.7526, -1.3706,  0.1993,  1.3357],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.9664, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5539,  1.0881,  4.4046, -1.6008, -1.6510, -1.3292, -1.1676, -2.9619,\n",
      "        -1.5224,  2.2979,  1.6714, -1.5659, -2.3526,  2.6553,  2.3641, -1.4451,\n",
      "         2.1694, -2.5136, -1.2222, -3.8791,  4.7944,  1.7300,  1.0024, -2.7307,\n",
      "        -1.4432,  1.0841,  1.9434,  2.2630, -1.5705,  1.1640, -1.3085, -2.3219],\n",
      "       device='cuda:0')\n",
      "tensor([-1.4324,  0.6474,  1.8456, -1.4370, -1.7865, -2.1314, -1.8821, -1.9055,\n",
      "        -1.8869,  1.6959,  1.6573, -1.1706, -1.9723, -1.2215,  1.3554, -1.9291,\n",
      "         1.3842, -1.7248, -0.7157, -1.5838,  1.2185, -1.2496,  1.2452, -1.8929,\n",
      "        -2.0364,  1.4979,  0.1184,  1.2250, -0.9928, -1.7096, -1.1244, -0.4480],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.9126, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1211,  1.5195, -1.5850, -1.7125, -1.9175, -1.4795, -1.0617, -3.6075,\n",
      "        -1.1628, -1.1656,  2.1625,  1.0452, -1.2126,  2.0987,  1.2412,  1.2630,\n",
      "        -1.0875,  1.4418, -1.9814,  1.0545,  2.9069, -2.3219, -1.8819, -2.3219,\n",
      "        -1.5025, -1.0966,  1.2630,  1.3510,  1.9140, -1.1898, -1.6338, -2.3028],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.4892,  1.0070, -1.4793, -1.2253, -1.3743, -1.6317, -1.2687, -1.4930,\n",
      "        -1.9651, -0.2248,  0.5459,  1.2368, -1.7129,  1.0919, -1.1100,  0.7270,\n",
      "        -1.7968,  1.4530, -1.7153,  2.2728, -1.2210, -1.4304, -1.7457, -0.7865,\n",
      "        -0.1917, -1.3976, -0.2960,  0.1978,  0.8827, -1.2617, -1.4709, -2.0104],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 96 Predict 1175 zeros 508 ones, one bias 0.301842\n",
      "train loss: 1.8367222573987834 dev loss: 1.7532158167428873\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(3.0399, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 3.3923,  1.1929,  2.0000,  3.0444,  2.4060, -1.3179, -1.9018,  1.6881,\n",
      "        -1.1656, -1.2315,  2.5025, -2.1703,  2.0358,  2.3692, -1.9069, -2.1027,\n",
      "         3.5850, -2.1905,  1.3219,  2.1399, -2.1309, -2.6439, -1.1975, -1.1048,\n",
      "        -2.3978, -1.3306, -2.2076,  1.3119, -1.3455, -1.9850,  1.2578, -1.9778],\n",
      "       device='cuda:0')\n",
      "tensor([-0.1734, -0.6749, -1.5486,  1.3598,  1.6293, -1.4040, -2.6148, -0.7147,\n",
      "        -1.7034, -1.1128,  1.2248, -1.6163,  0.9389,  0.9032, -1.1957, -1.6592,\n",
      "         0.7410, -0.5006,  1.2452, -1.1271, -1.8375, -1.8467, -1.1977, -1.7823,\n",
      "        -2.0084, -1.9018, -1.6337,  2.3847, -1.0844, -1.2472, -0.9392, -1.0758],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.8811, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.1584, -1.8074, -1.6488, -1.1265,  1.3219, -1.1907, -1.3785, -1.1176,\n",
      "         2.0315, -2.5850, -1.1375,  2.1066,  3.4150, -1.7162, -1.7411, -2.7641,\n",
      "        -1.3838,  1.4307, -1.7294, -1.7843,  2.2119, -1.1628, -1.3744, -1.6524,\n",
      "         1.7914,  1.0122,  2.0000, -1.7194, -1.1726, -1.2630,  2.3692, -2.2676],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6841, -2.0850, -1.2656, -1.2591,  0.0816, -1.7473,  0.7116, -1.6065,\n",
      "         1.5747, -2.0034, -1.3995,  1.4654,  2.0663, -1.8794, -2.1118, -0.6107,\n",
      "        -1.7707,  2.0145, -1.6175,  0.8579,  0.7742, -1.9077,  1.2394, -1.7785,\n",
      "        -1.5436, -0.4165,  1.9438, -1.9477,  0.0767, -0.6058,  0.0422, -0.6787],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.0205, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8884, -1.1942, -2.5850,  2.5361, -1.9260,  1.6712,  1.8224,  1.2786,\n",
      "         1.0090, -1.9850, -2.5850,  1.0680,  1.4387, -2.5850, -2.8073, -1.9376,\n",
      "        -3.5983, -1.1186, -1.7630, -1.9069, -1.3219, -2.3141, -1.5574,  1.3219,\n",
      "         1.5661, -2.1214, -1.0618, -1.5265, -1.2599,  1.2977,  1.0478, -1.9069],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.6282, -1.9072, -1.8195,  1.4571, -1.5943, -0.5617,  1.0125,  0.1428,\n",
      "         0.1701, -1.3205, -1.3213, -0.9456,  0.3866, -1.6431, -1.0355, -1.6255,\n",
      "        -0.5754, -0.6069,  0.6152, -0.0676,  0.2464, -1.8770, -1.2852, -0.9377,\n",
      "         0.4750, -1.1664, -1.6521, -1.6483, -1.8366, -0.2989, -1.0173, -1.0887],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.1087, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.0437,  1.2110, -1.2074, -1.1579,  1.4532, -1.1824,  2.3219, -1.1255,\n",
      "        -3.1530, -1.5224, -1.1155, -1.9376,  1.4411, -1.4191,  1.2346,  2.2479,\n",
      "        -3.9069,  1.0429, -2.3842,  1.5003, -1.8232,  1.6823, -2.2563, -1.5850,\n",
      "         1.7974,  2.3216, -1.3785, -1.2713, -1.3036, -1.2682, -1.9260,  1.4527],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.5156,  1.9952, -1.9462,  1.9043,  1.2321, -1.3424,  1.6762, -1.7370,\n",
      "         0.3587, -1.8841, -0.8761, -1.8587,  1.6196, -1.1478,  1.7601,  1.4627,\n",
      "        -1.5090, -0.4670, -1.0314,  1.3048, -0.3734,  0.3991, -1.0575, -1.3817,\n",
      "         1.6831, -1.1209,  0.5346, -1.8645, -0.4767, -1.2267, -1.0902,  1.3788],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(1.9218, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.1155,  1.7627, -1.5850, -1.2825, -1.8504, -1.0486, -1.8309, -1.5194,\n",
      "        -2.0197, -3.1699, -1.7033,  1.3333,  1.7914, -1.5850, -2.1993, -2.9798,\n",
      "         1.0288, -1.3823, -1.7744, -2.4909,  3.4175, -1.3033, -1.6288,  2.5698,\n",
      "        -1.2737, -1.5817, -2.0000,  2.0000, -2.1155, -1.6268, -2.1699,  2.2081],\n",
      "       device='cuda:0')\n",
      "tensor([-0.8345, -0.6979, -0.7440, -1.3940, -1.8299, -2.0187, -2.0833, -0.4684,\n",
      "        -1.8243, -1.1095, -1.9005, -0.0034, -0.1606, -1.3483, -1.7440, -1.3802,\n",
      "        -1.5116, -1.5715, -0.4876, -2.2782,  1.1447, -1.8283, -1.4169,  1.2777,\n",
      "         1.0853, -1.6829, -1.1498,  1.6836, -2.1287, -1.7476,  0.4558,  0.8546],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.8012, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.2058, -1.5439,  1.0241,  1.1520,  1.3399, -1.1890,  2.9069, -1.3219,\n",
      "         1.7360, -1.5032, -1.9814,  1.5850, -1.0310, -1.3591, -1.6108,  1.4150,\n",
      "        -1.0448, -1.1973, -1.2801, -1.2977,  2.4918,  1.5429, -1.0371, -1.0945,\n",
      "        -2.0351,  1.5850, -1.1427, -2.3842, -2.0862,  1.8514, -1.6280,  2.3835],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.9976, -2.0362,  0.9157,  0.7377, -0.1054, -0.9108,  1.1953, -1.2948,\n",
      "         1.6188, -0.9874, -1.9289,  1.5721,  0.8732, -1.8960,  0.9286,  1.3580,\n",
      "        -0.7369,  0.5452, -1.9511, -1.9017, -0.8445, -0.6684, -2.0860, -1.5979,\n",
      "        -1.6394,  1.3343,  0.5031, -1.6438, -1.3008, -0.8461, -1.5479,  1.6416],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 97 Predict 1112 zeros 571 ones, one bias 0.339275\n",
      "train loss: 1.7910594725963294 dev loss: 1.6125796508533765\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.8977, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6854,  1.2022, -1.9560, -1.7047, -2.2569, -2.4586,  1.3399, -3.1699,\n",
      "        -1.5368,  2.5025, -1.1975, -1.8689, -2.8297,  1.8745,  1.3022, -1.5247,\n",
      "        -2.0241, -1.5850, -1.4919,  1.3388, -3.1699,  2.3696, -2.5443, -1.1508,\n",
      "        -1.9548,  1.6491, -2.3833, -2.3219,  2.1467, -2.8524,  1.5332,  4.3923],\n",
      "       device='cuda:0')\n",
      "tensor([ 0.6981,  1.7715, -1.6656, -1.6792, -1.6516, -1.8022,  1.5065, -0.9903,\n",
      "        -1.4883,  0.4108, -0.0383, -0.7934, -1.8094,  1.7868,  1.9084, -1.5568,\n",
      "         0.5401,  0.4897, -1.2090,  1.3560, -1.4680,  1.4032, -0.8944, -1.6794,\n",
      "        -1.4992,  0.1792, -0.7478,  0.1432,  1.3780, -0.6190,  1.4557,  0.1650],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(3.2133, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.5025, -1.2680, -2.1312, -2.3219,  1.1575,  2.2481,  2.0000, -1.7843,\n",
      "        -1.1611, -2.8141, -1.5168,  2.4250,  1.4555, -1.2547,  1.5455, -1.1069,\n",
      "         1.9353,  1.4950, -2.4041,  1.6529, -2.4594, -4.1699, -3.0750,  1.9016,\n",
      "         1.5751,  1.8160,  1.3364, -2.0666,  1.0452, -1.5282, -1.1628,  1.2538],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5663,  1.3879, -1.5927, -1.1679, -0.9779,  1.6370, -0.9808, -1.5969,\n",
      "         1.5485, -1.7806, -1.8050,  1.3748,  0.6717, -1.9971,  0.0826, -1.6371,\n",
      "         0.5128,  1.8709, -1.8218,  2.2398,  1.3812,  0.3960, -1.8818,  1.7946,\n",
      "         1.4989,  2.1041,  0.2375, -3.0145,  1.9649, -0.0146, -1.8683, -1.2320],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.8758, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6415, -2.5620, -1.6800, -1.4610,  1.2320, -1.9260,  1.2630, -2.4595,\n",
      "        -1.0738,  1.3196,  2.0224, -1.1694,  2.9711, -1.5850,  1.4981, -1.0100,\n",
      "        -2.8290,  2.5698,  2.9380, -1.1942, -1.7503, -1.5850, -1.6938,  1.3219,\n",
      "         1.0761,  2.7549,  1.4477,  2.8073,  2.0000,  1.0608, -1.2267,  1.5400],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6446, -1.1738, -0.1721, -1.2389,  1.4900,  1.1478,  1.9412, -1.6472,\n",
      "         1.3627, -0.9948,  2.8148, -1.8452,  0.9754,  1.4503,  1.3058,  1.9460,\n",
      "        -1.6615,  1.6095,  1.7568, -1.7608, -1.6635, -1.6851, -0.1927,  0.2421,\n",
      "         0.9845,  1.5176, -0.7069, -1.3229,  1.4561, -0.6575, -1.7403,  0.6373],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(3.9680, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.4417,  3.1414,  1.3300, -1.7975,  2.0421,  1.9126, -1.1375,  1.1699,\n",
      "        -1.2044, -1.5475, -1.3215, -2.0000, -3.1043, -1.1694, -1.1579, -1.0562,\n",
      "        -1.1726, -1.0999,  1.9102,  1.4535, -2.1838, -2.9475, -1.1063,  4.7944,\n",
      "        -1.3576, -3.6075, -2.4594, -1.0233, -1.1631, -1.6524,  1.6201,  1.1537],\n",
      "       device='cuda:0')\n",
      "tensor([-0.4604,  0.9142, -0.0583,  1.0370, -1.5097,  0.9261,  0.6911,  1.2788,\n",
      "        -1.7303,  0.9179, -1.4999,  1.0502, -1.2110, -1.4265,  0.7522, -1.5980,\n",
      "        -1.4945, -1.3293,  1.8883,  1.6429, -1.5189, -0.8558, -1.6273,  0.0586,\n",
      "         0.5164, -1.5677, -1.2590, -0.9967, -1.5888,  0.7188,  1.0677, -0.6121],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(2.8949, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.7677, -3.6114,  1.2603,  1.4275,  1.9915,  1.4393,  2.0000, -3.3219,\n",
      "         1.0572, -1.0310,  1.7004,  2.0471, -1.3529, -2.8712, -1.1726, -2.0976,\n",
      "        -2.0630, -1.0641, -1.0999, -1.5623,  1.0841,  1.1574,  1.3986, -1.0766,\n",
      "        -2.1605, -3.2525, -1.8931, -1.8232,  1.6842, -1.7923, -1.5243, -2.0796],\n",
      "       device='cuda:0')\n",
      "tensor([-1.8400, -2.3198, -0.1637,  1.5034, -0.0862, -1.7183,  1.1377,  0.9775,\n",
      "         1.0172,  0.2748,  1.1917,  0.9765, -1.8332, -1.3339, -0.5241, -1.9785,\n",
      "         0.6359, -1.3050, -2.0554, -2.1753,  0.7874,  1.8998,  0.6652, -0.5900,\n",
      "         0.1169, -1.7172, -1.5391, -1.8741,  1.4944, -1.7889, -0.3640, -1.2921],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(2.4952, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 2.9069,  1.2475, -1.5549,  1.3069, -2.1888,  1.2518, -3.1699, -2.3219,\n",
      "        -1.0869,  2.5487, -1.0167,  1.9267,  2.2081, -2.4595,  1.7370, -1.5170,\n",
      "        -1.3823, -2.2605,  1.0841,  1.0085,  1.0706,  1.2357, -1.7140, -1.1703,\n",
      "        -1.5715, -2.9696,  1.7300, -1.7320,  1.3626, -1.4451,  1.6712, -2.9798],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1808,  0.6499, -1.6352,  1.0486, -1.8461,  0.6490, -1.3216, -0.8121,\n",
      "         0.9739,  1.7267,  0.4619,  0.8656, -1.0209, -1.5289,  1.1628, -1.9289,\n",
      "        -1.5646, -1.1994,  0.2081,  0.8364,  0.1052,  0.0532, -0.0873, -0.1376,\n",
      "        -1.2950, -1.3916, -0.3437, -1.8593, -0.6071,  0.7277, -0.2557,  0.3898],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 98 Predict 1067 zeros 616 ones, one bias 0.366013\n",
      "train loss: 1.7775789023832729 dev loss: 1.6565911164956033\n",
      "Size of train dataset: 9282\n",
      "Training...\n",
      "LEN 9282\n",
      "0/9282 \n",
      "loss: tensor(2.4300, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.5606,  1.4854, -1.1679, -1.8931, -1.5236, -1.1942,  1.2167, -1.8138,\n",
      "        -3.3709, -2.6924,  1.8160,  1.2838, -1.2224, -1.9454, -1.0454,  2.3317,\n",
      "        -1.8945, -1.0875,  1.7124,  1.2243, -1.1368,  1.2988,  1.4854, -1.7004,\n",
      "         1.2412, -1.2097, -1.1018,  2.1047, -1.2801, -1.1597, -1.2680,  1.7094],\n",
      "       device='cuda:0')\n",
      "tensor([-1.3375,  1.6790, -1.4914, -1.3093, -1.5143, -1.6822, -0.0947, -1.8229,\n",
      "        -0.8151, -2.1270,  0.7118,  0.9122,  1.5114,  0.1887, -1.6989,  1.6977,\n",
      "         1.0577, -1.0961,  1.3604,  0.9832, -1.9462,  1.4500,  0.5021,  1.6851,\n",
      "        -1.7257, -2.2924,  0.0093,  0.8848, -1.3307, -0.1022,  1.0224,  0.0068],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "1600/9282 \n",
      "loss: tensor(1.6257, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.6496, -1.8875, -1.8667, -1.2514, -1.3219, -1.2730, -1.5850, -3.0298,\n",
      "        -1.4058,  1.2837, -1.1769, -1.0995, -1.7001, -1.9069, -2.7918, -1.0766,\n",
      "        -2.0287, -1.2646, -1.3905, -2.6955, -1.8747, -2.1155, -1.8841, -1.4594,\n",
      "        -3.0000, -1.5850,  1.0573, -1.6265, -1.0969, -2.1871,  3.1028,  3.2920],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6503, -1.4159, -1.8220, -1.7135, -1.8449, -1.6886, -1.7378, -1.7656,\n",
      "         1.8076,  1.5445, -1.6194, -0.9069, -1.4570,  0.1340, -1.6441, -1.4274,\n",
      "        -1.8281, -1.7833, -1.7741, -1.9740, -1.8429, -1.8939, -0.3479, -1.3592,\n",
      "        -1.3354, -1.7407, -1.6902, -1.7624,  1.7244, -1.9204,  1.4095,  0.7869],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "3200/9282 \n",
      "loss: tensor(2.5263, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.2783,  3.0760, -2.3219, -1.3857, -2.0428, -2.8297, -1.5850, -1.8129,\n",
      "        -1.3278, -1.1069, -1.9069,  1.0853, -2.0000, -3.5025,  3.6322,  1.6712,\n",
      "         1.3768,  2.2748, -1.9809, -1.1699,  1.0772, -1.5376,  1.3099, -1.6800,\n",
      "        -2.4288, -1.2630, -1.3878, -2.8290, -2.3547, -1.9260, -1.2801, -2.0360],\n",
      "       device='cuda:0')\n",
      "tensor([-1.7099,  1.9934, -0.9128, -1.4544, -2.1332, -2.2099,  0.9571, -1.3474,\n",
      "        -2.0499,  1.8105, -1.2497,  1.3648,  1.6549, -1.8164,  1.3284, -1.6448,\n",
      "         0.3028,  1.4730, -1.3281, -1.8476, -1.0924, -0.0837,  1.3478, -1.9067,\n",
      "        -1.7883,  1.1199, -1.0527, -1.8918, -1.8219, -1.4465,  1.4731, -1.2532],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "4800/9282 \n",
      "loss: tensor(2.9114, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3204,  1.4150, -3.5983, -1.4150, -1.1375, -1.1621, -2.1180, -1.8473,\n",
      "        -2.8073, -3.5034,  2.5850, -3.0000, -1.5657, -2.3219,  1.3683, -1.5850,\n",
      "        -2.4413,  1.5487,  3.2016, -1.1375, -1.4812,  1.1045,  1.8217, -1.3278,\n",
      "         1.3219, -2.0657, -1.2419,  1.1555, -2.1445,  2.3696, -1.9376, -2.7004],\n",
      "       device='cuda:0')\n",
      "tensor([-1.6689,  1.5131, -1.3426, -1.5789, -1.9389, -1.3420, -1.6270, -1.7868,\n",
      "         0.9034, -1.5440,  0.3050,  1.0336, -1.6162, -1.7239,  1.2949, -1.3081,\n",
      "        -1.6687,  1.0183,  0.1265,  0.1502,  0.6254,  1.1251,  2.4167, -1.5359,\n",
      "         1.1957, -0.1515, -1.7060, -0.4405, -1.5322,  2.0956, -1.7586, -1.5742],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "6400/9282 \n",
      "loss: tensor(3.5545, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([-2.0976,  1.5624, -1.8194,  2.3692,  2.3815, -2.9798, -3.7211, -2.0000,\n",
      "         1.3986, -2.5374, -1.5224, -1.9069, -1.5850, -1.1165, -2.4010, -1.5850,\n",
      "         1.1375, -1.8977, -1.0870,  2.6439,  2.0000, -2.7399,  1.6562, -1.2955,\n",
      "        -1.3040, -1.8572, -1.0970,  1.5120, -1.1259, -2.1234,  1.0452, -2.1801],\n",
      "       device='cuda:0')\n",
      "tensor([-1.5210, -0.2903,  1.3125, -0.0858,  0.6596,  0.4160, -1.2596,  0.8803,\n",
      "         0.0532, -1.3175, -1.6914, -1.4029,  0.5519, -0.0228, -1.7497, -0.5387,\n",
      "         0.6297, -1.6452, -0.8257, -0.3252, -0.5713, -1.5697, -1.1334, -1.1579,\n",
      "        -1.1903, -0.1532, -0.6500,  0.8305, -1.3538, -0.3010,  0.7905, -0.8460],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "8000/9282 \n",
      "loss: tensor(1.2674, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "tensor([ 1.8723,  1.5482, -1.2730, -2.1115,  1.4026, -3.0589, -1.7004,  3.4175,\n",
      "         4.3631,  1.3705, -1.0999,  2.1066, -1.2599, -3.3709, -1.3870,  2.0000,\n",
      "        -1.4600, -1.4795,  2.0000, -1.0870, -2.3091, -1.8313, -1.3785, -1.3179,\n",
      "         1.5110, -1.8458,  1.2087,  1.2234, -1.5271, -1.2682,  1.8160, -1.8074],\n",
      "       device='cuda:0')\n",
      "tensor([ 1.1702,  1.2144, -1.9493, -2.0352,  0.0643, -1.6892, -1.2474,  1.4081,\n",
      "         4.4981,  1.6161, -2.5621,  1.0425, -1.7299, -0.4871, -1.5350, -0.0244,\n",
      "        -1.9874, -1.5194,  1.6152,  0.2769, -1.9375, -0.1071, -1.7826, -0.9796,\n",
      "         1.2221, -0.9081,  0.9450,  1.3535, -0.3573, -2.0698,  1.5737, -1.9564],\n",
      "       device='cuda:0', grad_fn=<SqueezeBackward0>)\n",
      "JASON Epoch 99 Predict 1119 zeros 564 ones, one bias 0.335116\n",
      "train loss: 1.7518650478547155 dev loss: 1.7221569146945461\n"
     ]
    }
   ],
   "source": [
    "import tensorboardX\n",
    "!python main.py \\\n",
    "--train_dataset 'CNRCI/CNRCI_train_data_source/transcripts_type/H1.hESC/lncRNA.csv' \\\n",
    "--dev_dataset   'CNRCI/CNRCI_dev_data_source/transcripts_type/H1.hESC/lncRNA.csv' \\\n",
    "--test_dataset  'CNRCI/CNRCI_test_data_source/transcripts_type/H1.hESC/lncRNA.csv' \\\n",
    "--filter_train 'Y' \\\n",
    "--filter_dev 'N' \\\n",
    "--filter_test 'N' \\\n",
    "--device 'cuda'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPe9GIA0ZYD3"
   },
   "source": [
    "## Excution notes\n",
    "This ran for about an hour on CoLab using a V100 GPU. The virtual machine reporting problems saving and we did not recover the train.log file. We did, however, recover and save the record.csv file, which captures the numerical portion of the log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
