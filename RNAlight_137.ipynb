{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace02a34-7d06-4e75-a244-cf1b915a9471",
   "metadata": {
    "id": "ace02a34-7d06-4e75-a244-cf1b915a9471"
   },
   "source": [
    "# LightGBM with default hyperparameters\n",
    "Like RNAlight_127 was for lncRNA, but this notebook is for mRNA.\n",
    "\n",
    "CoLab CPU himem.   \n",
    "Model = LG1 (default parameters)    \n",
    "In RNAlight, 1=nuclear.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1849059a-b4a8-4b24-b3b4-5ef3f15d5a2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1849059a-b4a8-4b24-b3b4-5ef3f15d5a2f",
    "outputId": "35e1b076-5ead-44ec-b2f7-6630f3696f11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-03 18:21:19.196900\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f0998f-216d-441d-9dc5-5cf2827fe98c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86f0998f-216d-441d-9dc5-5cf2827fe98c",
    "outputId": "ee5219b1-5b71-41fc-b334-e8b44e5ebefb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "#import sklearn.metrics as metrics\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bb7b34a-6cb1-4162-9c13-8d64163e98ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bb7b34a-6cb1-4162-9c13-8d64163e98ae",
    "outputId": "727d459f-1846-479a-83f6-a2b079a67652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06a3c204-1130-447c-a654-c8bff965a3a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06a3c204-1130-447c-a654-c8bff965a3a8",
    "outputId": "0a0779bf-b291-4e57-f423-12f2ade5d267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA DIR ./\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "    print('Running on CoLab')\n",
    "    PATH='/content/drive/'\n",
    "    drive.mount(PATH)\n",
    "    DATA_DIR=PATH+'My Drive/data/Localization/RNAlight/'  # must end in \"/\"\n",
    "    MODEL_DIR=PATH+'My Drive/data/Localization/RNAlight/'  # must end in \"/\"\n",
    "    output_dir=PATH+'My Drive/data/Localization/RNAlight/'\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "    DATA_DIR = './'    # Mac\n",
    "    MODEL_DIR = './'    # Mac\n",
    "    output_dir = './'\n",
    "print('DATA DIR', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "295a8797-dd52-4b92-969a-0655f5e62310",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "295a8797-dd52-4b92-969a-0655f5e62310",
    "outputId": "b83bb5d8-4c5d-490d-cf72-e8b5c8bc756c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "SEED = 100\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c1ce357-cdc1-422e-aba2-8c8a995f73f8",
   "metadata": {
    "id": "4c1ce357-cdc1-422e-aba2-8c8a995f73f8"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    new_model = lightgbm.LGBMClassifier()\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da9eb695-32e6-4527-b54c-a1afd03bcdff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da9eb695-32e6-4527-b54c-a1afd03bcdff",
    "outputId": "5cc56bc1-9456-4fed-a015-983975c74220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier()\n"
     ]
    }
   ],
   "source": [
    "test = build_model()\n",
    "print(test)\n",
    "test = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dea5888f-521c-418b-ad28-437df4507c44",
   "metadata": {
    "id": "dea5888f-521c-418b-ad28-437df4507c44"
   },
   "outputs": [],
   "source": [
    "class stats_collector:\n",
    "    def __init__(self):\n",
    "        self.reset_statistics()\n",
    "    def reset_statistics(self):\n",
    "        self.cv_accuracy=[]\n",
    "        self.cv_precision=[]\n",
    "        self.cv_recall=[]\n",
    "        self.cv_f1=[]\n",
    "        self.cv_mcc=[]\n",
    "        self.cv_auprc=[]\n",
    "        self.cv_auroc=[]\n",
    "    def _append_statistics(self,accuracy,precision,recall,f1,mcc,auprc,auroc):\n",
    "        self.cv_accuracy.append(accuracy)\n",
    "        self.cv_precision.append(precision)\n",
    "        self.cv_recall.append(recall)\n",
    "        self.cv_f1.append(f1)\n",
    "        self.cv_mcc.append(mcc)\n",
    "        self.cv_auprc.append(auprc)\n",
    "        self.cv_auroc.append(auroc)\n",
    "    def compute_performance(self,y_test,yhat_pred,yhat_classes,verbose=False):\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100.\n",
    "        precision = precision_score(y_test, yhat_classes)*100.\n",
    "        recall = recall_score(y_test, yhat_classes)*100.\n",
    "        f1 = f1_score(y_test, yhat_classes)*100.\n",
    "        mcc = matthews_corrcoef(y_test, yhat_classes)\n",
    "        prc_Y, prc_X, prc_bins = precision_recall_curve(y_test, yhat_pred)\n",
    "        auprc = auc(prc_X,prc_Y)*100.\n",
    "        auroc = roc_auc_score(y_test, yhat_pred)*100.\n",
    "        self._append_statistics(accuracy,precision,recall,f1,mcc,auprc,auroc)\n",
    "        if verbose:\n",
    "            self._show_confusion(y_test,yhat_pred,yhat_classes)\n",
    "            self._show_statistics(accuracy,precision,recall,f1,mcc,auprc,auroc)\n",
    "    def _show_confusion(self,y_test,yhat_pred,yhat_classes):\n",
    "            print('Distrib of scores:',np.mean(yhat_pred),'mean',np.std(yhat_pred),'std')\n",
    "            print('Range of scores:',np.min(yhat_pred),'to',np.max(yhat_pred))\n",
    "            cm1 = confusion_matrix(y_test,yhat_classes)\n",
    "            print('Confusion matrix\\n',cm1)\n",
    "            cm2 = confusion_matrix(y_test,yhat_classes,normalize='all')\n",
    "            print('Normalized matrix\\n',cm2)\n",
    "    def _show_statistics(self,accuracy,precision,recall,f1,mcc,auprc,auroc):\n",
    "            print('accuracy:',accuracy,'precision:',precision,'recall:',recall,\\\n",
    "                  'F1:',f1,'MCC:',mcc,'AUPRC:',auprc,'AUROC:',auroc)\n",
    "    def _show_variance(self, name, stats_list):\n",
    "        if name=='MCC':\n",
    "            print('%10s %5.3f mean, %6.3f stdev' % (name,np.mean(stats_list),np.std(stats_list) ) )\n",
    "        else:\n",
    "            print('%10s %5.2f mean, %6.3f stdev' % (name,np.mean(stats_list),np.std(stats_list) ) )\n",
    "        print(stats_list)\n",
    "    def dump_all(self):\n",
    "        self._show_variance('accuracy', self.cv_accuracy)\n",
    "        self._show_variance('precision',self.cv_precision)\n",
    "        self._show_variance('recall',   self.cv_recall)\n",
    "        self._show_variance('F1',       self.cv_f1)\n",
    "        self._show_variance('MCC',      self.cv_mcc)\n",
    "        self._show_variance('AUPRC',    self.cv_auprc)\n",
    "        self._show_variance('AUROC',    self.cv_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c0fe64b-d172-4167-bc2b-d9f617fbb1a1",
   "metadata": {
    "id": "2c0fe64b-d172-4167-bc2b-d9f617fbb1a1"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def _count_kmer(Dataset,k): # k = 3,4,5\n",
    "\n",
    "    # copy dataset\n",
    "    dataset = copy.deepcopy(Dataset)\n",
    "    # alphbet of nucleotide\n",
    "    nucleotide = ['A','C','G','T']\n",
    "\n",
    "    # generate k-mers\n",
    "    #  k == 5:\n",
    "    five = list(itertools.product(nucleotide,repeat=5))\n",
    "    pentamer = []\n",
    "    for n in five:\n",
    "        pentamer.append(\"\".join(n))\n",
    "\n",
    "    #  k == 4:\n",
    "    four = list(itertools.product(nucleotide,repeat=4))\n",
    "    tetramer = []\n",
    "    for n in four:\n",
    "        tetramer.append(\"\".join(n))\n",
    "\n",
    "    # k == 3:\n",
    "    three = list(itertools.product(nucleotide,repeat=3))\n",
    "    threemer = []\n",
    "    for n in three:\n",
    "        threemer.append(\"\".join(n))\n",
    "\n",
    "    # input features can be combinations of diffrent k values\n",
    "    if k == 34:\n",
    "        table_kmer = dict.fromkeys(threemer,0)\n",
    "        table_kmer.update(dict.fromkeys(tetramer,0))\n",
    "    if k == 45:\n",
    "        table_kmer = dict.fromkeys(tetramer,0)\n",
    "        table_kmer.update(dict.fromkeys(pentamer,0))\n",
    "    if k == 345:\n",
    "        table_kmer = dict.fromkeys(threemer,0)\n",
    "        table_kmer.update(dict.fromkeys(tetramer,0))\n",
    "        table_kmer.update(dict.fromkeys(pentamer,0))\n",
    "\n",
    "    # count k-mer for each sequence\n",
    "    for mer in table_kmer.keys():\n",
    "        table_kmer[mer] = dataset[\"cdna\"].apply(lambda x : x.count(mer))\n",
    "\n",
    "    # for k-mer raw count without normalization, index: nuc:1 or cyto:0\n",
    "    rawcount_kmer_df = pd.DataFrame(table_kmer)\n",
    "    df1_rawcount = pd.concat([rawcount_kmer_df,dataset[\"ensembl_transcript_id\"]],axis = 1)\n",
    "    df1_rawcount.index = dataset[\"tag\"]\n",
    "\n",
    "    # for k-mer frequency with normalization , index: nuc:1 or cyto:0\n",
    "    freq_kmer_df = rawcount_kmer_df.apply(lambda x: x/x.sum(),axis=1)\n",
    "    df1 = pd.concat([freq_kmer_df,dataset[\"ensembl_transcript_id\"]],axis = 1)\n",
    "    df1.index = dataset[\"tag\"]\n",
    "\n",
    "    return df1  # ,df1_rawcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e70228e-003b-4b4e-895f-b5d642270490",
   "metadata": {
    "id": "9e70228e-003b-4b4e-895f-b5d642270490"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def load_dataframe(cyto_f,nuc_f):\n",
    "    print('load dataframe')\n",
    "    dataset_cyto = pd.read_csv(cyto_f,sep='\\t',index_col = False)    #1806\n",
    "    dataset_nuc = pd.read_csv(nuc_f,sep='\\t',index_col = False)    #1986\n",
    "    print( len(dataset_cyto), 'cytoplasmic samples')\n",
    "    print( len(dataset_nuc),  'nuclear samples')\n",
    "    return dataset_cyto,dataset_nuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449b9c12-3a7d-4e97-9816-43db7ea0caa8",
   "metadata": {
    "id": "449b9c12-3a7d-4e97-9816-43db7ea0caa8"
   },
   "outputs": [],
   "source": [
    "# Added\n",
    "def rebalance(dataset_cyto,dataset_nuc):\n",
    "    print('sample down to balance classes')\n",
    "    min_size = min(len(dataset_cyto),len(dataset_nuc))\n",
    "    # random sampling without replacement\n",
    "    dataset_cyto = dataset_cyto.sample(min_size, random_state=SEED)\n",
    "    dataset_nuc  = dataset_nuc.sample(min_size,  random_state=SEED)\n",
    "    print( len(dataset_cyto), 'cytoplasmic samples')\n",
    "    print( len(dataset_nuc),  'nuclear samples')\n",
    "    return dataset_cyto,dataset_nuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef1e58c-07a6-47f0-9fef-c439c298b3ff",
   "metadata": {
    "id": "4ef1e58c-07a6-47f0-9fef-c439c298b3ff"
   },
   "outputs": [],
   "source": [
    "# From RNAlight notebook\n",
    "def extract_features_and_split(dataset_cyto,dataset_nuc):\n",
    "    print('add labels, concatenate')\n",
    "    # Set the tag of RCI(log2FC): nuclear 1 / cytosol 0\n",
    "    dataset_nuc['tag'] = 1;dataset_cyto['tag'] = 0\n",
    "    # merge the nuc and cyto dataset\n",
    "    dataset = pd.concat([dataset_nuc,dataset_cyto]) # 3792\n",
    "\n",
    "    print('dedupe (probably not necessary)')\n",
    "    # remove duplications(actually,each mRNA is unique in its class)\n",
    "    dataset.drop_duplicates(keep=\"first\",subset=[\"ensembl_transcript_id\",\"name\",\"cdna\"],inplace=True) # 3792\n",
    "\n",
    "    print('count kmers')\n",
    "    # k = 3,4,5 count the normalized and raw count of kmer\n",
    "    df_kmer_345 = _count_kmer(dataset,345)   # df_kmer_345,df_kmer_345_rawcount =\n",
    "\n",
    "    # We commented this out. No need to save the tsv.\n",
    "    # df_kmer_345.to_csv(os.path.join(output_dir,\"df_kmer345_freq.tsv\"),sep='\\t')\n",
    "    # This was commented out in the original. Seems they reran using saved kmers. Should test if file exists.\n",
    "    # load kmer file\n",
    "    # df_kmer_345 = pd.read_csv(os.path.join(output_dir,\"df_kmer345_freq.tsv\"),sep='\\t',index_col= 0)\n",
    "\n",
    "    # convert to x:kmer-freq , y:label\n",
    "    del df_kmer_345['ensembl_transcript_id']\n",
    "    x_kmer = df_kmer_345.values\n",
    "    y_kmer = y_kmer = np.array(df_kmer_345.index)\n",
    "\n",
    "    # split into training and test sets (9:1)\n",
    "    print('train/test split')\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_kmer, y_kmer, test_size = 0.1, random_state = SEED)\n",
    "\n",
    "    #print('Apply cross-validation to all the data (no test set withheld)')\n",
    "    #x_train, x_test, y_train, y_test = train_test_split(x_kmer, y_kmer, test_size = None, random_state = SEED)\n",
    "    print('train set shape',x_train.shape)\n",
    "    # Added\n",
    "    labels,counts = np.unique(y_train,return_counts=True)\n",
    "    print('train set labels', labels, 'counts',counts)\n",
    "    labels,counts = np.unique(y_test,return_counts=True)\n",
    "    print('test set labels', labels, 'counts',counts)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18b66e70-43ab-4a04-95ec-8d74064d8b65",
   "metadata": {
    "id": "18b66e70-43ab-4a04-95ec-8d74064d8b65"
   },
   "outputs": [],
   "source": [
    "def do_cv(x_train, y_train):\n",
    "    stats = stats_collector()\n",
    "    for round in range(1,3):\n",
    "        fold=0\n",
    "        splitter = KFold(n_splits=5)\n",
    "        for train_index, valid_index in splitter.split(x_train):\n",
    "            fold += 1\n",
    "            print('Round', round, 'Fold', fold)\n",
    "            print('Num samples in train and valid sets:', len(train_index), len(valid_index))\n",
    "            print('Train')\n",
    "            lgb = build_model()\n",
    "            history = lgb.fit(x_train[train_index], y_train[train_index])\n",
    "            print('Validate')\n",
    "            x_valid = x_train[valid_index]\n",
    "            y_valid = y_train[valid_index]\n",
    "            yhat_classes= lgb.predict(x_valid)  # get 0 or 1\n",
    "            yhat_pairs=   lgb.predict_proba(x_valid)  # get [ prob of 0, prob of 1 ]\n",
    "            yhat_pred=    [pair[1] for pair in yhat_pairs]\n",
    "            stats.compute_performance(y_valid,yhat_pred,yhat_classes,verbose=False)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37daf14d-0c14-49c8-b9c0-1590df839c3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37daf14d-0c14-49c8-b9c0-1590df839c3d",
    "outputId": "f42b1bfc-2411-4ac2-9a98-df45cb46610a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the RNAlight training set (already has middle excluded)\n",
      "Data files:\n",
      "./02_mRNA_info_cyto_transcript.tsv \n",
      " ./02_mRNA_info_nuc_transcript.tsv\n",
      "load dataframe\n",
      "2924 cytoplasmic samples\n",
      "2256 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (4662, 1344)\n",
      "train set labels [0 1] counts [2642 2020]\n",
      "test set labels [0 1] counts [282 236]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 3729 933\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1621, number of negative: 2108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.127713 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.434701 -> initscore=-0.262696\n",
      "[LightGBM] [Info] Start training from score -0.262696\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 3729 933\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1606, number of negative: 2123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430678 -> initscore=-0.279084\n",
      "[LightGBM] [Info] Start training from score -0.279084\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1631, number of negative: 2099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101374 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.437265 -> initscore=-0.252268\n",
      "[LightGBM] [Info] Start training from score -0.252268\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1604, number of negative: 2126\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430027 -> initscore=-0.281742\n",
      "[LightGBM] [Info] Start training from score -0.281742\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1618, number of negative: 2112\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.433780 -> initscore=-0.266445\n",
      "[LightGBM] [Info] Start training from score -0.266445\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 3729 933\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1621, number of negative: 2108\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.434701 -> initscore=-0.262696\n",
      "[LightGBM] [Info] Start training from score -0.262696\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 3729 933\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1606, number of negative: 2123\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.102090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3729, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430678 -> initscore=-0.279084\n",
      "[LightGBM] [Info] Start training from score -0.279084\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1631, number of negative: 2099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.437265 -> initscore=-0.252268\n",
      "[LightGBM] [Info] Start training from score -0.252268\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1604, number of negative: 2126\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.106533 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.430027 -> initscore=-0.281742\n",
      "[LightGBM] [Info] Start training from score -0.281742\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 3730 932\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1618, number of negative: 2112\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.132246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3730, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.433780 -> initscore=-0.266445\n",
      "[LightGBM] [Info] Start training from score -0.266445\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 69.03 mean,  1.314 stdev\n",
      "[68.70310825294747, 67.30975348338693, 69.74248927038627, 71.13733905579399, 68.24034334763948, 68.70310825294747, 67.30975348338693, 69.74248927038627, 71.13733905579399, 68.24034334763948]\n",
      " precision 67.61 mean,  2.725 stdev\n",
      "[67.54098360655738, 66.17210682492582, 65.8753709198813, 72.89719626168224, 65.58823529411765, 67.54098360655738, 66.17210682492582, 65.8753709198813, 72.89719626168224, 65.58823529411765]\n",
      "    recall 54.86 mean,  1.930 stdev\n",
      "[51.62907268170426, 53.864734299516904, 57.0694087403599, 56.25, 55.472636815920396, 51.62907268170426, 53.864734299516904, 57.0694087403599, 56.25, 55.472636815920396]\n",
      "        F1 60.54 mean,  1.716 stdev\n",
      "[58.52272727272727, 59.38748335552597, 61.15702479338842, 63.50067842605156, 60.10781671159029, 58.52272727272727, 59.38748335552597, 61.15702479338842, 63.50067842605156, 60.10781671159029]\n",
      "       MCC 0.361 mean,  0.029 stdev\n",
      "[0.34899626516275833, 0.32993508966242013, 0.3683698494294147, 0.41207782768140716, 0.34360561580563576, 0.34899626516275833, 0.32993508966242013, 0.3683698494294147, 0.41207782768140716, 0.34360561580563576]\n",
      "     AUPRC 69.70 mean,  1.904 stdev\n",
      "[69.6389952266259, 68.97241111192089, 68.05852136151887, 73.36529304750037, 68.48617301621701, 69.6389952266259, 68.97241111192089, 68.05852136151887, 73.36529304750037, 68.48617301621701]\n",
      "     AUROC 74.05 mean,  1.477 stdev\n",
      "[74.34644664094692, 72.00115420773878, 74.08711954437642, 76.51125521765056, 73.29672392753214, 74.34644664094692, 72.00115420773878, 74.08711954437642, 76.51125521765056, 73.29672392753214]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use the RNAlight training set (already has middle excluded)')\n",
    "    cyto_f = DATA_DIR+'02_mRNA_info_cyto_transcript.tsv'\n",
    "    nuc_f  = DATA_DIR+'02_mRNA_info_nuc_transcript.tsv'\n",
    "    print('Data files:')\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c05c7485-5917-446b-9207-74fa17bcf5eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c05c7485-5917-446b-9207-74fa17bcf5eb",
    "outputId": "c424b4e2-c904-498b-d6b1-7339a7b9d04a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "2256 cytoplasmic samples\n",
      "2256 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (4060, 1344)\n",
      "train set labels [0 1] counts [2029 2031]\n",
      "test set labels [0 1] counts [227 225]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1632, number of negative: 1616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085953 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502463 -> initscore=0.009852\n",
      "[LightGBM] [Info] Start training from score 0.009852\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1608, number of negative: 1640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077412 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495074 -> initscore=-0.019705\n",
      "[LightGBM] [Info] Start training from score -0.019705\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1632, number of negative: 1616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502463 -> initscore=0.009852\n",
      "[LightGBM] [Info] Start training from score 0.009852\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1626, number of negative: 1622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500616 -> initscore=0.002463\n",
      "[LightGBM] [Info] Start training from score 0.002463\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1626, number of negative: 1622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086176 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500616 -> initscore=0.002463\n",
      "[LightGBM] [Info] Start training from score 0.002463\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1632, number of negative: 1616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502463 -> initscore=0.009852\n",
      "[LightGBM] [Info] Start training from score 0.009852\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1608, number of negative: 1640\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495074 -> initscore=-0.019705\n",
      "[LightGBM] [Info] Start training from score -0.019705\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1632, number of negative: 1616\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502463 -> initscore=0.009852\n",
      "[LightGBM] [Info] Start training from score 0.009852\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1626, number of negative: 1622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500616 -> initscore=0.002463\n",
      "[LightGBM] [Info] Start training from score 0.002463\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 3248 812\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 1626, number of negative: 1622\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 3248, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500616 -> initscore=0.002463\n",
      "[LightGBM] [Info] Start training from score 0.002463\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 67.56 mean,  1.262 stdev\n",
      "[69.33497536945814, 67.11822660098522, 68.7192118226601, 66.62561576354679, 66.00985221674877, 69.33497536945814, 67.11822660098522, 68.7192118226601, 66.62561576354679, 66.00985221674877]\n",
      " precision 67.99 mean,  1.376 stdev\n",
      "[68.38235294117648, 70.3125, 67.46987951807229, 66.10576923076923, 67.67123287671232, 68.38235294117648, 70.3125, 67.46987951807229, 66.10576923076923, 67.67123287671232]\n",
      "    recall 66.56 mean,  3.597 stdev\n",
      "[69.92481203007519, 63.829787234042556, 70.17543859649122, 67.90123456790124, 60.98765432098765, 69.92481203007519, 63.829787234042556, 70.17543859649122, 67.90123456790124, 60.98765432098765]\n",
      "        F1 67.20 mean,  1.773 stdev\n",
      "[69.14498141263941, 66.91449814126395, 68.7960687960688, 66.99147381242386, 64.15584415584415, 69.14498141263941, 66.91449814126395, 68.7960687960688, 66.99147381242386, 64.15584415584415]\n",
      "       MCC 0.352 mean,  0.025 stdev\n",
      "[0.38684663562563976, 0.3454434947168617, 0.3749142767310194, 0.3326749166238937, 0.32159329152348665, 0.38684663562563976, 0.3454434947168617, 0.3749142767310194, 0.3326749166238937, 0.32159329152348665]\n",
      "     AUPRC 74.24 mean,  1.269 stdev\n",
      "[73.62981497860245, 74.04747214345792, 76.05089754703816, 75.11258746711992, 72.34186617206657, 73.62981497860245, 74.04747214345792, 76.05089754703816, 75.11258746711992, 72.34186617206657]\n",
      "     AUROC 74.51 mean,  1.299 stdev\n",
      "[74.50284306407666, 74.0159346569673, 76.54912098648559, 74.93493493493494, 72.54769921436588, 74.50284306407666, 74.0159346569673, 76.54912098648559, 74.93493493493494, 72.54769921436588]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf916e9f-18b0-4892-8f78-4ea810f7bfe1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf916e9f-18b0-4892-8f78-4ea810f7bfe1",
    "outputId": "1ba95d55-9c75-43e5-a4b6-979da5823d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use our lncATLAS training set \"middle exclusion\" (CN-RCI < -2 or CN-RCI > 0)\n",
      "Data files:\n",
      "./ForRNAlight.mRNA_RCIgt0.canonical.tsv \n",
      " ./ForRNAlight.mRNA_RCIlt-2.canonical.tsv\n",
      "load dataframe\n",
      "7909 cytoplasmic samples\n",
      "987 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (8006, 1344)\n",
      "train set labels [0 1] counts [7136  870]\n",
      "test set labels [0 1] counts [773 117]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 6404 1602\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 685, number of negative: 5719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6404, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.106964 -> initscore=-2.122130\n",
      "[LightGBM] [Info] Start training from score -2.122130\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 692, number of negative: 5713\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108041 -> initscore=-2.110914\n",
      "[LightGBM] [Info] Start training from score -2.110914\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 695, number of negative: 5710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148377 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108509 -> initscore=-2.106062\n",
      "[LightGBM] [Info] Start training from score -2.106062\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 698, number of negative: 5707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.159322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108977 -> initscore=-2.101230\n",
      "[LightGBM] [Info] Start training from score -2.101230\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 710, number of negative: 5695\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.155902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110851 -> initscore=-2.082079\n",
      "[LightGBM] [Info] Start training from score -2.082079\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 6404 1602\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 685, number of negative: 5719\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.148336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6404, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.106964 -> initscore=-2.122130\n",
      "[LightGBM] [Info] Start training from score -2.122130\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 692, number of negative: 5713\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.149685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108041 -> initscore=-2.110914\n",
      "[LightGBM] [Info] Start training from score -2.110914\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 695, number of negative: 5710\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.163156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108509 -> initscore=-2.106062\n",
      "[LightGBM] [Info] Start training from score -2.106062\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 698, number of negative: 5707\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.162391 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.108977 -> initscore=-2.101230\n",
      "[LightGBM] [Info] Start training from score -2.101230\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 6405 1601\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 710, number of negative: 5695\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.164325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 6405, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.110851 -> initscore=-2.082079\n",
      "[LightGBM] [Info] Start training from score -2.082079\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 92.56 mean,  0.343 stdev\n",
      "[92.63420724094883, 92.4422236102436, 92.0049968769519, 93.06683322923173, 92.62960649594004, 92.63420724094883, 92.4422236102436, 92.0049968769519, 93.06683322923173, 92.62960649594004]\n",
      " precision 78.81 mean,  4.391 stdev\n",
      "[86.02150537634408, 78.78787878787878, 72.81553398058253, 80.19801980198021, 76.25, 86.02150537634408, 78.78787878787878, 72.81553398058253, 80.19801980198021, 76.25]\n",
      "    recall 43.03 mean,  2.873 stdev\n",
      "[43.24324324324324, 43.82022471910113, 42.857142857142854, 47.093023255813954, 38.125, 43.24324324324324, 43.82022471910113, 42.857142857142854, 47.093023255813954, 38.125]\n",
      "        F1 55.60 mean,  2.958 stdev\n",
      "[57.55395683453237, 56.317689530685925, 53.956834532374096, 59.34065934065934, 50.83333333333333, 57.55395683453237, 56.317689530685925, 53.956834532374096, 59.34065934065934, 50.83333333333333]\n",
      "       MCC 0.548 mean,  0.030 stdev\n",
      "[0.5784821921312423, 0.5526581533532683, 0.5200674858408291, 0.5820065952055359, 0.5066482686818436, 0.5784821921312423, 0.5526581533532683, 0.5200674858408291, 0.5820065952055359, 0.5066482686818436]\n",
      "     AUPRC 67.26 mean,  2.337 stdev\n",
      "[71.07209862766277, 67.85518235912006, 65.00274920115268, 67.75615236405255, 64.600116140603, 71.07209862766277, 67.85518235912006, 65.00274920115268, 67.75615236405255, 64.600116140603]\n",
      "     AUROC 90.72 mean,  0.321 stdev\n",
      "[90.98781208872953, 90.97057174666593, 90.16068924063315, 90.54469705599948, 90.91689798750868, 90.98781208872953, 90.97057174666593, 90.16068924063315, 90.54469705599948, 90.91689798750868]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use our lncATLAS training set \"middle exclusion\" (CN-RCI < -2 or CN-RCI > 0)')\n",
    "    cyto_f = DATA_DIR+'ForRNAlight.mRNA_RCIgt0.canonical.tsv'\n",
    "    nuc_f  = DATA_DIR+'ForRNAlight.mRNA_RCIlt-2.canonical.tsv'\n",
    "    print('Data files:')\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c636039b-3223-4bed-9975-aa712353a1a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c636039b-3223-4bed-9975-aa712353a1a5",
    "outputId": "9e4c9575-3d11-4075-ece7-99c5126769d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "987 cytoplasmic samples\n",
      "987 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (1776, 1344)\n",
      "train set labels [0 1] counts [881 895]\n",
      "test set labels [0 1] counts [106  92]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 1420 356\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 708, number of negative: 712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340131\n",
      "[LightGBM] [Info] Number of data points in the train set: 1420, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498592 -> initscore=-0.005634\n",
      "[LightGBM] [Info] Start training from score -0.005634\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.040010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340126\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503871 -> initscore=0.015482\n",
      "[LightGBM] [Info] Start training from score 0.015482\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 719, number of negative: 702\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505982 -> initscore=0.023928\n",
      "[LightGBM] [Info] Start training from score 0.023928\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 727, number of negative: 694\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.038899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511612 -> initscore=0.046455\n",
      "[LightGBM] [Info] Start training from score 0.046455\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 710, number of negative: 711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.037935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340053\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n",
      "[LightGBM] [Info] Start training from score -0.001407\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 1420 356\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 708, number of negative: 712\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.041470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340131\n",
      "[LightGBM] [Info] Number of data points in the train set: 1420, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498592 -> initscore=-0.005634\n",
      "[LightGBM] [Info] Start training from score -0.005634\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 716, number of negative: 705\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340126\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503871 -> initscore=0.015482\n",
      "[LightGBM] [Info] Start training from score 0.015482\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 719, number of negative: 702\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340060\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505982 -> initscore=0.023928\n",
      "[LightGBM] [Info] Start training from score 0.023928\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 727, number of negative: 694\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.039787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340100\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.511612 -> initscore=0.046455\n",
      "[LightGBM] [Info] Start training from score 0.046455\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 1421 355\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 710, number of negative: 711\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.042136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 340053\n",
      "[LightGBM] [Info] Number of data points in the train set: 1421, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499648 -> initscore=-0.001407\n",
      "[LightGBM] [Info] Start training from score -0.001407\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 82.38 mean,  1.555 stdev\n",
      "[80.33707865168539, 83.38028169014085, 81.97183098591549, 81.40845070422536, 84.78873239436619, 80.33707865168539, 83.38028169014085, 81.97183098591549, 81.40845070422536, 84.78873239436619]\n",
      " precision 83.03 mean,  2.840 stdev\n",
      "[81.28342245989305, 83.70786516853933, 81.11111111111111, 80.72289156626506, 88.30409356725146, 81.28342245989305, 83.70786516853933, 81.11111111111111, 80.72289156626506, 88.30409356725146]\n",
      "    recall 81.77 mean,  1.253 stdev\n",
      "[81.28342245989305, 83.24022346368714, 82.95454545454545, 79.76190476190477, 81.62162162162161, 81.28342245989305, 83.24022346368714, 82.95454545454545, 79.76190476190477, 81.62162162162161]\n",
      "        F1 82.37 mean,  1.620 stdev\n",
      "[81.28342245989305, 83.47338935574228, 82.02247191011237, 80.23952095808383, 84.8314606741573, 81.28342245989305, 83.47338935574228, 82.02247191011237, 80.23952095808383, 84.8314606741573]\n",
      "       MCC 0.648 mean,  0.032 stdev\n",
      "[0.6057336328829541, 0.6676083164765998, 0.639641928785779, 0.62691525411958, 0.6984137248928131, 0.6057336328829541, 0.6676083164765998, 0.639641928785779, 0.62691525411958, 0.6984137248928131]\n",
      "     AUPRC 90.47 mean,  1.584 stdev\n",
      "[90.55944538667234, 92.15603313275899, 88.45043369192842, 88.9268052814806, 92.26938940303317, 90.55944538667234, 92.15603313275899, 88.45043369192842, 88.9268052814806, 92.26938940303317]\n",
      "     AUROC 90.22 mean,  1.421 stdev\n",
      "[89.3617694522672, 91.80421533773489, 88.83951244286439, 89.0183346065699, 92.09220985691574, 89.3617694522672, 91.80421533773489, 88.83951244286439, 89.0183346065699, 92.09220985691574]\n"
     ]
    }
   ],
   "source": [
    "if True:   # just to be sure\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1830d712-20a6-4f94-9ddb-e21be989c4d6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1830d712-20a6-4f94-9ddb-e21be989c4d6",
    "outputId": "205d7595-385e-4ad4-ca01-7c38e166a1a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use our lncATLAS training set \"all\" (-inf <= CN-RCI <= +inf)\n",
      "./ForRNAlight.mRNA_RCIgt-1.canonical.tsv \n",
      " ./ForRNAlight.mRNA_RCIlt-1.canonical.tsv\n",
      "load dataframe\n",
      "12763 cytoplasmic samples\n",
      "3330 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (14483, 1344)\n",
      "train set labels [0 1] counts [11512  2971]\n",
      "test set labels [0 1] counts [1251  359]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2368, number of negative: 9218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.295119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204385 -> initscore=-1.359112\n",
      "[LightGBM] [Info] Start training from score -1.359112\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2423, number of negative: 9163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.299001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.209132 -> initscore=-1.330167\n",
      "[LightGBM] [Info] Start training from score -1.330167\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2336, number of negative: 9250\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.289707 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201623 -> initscore=-1.376183\n",
      "[LightGBM] [Info] Start training from score -1.376183\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 11587 2896\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2395, number of negative: 9192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.276011 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206697 -> initscore=-1.344950\n",
      "[LightGBM] [Info] Start training from score -1.344950\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 11587 2896\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2362, number of negative: 9225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.288065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203849 -> initscore=-1.362408\n",
      "[LightGBM] [Info] Start training from score -1.362408\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2368, number of negative: 9218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.290785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.204385 -> initscore=-1.359112\n",
      "[LightGBM] [Info] Start training from score -1.359112\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2423, number of negative: 9163\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.464301 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.209132 -> initscore=-1.330167\n",
      "[LightGBM] [Info] Start training from score -1.330167\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 11586 2897\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2336, number of negative: 9250\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.279840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11586, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.201623 -> initscore=-1.376183\n",
      "[LightGBM] [Info] Start training from score -1.376183\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 11587 2896\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2395, number of negative: 9192\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.279602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206697 -> initscore=-1.344950\n",
      "[LightGBM] [Info] Start training from score -1.344950\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 11587 2896\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2362, number of negative: 9225\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.271221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 11587, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203849 -> initscore=-1.362408\n",
      "[LightGBM] [Info] Start training from score -1.362408\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 82.27 mean,  0.644 stdev\n",
      "[82.32654470141526, 83.39661719019675, 81.53261995167415, 82.32044198895028, 81.76795580110497, 82.32654470141526, 83.39661719019675, 81.53261995167415, 82.32044198895028, 81.76795580110497]\n",
      " precision 63.67 mean,  2.930 stdev\n",
      "[66.30824372759857, 60.63492063492063, 67.6056338028169, 60.322580645161295, 63.45514950166113, 66.30824372759857, 60.63492063492063, 67.6056338028169, 60.322580645161295, 63.45514950166113]\n",
      "    recall 31.92 mean,  1.649 stdev\n",
      "[30.679933665008292, 34.85401459854015, 30.236220472440944, 32.46527777777778, 31.362889983579638, 30.679933665008292, 34.85401459854015, 30.236220472440944, 32.46527777777778, 31.362889983579638]\n",
      "        F1 42.44 mean,  0.923 stdev\n",
      "[41.950113378684804, 44.264194669756655, 41.784548422198036, 42.21218961625282, 41.978021978021985, 41.950113378684804, 44.264194669756655, 41.784548422198036, 42.21218961625282, 41.978021978021985]\n",
      "       MCC 0.361 mean,  0.008 stdev\n",
      "[0.36581439655855635, 0.37207087765150765, 0.3640757911805218, 0.35070883957119237, 0.35457242454310933, 0.36581439655855635, 0.37207087765150765, 0.3640757911805218, 0.35070883957119237, 0.35457242454310933]\n",
      "     AUPRC 53.67 mean,  1.154 stdev\n",
      "[53.952286545240845, 53.776649042619376, 55.17024586007517, 51.60257926870597, 53.871429484630454, 53.952286545240845, 53.776649042619376, 55.17024586007517, 51.60257926870597, 53.871429484630454]\n",
      "     AUROC 79.79 mean,  0.699 stdev\n",
      "[79.3622703107537, 80.8082644268566, 80.43749173263157, 79.019845545977, 79.33156134157295, 79.3622703107537, 80.8082644268566, 80.43749173263157, 79.019845545977, 79.33156134157295]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Use our lncATLAS training set \"all\" (-inf <= CN-RCI <= +inf)')\n",
    "    cyto_f = DATA_DIR+'ForRNAlight.mRNA_RCIgt-1.canonical.tsv'\n",
    "    nuc_f  = DATA_DIR+'ForRNAlight.mRNA_RCIlt-1.canonical.tsv'\n",
    "    print(cyto_f,'\\n',nuc_f)\n",
    "    dataset_cyto,dataset_nuc = load_dataframe(cyto_f,nuc_f)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44560340-f786-4111-a3de-242d9b2aeb17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44560340-f786-4111-a3de-242d9b2aeb17",
    "outputId": "6053dce0-01c3-474b-df55-a7bb89027670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebalance (sample down the majority class) and repeat\n",
      "sample down to balance classes\n",
      "3330 cytoplasmic samples\n",
      "3330 nuclear samples\n",
      "add labels, concatenate\n",
      "dedupe (probably not necessary)\n",
      "count kmers\n",
      "train/test split\n",
      "train set shape (5994, 1344)\n",
      "train set labels [0 1] counts [2995 2999]\n",
      "test set labels [0 1] counts [335 331]\n",
      "Round 1 Fold 1\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2385, number of negative: 2410\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497393 -> initscore=-0.010428\n",
      "[LightGBM] [Info] Start training from score -0.010428\n",
      "Validate\n",
      "Round 1 Fold 2\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2412, number of negative: 2383\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503024 -> initscore=0.012096\n",
      "[LightGBM] [Info] Start training from score 0.012096\n",
      "Validate\n",
      "Round 1 Fold 3\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2376, number of negative: 2419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.114070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495516 -> initscore=-0.017936\n",
      "[LightGBM] [Info] Start training from score -0.017936\n",
      "Validate\n",
      "Round 1 Fold 4\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2419, number of negative: 2376\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504484 -> initscore=0.017936\n",
      "[LightGBM] [Info] Start training from score 0.017936\n",
      "Validate\n",
      "Round 1 Fold 5\n",
      "Num samples in train and valid sets: 4796 1198\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2404, number of negative: 2392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501251 -> initscore=0.005004\n",
      "[LightGBM] [Info] Start training from score 0.005004\n",
      "Validate\n",
      "Round 2 Fold 1\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2385, number of negative: 2410\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497393 -> initscore=-0.010428\n",
      "[LightGBM] [Info] Start training from score -0.010428\n",
      "Validate\n",
      "Round 2 Fold 2\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2412, number of negative: 2383\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.113621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503024 -> initscore=0.012096\n",
      "[LightGBM] [Info] Start training from score 0.012096\n",
      "Validate\n",
      "Round 2 Fold 3\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2376, number of negative: 2419\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.116819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495516 -> initscore=-0.017936\n",
      "[LightGBM] [Info] Start training from score -0.017936\n",
      "Validate\n",
      "Round 2 Fold 4\n",
      "Num samples in train and valid sets: 4795 1199\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2419, number of negative: 2376\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.126385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4795, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504484 -> initscore=0.017936\n",
      "[LightGBM] [Info] Start training from score 0.017936\n",
      "Validate\n",
      "Round 2 Fold 5\n",
      "Num samples in train and valid sets: 4796 1198\n",
      "Train\n",
      "[LightGBM] [Info] Number of positive: 2404, number of negative: 2392\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.129722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 342720\n",
      "[LightGBM] [Info] Number of data points in the train set: 4796, number of used features: 1344\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501251 -> initscore=0.005004\n",
      "[LightGBM] [Info] Start training from score 0.005004\n",
      "Validate\n",
      "\n",
      "Cross validation results\n",
      "  accuracy 71.00 mean,  0.973 stdev\n",
      "[71.3094245204337, 71.72643869891576, 69.14095079232693, 71.80984153461218, 71.03505843071787, 71.3094245204337, 71.72643869891576, 69.14095079232693, 71.80984153461218, 71.03505843071787]\n",
      " precision 71.21 mean,  1.031 stdev\n",
      "[73.03754266211604, 70.0, 70.50243111831442, 71.2280701754386, 71.30584192439862, 73.03754266211604, 70.0, 70.50243111831442, 71.2280701754386, 71.30584192439862]\n",
      "    recall 70.64 mean,  1.649 stdev\n",
      "[69.70684039087948, 73.93526405451448, 69.82343499197432, 70.0, 69.74789915966386, 69.70684039087948, 73.93526405451448, 69.82343499197432, 70.0, 69.74789915966386]\n",
      "        F1 70.91 mean,  0.631 stdev\n",
      "[71.33333333333333, 71.91383595691796, 70.16129032258065, 70.6086956521739, 70.51826677994903, 71.33333333333333, 71.91383595691796, 70.16129032258065, 70.6086956521739, 70.51826677994903]\n",
      "       MCC 0.420 mean,  0.020 stdev\n",
      "[0.4269662924591243, 0.43559115420084116, 0.3821311695166136, 0.4353537354010808, 0.4206904836565767, 0.4269662924591243, 0.43559115420084116, 0.3821311695166136, 0.4353537354010808, 0.4206904836565767]\n",
      "     AUPRC 77.39 mean,  0.772 stdev\n",
      "[78.71215760438875, 77.7742772989811, 76.5693808828234, 76.90140468234175, 76.97957868595834, 78.71215760438875, 77.7742772989811, 76.5693808828234, 76.90140468234175, 76.97957868595834]\n",
      "     AUROC 78.38 mean,  1.210 stdev\n",
      "[78.85130432361703, 79.93285900390819, 76.22308052434458, 78.56526098824578, 78.3463634209903, 78.85130432361703, 79.93285900390819, 76.22308052434458, 78.56526098824578, 78.3463634209903]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print('Rebalance (sample down the majority class) and repeat')\n",
    "    dataset_cyto,dataset_nuc = rebalance(dataset_cyto,dataset_nuc)\n",
    "    x_train, x_test, y_train, y_test = extract_features_and_split(dataset_cyto,dataset_nuc)\n",
    "    stats = do_cv(x_train, y_train)\n",
    "    print('\\nCross validation results')\n",
    "    stats.dump_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35cf8437-c2c6-41d2-8b1f-70cc7ba25672",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35cf8437-c2c6-41d2-8b1f-70cc7ba25672",
    "outputId": "50d657e7-1f49-43ff-fccf-13364c8562c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-03 18:45:17.876159\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
